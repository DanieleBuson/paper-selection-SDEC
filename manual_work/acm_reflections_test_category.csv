,Unnamed: 0.2,Category,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,ISBN,ISSN,Date,Date Added,Date Modified,Pages,Series,Publisher,Key,Eligibility_Abstract_Score,Eligibility_Keywords_Score,Eligibility_Title_Score,Eligibility_Score
0,4.0,reflections,5.0,5.0,Implementing AI Ethics: Making Sense of the Ethical Requirements,Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering,,,10.1145/3593434.3593453,"Agbese, Mamia; Mohanani, Rahul; Khan, Arif; Abrahamsson, Pekka",2023.0,https://doi.org/10.1145/3593434.3593453,conferencePaper,"Society’s increasing dependence on Artificial Intelligence (AI) and AI-enabled systems require a more practical approach from software engineering (SE) executives in middle and higher-level management to improve their involvement in implementing AI ethics by making ethical requirements part of their management practices. However, research indicates that most work on implementing ethical requirements in SE management primarily focuses on technical development, with scarce findings for middle and higher-level management. We investigate this by interviewing ten Finnish SE executives in middle and higher-level management to examine how they consider and implement ethical requirements. We use ethical requirements from the European Union (EU) Trustworthy Ethics guidelines for Trustworthy AI as our reference for ethical requirements and an Agile portfolio management framework to analyze implementation. Our findings reveal a general consideration of privacy and data governance ethical requirements as legal requirements with no other consideration for ethical requirements identified. The findings also show practicable consideration of ethical requirements as technical robustness and safety for implementation as risk requirements and societal and environmental well-being for implementation as sustainability requirements. We examine a practical approach to implementing ethical requirements using the ethical risk requirements stack employing the Agile portfolio management framework.",Agile portfolio management; AI; AI ethics; AI ethics principles; Ethical requirements; Ethical requirements stack,9798400700446,,2023,2023-11-06 01:29:48,2023-11-06 01:29:48,62–71,EASE '23,Association for Computing Machinery,EVKFC8AL,0.2,0.9285714285714286,0.6666666666666666,0.2671024151287309
1,10.0,reflections,12.0,12.0,Artificial Intelligence Ethics Guidelines for K-12 Education: A Review of the Global Landscape,"Artificial Intelligence in Education: 22nd International Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part II",,,10.1007/978-3-030-78270-2_4,"Adams, Cathy; Pente, Patti; Lemermeyer, Gillian; Rockwell, Geoffrey",2021.0,https://doi.org/10.1007/978-3-030-78270-2_4,conferencePaper,"To scope the global landscape of ethical issues involving the use of AI in K-12 education, we identified relevant ethics guidance documents, and then compared and contrasted concerns raised and principles applied. We found that while AIEdK-12 ethics guidelines employed many principles common to non-AIEd policy statements (e.g., transparency), new ethical principles were being engaged including pedagogical appropriateness and children’s rights.",AI literacy; AI and ethics; AI ethics guidelines; Artificial intelligence in education; Children’s rights; K-12 education; Teacher well-being,978-3-030-78269-6,,2021,2023-11-06 01:30:04,2023-11-06 01:30:04,24–28,,Springer-Verlag,EJS6LDIG,0.180327868852459,0.3888888888888889,0.1538461538461538,0.219796816967626
2,11.0,reflections,13.0,13.0,The Cost of Ethical AI Development for AI Startups,"Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3514094.3534195,"Bessen, James; Impink, Stephen Michael; Seamans, Robert",2022.0,https://doi.org/10.1145/3514094.3534195,conferencePaper,"Artificial Intelligence startups use training data as direct inputs in product development. These firms must balance numerous tradeoffs between ethical issues and data access without substantive guidance from regulators or existing judicial precedence. We survey these startups to determine what actions they have taken to address these ethical issues and the consequences of those actions. We find that 58% of these startups have established a set of AI principles. Startups with data-sharing relationships with high-technology firms or that have prior experience with privacy regulations are more likely to establish ethical AI principles and are more likely to take costly steps, like dropping training data or turning down business, to adhere to their ethical AI policies. Moreover, startups with ethical AI policies are more likely to invest in unconscious bias training, hire ethnic minorities and female programmers, seek expert advice, and search for more diverse training data. Potential costs associated with data-sharing relationships and the adherence to ethical policies may create tradeoffs between increased AI product competition and more ethical AI production.",ethics; AI; data; scale barriers; startups,978-1-4503-9247-1,,2022,2023-11-06 01:29:57,2023-11-06 01:29:57,92–106,AIES '22,Association for Computing Machinery,H9LSTATR,0.1871345029239766,0.6666666666666666,0.5555555555555556,0.2175217397315195
3,15.0,reflections,17.0,17.0,Modeling and Guiding the Creation of Ethical Human-AI Teams,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462573,"Flathmann, Christopher; Schelble, Beau G.; Zhang, Rui; McNeese, Nathan J.",2021.0,https://doi.org/10.1145/3461702.3462573,conferencePaper,"With artificial intelligence continuing to advance, so too do the ethical concerns that can potentially negatively impact humans and the greater society. When these systems begin to interact with humans, these concerns become much more complex and much more important. The field of human-AI teaming provides a relevant example of how AI ethics can have significant and continued effects on humans. This paper reviews research in ethical artificial intelligence, as well as ethical teamwork through the lens of the rapidly advancing field of human-AI teaming, resulting in a model demonstrating the requirements and outcomes of building ethical human-AI teams. The model is created to guide the prioritization of ethics in human-AI teaming by outlining the ethical teaming process, outcomes of ethical teams, and external requirements necessary to ensure ethical human-AI teams. A final discussion is presented on how the developed model will influence the implementation of AI teammates, as well as the development of policy and regulation surrounding the domain in the coming years.",AI ethics; artificial intelligence; human-AI ethics; human-AI teamwork,978-1-4503-8473-5,,2021,2023-11-06 01:29:49,2023-11-06 01:29:49,469–479,AIES '21,Association for Computing Machinery,PMTFXUSL,0.1646341463414634,0.625,0.3333333333333333,0.1994351874211811
4,16.0,reflections,18.0,18.0,Ethics of AI: A Systematic Literature Review of Principles and Challenges,Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering,,,10.1145/3530019.3531329,"Khan, Arif Ali; Badshah, Sher; Liang, Peng; Waseem, Muhammad; Khan, Bilal; Ahmad, Aakash; Fahmideh, Mahdi; Niazi, Mahmood; Akbar, Muhammad Azeem",2022.0,https://doi.org/10.1145/3530019.3531329,conferencePaper,"Ethics in AI becomes a global topic of interest for both policymakers and academic researchers. In the last few years, various research organizations, lawyers, think tankers, and regulatory bodies get involved in developing AI ethics guidelines and principles. However, there is still debate about the implications of these principles. We conducted a systematic literature review (SLR) study to investigate the agreement on the significance of AI principles and identify the challenging factors that could negatively impact the adoption of AI ethics principles. The results reveal that the global convergence set consists of 22 ethical principles and 15 challenges. Transparency, privacy, accountability and fairness are identified as the most common AI ethics principles. Similarly, lack of ethical knowledge and vague principles are reported as the significant challenges for considering ethics in AI. The findings of this study are the preliminary inputs for proposing a maturity model that assesses the ethical capabilities of AI systems and provides best practices for further improvements.",AI Ethics; Principles; Challenges; Machine Ethics; Systematic Literature Review,978-1-4503-9613-4,,2022,2023-11-06 01:29:55,2023-11-06 01:29:55,383–392,EASE '22,Association for Computing Machinery,JD9H6H5T,0.16875,0.5555555555555556,0.2727272727272727,0.1993418041683879
5,20.0,reflections,22.0,22.0,A Literature Review on Digital Ethics from a Humanistic and Sustainable Perspective,Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance,,,10.1145/3494193.3494295,"Teran, Luis; Pincay, Jhonny; Wallimann-Helmer, Ivo; Portmann, Edy",2022.0,https://doi.org/10.1145/3494193.3494295,conferencePaper,"The rapid technological transition requires the adoptive approach to the digital conduct of public and private institutions. Countries and companies strive to integrate a balanced understanding of digital ethics and sustainability concepts from various standpoints, which results in a dispersed and uncategorized knowledge base. This work presents a literature review on digital ethics published from 2010 to 2020 in three technical libraries and one library maintained by the community of philosophers. The investigation process integrates a thorough review of digital ethics concepts in the leading academic libraries using keywords representing various concept applications. This study's outcome is a quantitative and sectorial categorization of works on digital ethics, followed by a holistic review of concepts, maturity level, and conclusions on each category. This work aims to understand the trends from a technological and philosophical perspective towards designing a sustainable digital ethical framework applied in digital services that fulfill sufficiency thresholds of justice and do not foster overshooting of planetary boundaries. The first version of a holistic framework based on the literature review is presented at the end of this work. It will be extended in future work.",digital ethics; ethical challenge; humanistic; literature review; sustainability,978-1-4503-9011-8,,2022,2023-11-06 01:29:48,2023-11-06 01:29:48,57–64,ICEGOV '21,Association for Computing Machinery,WG3RQG8Q,0.1397849462365591,0.875,0.3333333333333333,0.1912146992792153
6,22.0,reflections,24.0,24.0,Ethical Framework for Artificial Intelligence and Digital Technologies,Int. J. Inf. Manag.,62.0,C,10.1016/j.ijinfomgt.2021.102433,"Ashok, Mona; Madan, Rohit; Joha, Anton; Sivarajah, Uthayasankar",2022.0,https://doi.org/10.1016/j.ijinfomgt.2021.102433,journalArticle,"The use of Artificial Intelligence (AI) in Digital technologies (DT) is proliferating a profound socio-technical transformation. Governments and AI scholarship have endorsed key AI principles but lack direction at the implementation level. Through a systematic literature review of 59 papers, this paper contributes to the critical debate on the ethical use of AI in DTs beyond high-level AI principles. To our knowledge, this is the first paper that identifies 14 digital ethics implications for the use of AI in seven DT archetypes using a novel ontological framework (physical, cognitive, information, and governance). The paper presents key findings of the review and a conceptual model with twelve propositions highlighting the impact of digital ethics implications on societal impact, as moderated by DT archetypes and mediated by organisational impact. The implications of intelligibility, accountability, fairness, and autonomy (under the cognitive domain), and privacy (under the information domain) are the most widely discussed in our sample. Furthermore, ethical implications related to the governance domain are shown to be generally applicable for most DT archetypes. Implications under the physical domain are less prominent when it comes to AI diffusion with one exception (safety). The key findings and resulting conceptual model have academic and professional implications.",Artificial Intelligence (AI) ethics; Digital ethics; Digital technologies and archetypes; Ontological framework; PRISMA; Systematic literature review,,0268-4012,2022-02,2023-11-06 01:29:50,2023-11-06 01:29:50,,,,RGCVHYXK,0.1243781094527363,0.5625,0.625,0.1866909628874262
7,23.0,reflections,25.0,25.0,Getting into the Engine Room: A Blueprint to Investigate the Shadowy Steps of AI Ethics,AI Soc.,36.0,2,10.1007/s00146-020-01069-w,"Rochel, Johan; Evéquoz, Florian",2021.0,https://doi.org/10.1007/s00146-020-01069-w,journalArticle,"Enacting an AI system typically requires three iterative phases where AI engineers are in command: selection and preparation of the data, selection and configuration of algorithmic tools, and fine-tuning of the different parameters on the basis of intermediate results. Our main hypothesis is that these phases involve practices with ethical questions. This paper maps these ethical questions and proposes a way to address them in light of a neo-republican understanding of freedom, defined as absence of domination. We thereby identify different types of responsibility held by AI engineers and link them to concrete suggestions on how to improve professional practices. This paper contributes to the literature on AI and ethics by focusing on the work necessary to configure AI systems, thereby offering an input to better practices and an input for societal debates.",AI ethics; Applied ethics; Data ethics; Data science; Responsible innovation,,0951-5666,2021-06,2023-11-06 01:29:48,2023-11-06 01:29:48,609–622,,,GFZ5PDIF,0.1203007518796992,0.9,0.2,0.1844392959142041
8,25.0,reflections,27.0,27.0,Design Science Research and Designing Ethical Guidelines for the SHAPES AI Developers,Procedia Comput. Sci.,192.0,C,10.1016/j.procs.2021.08.223,"Nevanperä, Minna; Rajamäki, Jyri; Helin, Jaakko",2021.0,https://doi.org/10.1016/j.procs.2021.08.223,journalArticle,"This article targets the design process of ethical guidelines for the SHAPES project (Smart and Healthy Aging through People Engaging in Supportive Systems) which is a H2020 Innovation Action project. The aim of the project is to build solutions that can make it easier for older individuals to live at home, such as, robots, wearables and sensor technologies that apply artificial intelligence (AI). The guiding method of the design process of ethical guidelines is Alan Hevner’s Design Science Research. Theoretical background consists of a form of literature overview, which contains the most relevant ethical theories and research on AI ethics, machine ethics and human rights. This article introduces the process of building the ethical guidelines for the SHAPES project and further discussion if providing guidelines is the sufficient tool to developers to take ethical action in development of the AI systems. The SHAPES guidelines include the following themes; accountability, transparency and explainability, diversity, inclusion and fairness, safety and security and societal wellbeing and humanity.",Design Science Reseach; Ethical Competence; Ethical Guidelines; SHAPES,,1877-0509,2021-01,2023-11-06 01:30:03,2023-11-06 01:30:03,2330–2339,,,9ZGXWGLX,0.1341463414634146,0.75,0.3333333333333333,0.1816468560255222
9,33.0,reflections,36.0,36.0,The European Commission Report on Ethics of Connected and Automated Vehicles and the Future of Ethics of Transportation,Ethics and Inf. Technol.,23.0,4,10.1007/s10676-021-09609-8,"Santoni de Sio, Filippo",2021.0,https://doi.org/10.1007/s10676-021-09609-8,journalArticle,"The paper has two goals. The first is presenting the main results of the recent report Ethics of Connected and Automated Vehicles: recommendations on road safety, privacy, fairness, explainability and responsibility written by the Horizon 2020 European Commission Expert Group to advise on specific ethical issues raised by driverless mobility, of which the author of this paper has been member and rapporteur. The second is presenting some broader ethical and philosophical implications of these recommendations, and using these to contribute to the establishment of Ethics of Transportation as an independent&nbsp;branch of applied ethics. The recent debate on the ethics of Connected and Automated Vehicles (CAVs) presents a paradox and an opportunity. The paradox is the presence of a flourishing debate on the ethics of one very specific transportation technology without ethics of transportation being in itself a well-established academic discipline. The opportunity is that now that a spotlight has been switched on the ethical dimensions of CAVs it may be easier to establish a broader debate on ethics of transportation. While the 20 recommendations of the EU report are grouped in three macro-areas: road safety, data ethics, and responsibility, in this paper they will be grouped according to eight philosophical themes: Responsible Innovation, road justice, road safety, freedom, human control, privacy, data fairness, responsibility. These are proposed as the first topics for a new ethics of transportation.",Ethics of self-driving cars; Ethics of transportation; European Commission Report on ethics of CAVs; Responsible innovation in self-driving cars,,1388-1957,2021-12,2023-11-06 01:30:04,2023-11-06 01:30:04,713–726,,,BSYCZR64,0.1541850220264317,0.3157894736842105,0.2222222222222222,0.1717578331536133
10,38.0,reflections,41.0,41.0,What Does It Mean to Embed Ethics in Data Science? An Integrative Approach Based on Microethics and Virtues,AI Soc.,36.0,3,10.1007/s00146-020-01112-w,"Bezuidenhout, Louise; Ratti, Emanuele",2021.0,https://doi.org/10.1007/s00146-020-01112-w,journalArticle,"In the past few years, scholars have been questioning whether the current approach in data ethics based on the higher level case studies and general principles is effective. In particular, some have been complaining that such an approach to ethics is difficult to be applied and to be taught in the context of data science. In response to these concerns, there have been discussions about how ethics should be “embedded” in the practice of data science, in the sense of showing how ethical issues emerge in small technical choices made by data scientists in their day-to-day activities, and how such an approach can be used to teach data ethics. However, a precise description of how such proposals have to be theoretically conceived and could be operationalized has been lacking. In this article, we propose a full-fledged characterization of ‘embedding’ ethics, and how this can be applied especially to the problem of teaching data science ethics. Using the emerging model of ‘microethics’, we propose a way of teaching daily responsibility in digital activities that is connected to (and draws from) the higher level ethical challenges discussed in digital/data ethics. We ground this microethical approach into a virtue theory framework, by stressing that the goal of a microethics is to foster the cultivation of moral virtues. After delineating this approach of embedding ethics in theoretical detail, this article discusses a concrete example of how such a ‘micro-virtue ethics’ approach could be practically taught to data science students.",Embedded ethics; Data science; Virtue ethics; Microethics; Teaching ethics,,0951-5666,2021-09,2023-11-06 01:30:03,2023-11-06 01:30:03,939–953,,,B9TXHEP8,0.1387755102040816,0.7777777777777778,0.1666666666666666,0.167833615141625
11,39.0,reflections,42.0,42.0,A Sector-Based Approach to AI Ethics: Understanding Ethical Issues of AI-Related Incidents within Their Sectoral Context,"Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3600211.3604680,"Burema, Dafna; Debowski-Weimann, Nicole; von Janowski, Alexander; Grabowski, Jil; Maftei, Mihai; Jacobs, Mattis; van der Smagt, Patrick; Benbouzid, Djalel",2023.0,https://doi.org/10.1145/3600211.3604680,conferencePaper,"Acknowledging that society is made up of different sectors with their own rules and structures, this paper studies the relevance of a sector-specific perspective to AI ethics. Incidents with AI are studied in relation to five sectors (police, healthcare, education and academia, politics, automotive) using the AIAAIC repository. A total of 125 incidents are sampled and analyzed by conducting a qualitative content analysis on media reports. The results show that certain ethical principles are found breached across sectors: accuracy/reliability, bias/discrimination, transparency, surveillance/privacy, security. However, results also show that 1) some ethical issues (misinformation, safety, premise/intent) are sector specific, 2) the consequences and meaning of the same ethical issue is able to vary across sectors and 3) pre-existing sector-specific issues are reproduced with these ethical breaches. The paper concludes that general ethical principles are relevant to discuss across sectors, yet, a sector-based approach to AI ethics gives in-depth information on sector-specific structural issues.",,9798400702310,,2023,2023-11-06 01:29:48,2023-11-06 01:29:48,705–714,AIES '23,Association for Computing Machinery,4REIZHKM,0.1447368421052631,0.0,0.375,0.1672564663492472
