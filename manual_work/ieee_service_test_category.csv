,Unnamed: 0.2,Category,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,Author Affiliations,Date Added To Xplore,Unnamed: 13,Unnamed: 14,Start Page,End Page,ISSN,ISBNs,Funding Information,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Reference Count,License,Online Date,Publisher,Eligibility_Abstract_Score,Eligibility_Keywords_Score,Eligibility_Title_Score,Eligibility_Score
0,0.0,service,0.0,0.0,An Integrated Framework for Ethical and Sustainable Digitalization,2021 Eighth International Conference on eDemocracy & eGovernment (ICEDEG),,,10.1109/ICEDEG52154.2021.9530972,I. Wallimann-Helmer; L. Terán; E. Portmann; H. Schübel; J. Pincay,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530972,IEEE Conferences,"Dynamically developing digitization initiatives among public institutions and private companies necessitate a balanced approach to digital ethics. Several frameworks and legal regulations have been adopted to clarify and define the various ethical challenges in digital contexts. These initiatives often accentuate one of three components: data security, data governance, or digital strategy. However, an integrated approach is required to meet the current demand for an ethical and sustainable approach to digitalization and address the growing number of challenges occurring in handling data and related peripheral components. This paper develops the concept of an integrated framework to incorporate all relevant aspects of digital ethics by combining three categories of digital contexts: law and regulations, ethics and justice, and environmental sustainability. The core of this integrated framework, the Fribourg sustainable digital ethics framework (FSDEF), consists of two boundary conditions of sustainable development: social thresholds of justice and ecological planetary boundaries. It also incorporates numerous other frameworks and standards, including value-based engineering and IEEE standards.",Digital ethics;sustainability;corporate digital responsibility,"UniFR_ESH Institute, University of Fribourg, Fribourg, Switzerland; Human-IST Insitute, University of Fribourg, Fribourg, Switzerland; Human-IST Insitute, University of Fribourg, Fribourg, Switzerland; UniFR_ESH Institute, University of Fribourg, Fribourg, Switzerland; Human-IST Insitute, University of Fribourg, Fribourg, Switzerland",13 Sep 2021,,,156.0,162.0,2573-1998,978-1-6654-2512-4,,Ethics;Law;Data security;Green products;Companies;IEEE Standards;Regulation,data governance;environmental factors;ethical aspects;IEEE standards;law;public administration;security of data;sustainable development,sustainable digitalization;digitization initiatives;legal regulations;data security;data governance;digital strategy;peripheral components;justice;environmental sustainability;Fribourg sustainable digital ethics framework;sustainable development;ethical digitalization;data handling;law;regulations;ethics;FSDEF;value-based engineering;IEEE standards;public institutions;private companies,,2.0,20.0,IEEE,13 Sep 2021,IEEE,0.1925465838509316,1.25,0.375,0.2505032957755626
1,1.0,service,1.0,1.0,AI Ethics in Smart Healthcare,IEEE Consumer Electronics Magazine,12,4.0,10.1109/MCE.2022.3220001,S. Pasricha,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940606,IEEE Magazines,"This article reviews the landscape of ethical challenges of integrating artificial intelligence (AI) into smart healthcare products, including medical electronic devices. Differences between traditional ethics in the medical domain and emerging ethical challenges with AI-driven healthcare are presented, particularly as they relate to transparency, bias, privacy, safety, responsibility, justice, and autonomy. Open challenges and recommendations are outlined to enable the integration of ethical principles into the design, validation, clinical trials, deployment, monitoring, repair, and retirement of AI-based smart healthcare products.",,"Colorado State University, Fort Collins, CO, USA",6 Jun 2023,,,12.0,20.0,2162-2256,,National Science Foundation(grant numbers:CNS-2132385); ,Artificial intelligence;Ethics;Medical services;Medical diagnostic imaging;Consumer electronics;Behavioral sciences;Safety,artificial intelligence;ethical aspects;health care,AI ethics;AI-based smart healthcare products;AI-driven healthcare;artificial intelligence;ethical principles;medical domain;medical electronic devices,,,38.0,IEEE,7 Nov 2022,IEEE,0.2,0.0,0.6,0.217339312406577
2,6.0,service,6.0,6.0,AI Ethics Impact Assessment based on Requirement Engineering,2022 IEEE 30th International Requirements Engineering Conference Workshops (REW),,,10.1109/REW56159.2022.00037,I. Nitta; K. Ohashi; S. Shiga; S. Onodera,2022.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9920150,IEEE Conferences,"This paper proposes a methodology for evaluating the ethical impact of artificial intelligence (AI) systems on people and society based on AI ethics guidelines. The ethical impact of AI has been recognized as a social issue, and countries and organizations have formulated principles and guidelines on AI ethics, and laws and regulations will be enforced in Europe. Because these principles and guidelines are written in terms of philosophy and law, AI service providers, developers, and business users have the challenge of how they should practice the principles and guidelines to their AI systems. To address this challenge, we first analyzed cases of ethical problems caused by AI in the past and assumed that ethical problems could be linked to interactions between components of AI systems and stakeholders related to such systems. On the basis of this assumption, we then developed a methodology to comprehensively extract the ethical risks that an AI system poses. This methodology consists of two approaches. The first approach is to develop an AI ethics model that embodies ethics guidelines as necessary requirements for ethical AI systems and correlates these requirements with interactions. The second approach is an impact assessment process that uses the AI ethics models to extract ethical risks for individual AI systems. In this paper, we discuss the details of this methodology and show the results of an initial validation to verify the above assumption and the ease of the impact assessment process.",AI ethics;AI governance;responsible AI;impact assessment;risk-based approach,"Fujitsu Limited, Kawasaki, Japan; Fujitsu Limited, Kawasaki, Japan; Fujitsu Limited, Kawasaki, Japan; Fujitsu Limited, Kawasaki, Japan",20 Oct 2022,,,152.0,161.0,2770-6834,978-1-6654-6000-2,Stanford University; ,Ethics;Philosophical considerations;Conferences;Europe;Organizations;Regulation;Requirements engineering,artificial intelligence;ethical aspects,artificial intelligence systems;AI ethics guidelines;AI service providers;ethical risks;ethical AI systems;AI ethics impact assessment;requirement engineering,,2.0,27.0,IEEE,20 Oct 2022,IEEE,0.1841004184100418,0.1666666666666666,0.375,0.1902169701992332
3,7.0,service,7.0,7.0,Exploring Approaches to Artificial Intelligence Governance: From Ethics to Policy,"2023 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)",,,10.1109/ETHICS57328.2023.10155067,D. Kim; Q. Zhu; H. Eldardiry,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155067,IEEE Conferences,"There has been a trend among various stakeholders for AI governance, such as the government, industry, and academia, that advocates for a shift from AI ethics to AI policy. In this paper, we briefly introduce the motivation for such a change and two complementary reports about AI ethics policy development to help AI ethics researchers operationalize abstract AI ethics principles into actionable policy items. We also discuss the implications of the policy approach to AI governance for training the next generation of AI professionals.",AI Governance;AI Policy;AI Ethics;Responsible AI;AI Education,"Department of Engineering Education, Virginia Tech, Blacksburg, USA; Department of Engineering Education, Virginia Tech, Blacksburg, USA; Department of Computer Science, Virginia Tech, Blacksburg, USA",23 Jun 2023,,,1.0,5.0,,978-1-6654-5713-2,,Training;Industries;Ethics;Government;Market research;Stakeholders;Artificial intelligence,artificial intelligence;ethical aspects,abstract AI ethics principles;actionable policy items;AI ethics policy development;AI ethics researchers;AI governance;AI policy;AI professionals;artificial intelligence governance;government;policy approach,,,21.0,IEEE,23 Jun 2023,IEEE,0.1904761904761904,0.1666666666666666,0.2,0.1894747899159664
4,12.0,service,12.0,12.0,The Contestation of Tech Ethics: A Sociotechnical Approach to Technology Ethics in Practice,Journal of Social Computing,2,3.0,10.23919/JSC.2021.0018,B. Green,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684741,TUP Journals,"This article introduces the special issue “Technology Ethics in Action: Critical and Interdisciplinary Perspectives”. In response to recent controversies about the harms of digital technology, discourses and practices of “tech ethics” have proliferated across the tech industry, academia, civil society, and government. Yet despite the seeming promise of ethics, tech ethics in practice suffers from several significant limitations: tech ethics is vague and toothless, has a myopic focus on individual engineers and technology design, and is subsumed into corporate logics and incentives. These limitations suggest that tech ethics enables corporate “ethics-washing”: embracing the language of ethics to defuse criticism and resist government regulation, without committing to ethical behavior. Given these dynamics, I describe tech ethics as a terrain of contestation where the central debate is not whether ethics is desirable, but what “ethics” entails and who gets to define it. Current approaches to tech ethics are poised to enable technologists and technology companies to label themselves as “ethical” without substantively altering their practices. Thus, those striving for structural improvements in digital technologies must be mindful of the gap between ethics as a mode of normative inquiry and ethics as a practical endeavor. In order to better evaluate the opportunities and limits of tech ethics, I propose a sociotechnical approach that analyzes tech ethics in light of who defines it and what impacts it generates in practice.",technology ethics;AI ethics;ethics-washing;Science;Technology;and Society (STS);sociotechnical systems,"Society of Fellows and the Gerald R. Ford School of Public Policy, University of Michigan, Ann Arbor, MI, USA",18 Jan 2022,,,209.0,225.0,2688-5255,,,Ethics;Social computing;Special issues and sections;Law;Government;Resists;Regulation,ethical aspects;organisational aspects,technology ethics;digital technology;corporate logics;ethics-washing;government regulation,,22.0,165.0,,18 Jan 2022,TUP,0.1769911504424778,0.0,0.3076923076923077,0.1734452137496752
5,13.0,service,13.0,13.0,An Overview of Artificial Intelligence Ethics,IEEE Transactions on Artificial Intelligence,4,4.0,10.1109/TAI.2022.3194503,C. Huang; Z. Zhang; B. Mao; X. Yao,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844014,IEEE Journals,"Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This article will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, and methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.",Artificial intelligence (AI);AI ethics;ethical issue;ethical theory;ethical principle,"Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China; Trustworthiness Theory Research Center, Huawei Technologies Company, Ltd., Shenzhen, China; Trustworthiness Theory Research Center, Huawei Technologies Company, Ltd., Shenzhen, China; Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China",21 Jul 2023,,,799.0,819.0,2691-4581,,Research Institute of Trustworthy Autonomous Systems; Guangdong Provincial Key Laboratory(grant numbers:2020B121201001); Program for Guangdong Introducing Innovative and Enterpreneurial Teams(grant numbers:2017ZT07X386); Shenzhen Science and Technology Program(grant numbers:KQTD2016112514355531); Huawei and Southern University of Science and Technology(grant numbers:FA2019061021); ,Artificial intelligence;Ethics;Guidelines;Privacy;Government;Systematics;Security,artificial intelligence;data privacy;ethical aspects;industrial robots;Internet,AI ethics;AI systems;artificial intelligence ethics;ethical concerns;ethical guidelines;ethical issues;ethical risks,,9.0,155.0,CCBY,28 Jul 2022,IEEE,0.1756756756756756,0.0,0.3333333333333333,0.1707678248066476
6,15.0,service,15.0,15.0,A Case Study of Privacy Protection Challenges and Risks in AI-Enabled Healthcare App,2023 IEEE Conference on Artificial Intelligence (CAI),,,10.1109/CAI54212.2023.00132,P. Wang; H. Zare,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195065,IEEE Conferences,"Artificial intelligence (AI) is increasingly used in healthcare systems and applications (apps) with questions and debates on ethical issues and privacy risks. This research study explores and discusses the ethical challenges, privacy risks, and possible solutions related to protecting user data privacy in AI-enabled healthcare apps. The study is based on the healthcare app named Charlie in one of the fictional case studies designed by Princeton University to elucidate critical thinking and discussions on emerging ethical issues embracing AI.",AI;healthcare;ethics;privacy;security;risks,"Department of Computer Information Systems, Robert Morris University, Pittsburgh, USA; Bloomberg School of Public Health, Johns Hopkins University, Baltimore, USA",2 Aug 2023,,,296.0,297.0,,979-8-3503-3984-0,National Science Foundation; ,Privacy;Ethics;Data privacy;Medical services;Artificial intelligence;Guidelines,artificial intelligence;data privacy;ethical aspects;health care,AI-enabled healthcare app;artificial intelligence;ethical challenges;ethical issues;fictional case studies;healthcare systems;privacy protection challenges;privacy risks;research study explores;user data privacy,,,14.0,IEEE,2 Aug 2023,IEEE,0.189873417721519,0.0,0.0769230769230769,0.163721735367305
7,16.0,service,16.0,16.0,"Bridging Industry, Government, and Academia for Socially Responsible AI: The CSEAI Initiative","2023 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)",,,10.1109/ETHICS57328.2023.10155071,P. Rivas; J. Ortiz; D. A. Díaz-Pachón; L. N. Montoya,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155071,IEEE Conferences,"The mission of the Center for Standards and Ethics in Artificial Intelligence (CSEAI) is to promote safe, effective, and ethical AI standards through research, outreach, and education in partnership with industry and government. We briefly discuss CSEAI's workforce development plan, including mentoring undergraduate and graduate students and providing continuing education for industry professionals. The CSEAI aims to facilitate the production of standardized, ethical AI products that are safe for users and promote diversity in the field. By underscoring the importance of socially responsible innovation and ethical standards in AI, we show the CSEAI's aims to protect consumers and increase trust in responsible AI products and services.",responsible AI;AI ethics standards,"Industry-University Cooperative Research Center for Standards and Ethics in Artificial Intelligence, Baylor University, Rutgers University, The University of Miami, Accel AI Institute; Industry-University Cooperative Research Center for Standards and Ethics in Artificial Intelligence, Baylor University, Rutgers University, The University of Miami, Accel AI Institute; Industry-University Cooperative Research Center for Standards and Ethics in Artificial Intelligence, Baylor University, Rutgers University, The University of Miami, Accel AI Institute; Industry-University Cooperative Research Center for Standards and Ethics in Artificial Intelligence, Baylor University, Rutgers University, The University of Miami, Accel AI Institute",23 Jun 2023,,,1.0,1.0,,978-1-6654-5713-2,NSF(grant numbers:CNS-2136961); ,Industries;Ethics;Technological innovation;Government;Education;Production;Mentoring,artificial intelligence;ethical aspects;further education;government policies,center for standards and ethics in artificial intelligence;continuing education;CSEAI initiative;CSEAI workforce development plan;ethical AI standard;government;industry professional;socially responsible AI;socially responsible innovation;undergraduate student,,,4.0,IEEE,23 Jun 2023,IEEE,0.1509433962264151,0.5,0.0833333333333333,0.157350042241622
8,17.0,service,17.0,17.0,A Quantitative Model for the Assessment of Ethics Risks in Information Technology,"2023 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)",,,10.1109/ETHICS57328.2023.10155002,G. Rafaiani; G. Barchiesi; L. Ilari; M. Baldi; B. Giovanola,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155002,IEEE Conferences,"The management of sensitive and personal data in the healthcare sector must guarantee the widest respect of patients' fundamental rights. However, some quantitative evaluation framework for assessing the level of ethical compliance of a technology to the most important ethical principles is still missing. In this work, we first provide a model to quantitatively assess constitutive ethics, i.e., the intrinsic ethical compliance of a technology. Secondly, we propose a method for quantitatively assessing circumstantial ethics risks of a technology, when used in some specific context. Our ethics risk assessment model is based on the evaluation of the compliance of the technology to a defined set of controls about some ethical principles and about the robustness of the technological infrastructure underneath. Then, we validate our model by applying it to some recent healthrelated blockchain frameworks, and we compare a qualitative ethical assessment with the quantitative assessment made with the proposed model for constitutive ethics compliance. Through our assessment, we identify some technical choices that achieve the highest ethical scores, such as using a permissioned blockchain, off-chain storage, and encryption of data. Finally, we observe that the principles of privacy and data governance turn out to be the most satisfied ethical principles, contrary to fairness.",Ethics;Risk Assessment;Ethics by design;Privacy;Blockchain;Information Technology,"Department of Information Engineering, Marche Polytechnic University, Ancona, Italy; Department of Information Engineering, Marche Polytechnic University, Ancona, Italy; Department of Political Sciences, Communication, and International Relations, University of Macerata, Macerata, Italy; Department of Information Engineering, Marche Polytechnic University, Ancona, Italy; Department of Political Sciences, Communication, and International Relations, University of Macerata, Macerata, Italy",23 Jun 2023,,,1.0,8.0,,978-1-6654-5713-2,,Ethics;Analytical models;Protocols;Statistical analysis;Organizations;Probability;Data models,blockchains;data privacy;ethical aspects;health care;risk management,assessment model;circumstantial ethics risks;constitutive ethics compliance;data governance;ethical principles;ethical scores;ethics risk assessment model;health-related blockchain frameworks;healthcare sector;information technology;intrinsic ethical compliance;patients;personal data;privacy;qualitative ethical assessment;quantitative assessment;quantitative evaluation framework;technological infrastructure,,,31.0,IEEE,23 Jun 2023,IEEE,0.1625615763546798,0.0,0.1666666666666666,0.1542756012936997
9,22.0,service,22.0,22.0,"Peer Support Specialists and Service Users’ Perspectives on Privacy, Confidentiality, and Security of Digital Mental Health",IEEE Pervasive Computing,21,2.0,10.1109/MPRV.2022.3141986,M. D. Venegas; J. M. Brooks; A. L. Myers; M. Storm; K. L. Fortuna,2022.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723457,IEEE Magazines,"As the digitalization of mental health systems progresses, the ethical and social debate on the use of these mental health technologies has seldom been explored among end-users. This article explores how service users (e.g., patients and users of mental health services) and peer support specialists understand and perceive issues of privacy, confidentiality, and security of digital mental health interventions. Semi-structured qualitative interviews were conducted among service users (n = 17) and peer support specialists (n = 15) from a convenience sample at an urban community mental health center in the United States. We identified technology ownership and use, lack of technology literacy including limited understanding of privacy, confidentiality, and security as the main barriers to engagement among service users. Peers demonstrated a high level of technology engagement, literacy of digital mental health tools, and a more comprehensive awareness of digital mental health ethics. We recommend peer support specialists as a potential resource to facilitate the ethical engagement of digital mental health interventions for service users. Finally, engaging potential end-users in the development cycle of digital mental health support platforms and increased privacy regulations may lead the field to a better understanding of effective uses of technology for people with mental health conditions. This study contributes to the ongoing debate of digital mental health ethics, data justice, and digital mental health by providing a first-hand experience of digital ethics from end-users’ perspectives.",,"Department of Veterans Affairs GRECC, Bedford, VA, USA; University of Wisconsin-Madison, Madison, WI, USA; Rivier University, Nashua, NH, USA; University of Stavanger, Stavanger, Norway; Dartmouth College, Hanover, NH, USA",7 Jul 2022,,,41.0,50.0,1558-2590,,National Institute of Mental Health(grant numbers:K01MH117496); ,Mental health;Interviews;Privacy;Security;Ethics;Social networking (online);Codes,behavioural sciences computing;data privacy;ethical aspects;health care;medical computing;patient treatment,digital ethics;mental health conditions;digital mental health support platforms;potential end-users;digital mental health ethics;digital mental health tools;technology engagement;urban community mental health center;digital mental health interventions;support specialists understand;mental health services;mental health technologies;mental health systems progresses;digitalization;confidentiality;privacy;service users;peer support specialists,,1.0,31.0,USGov,1 Mar 2022,IEEE,0.1428571428571428,0.0,0.1875,0.1460220255249073
10,24.0,service,24.0,24.0,"Dealing with Ethics, Privacy, and Security",Reimagining Businesses with AI,,,10.1002/9781119709183.ch12,S. Sinha; K. Al Huraimel,2021.0,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9821896.pdf&bkn=9820895&pdfType=chapter,Wiley Data and Cybersecurity eBook Chapters,"This chapter broadens the horizon about ethics, data privacy, and cybersecurity in businesses. It gives practical guidance on how to build barriers against threats. In the age of artificial intelligence (AI), ethics has attained a completely different level of significance and debate. The chapter discusses some of the key issues to consider around ethics and AI, including artificial stupidity and data trustworthiness. Privacy starts with data ownership. The General Data Protection Regulation (GDPR) has stringent stipulations around the various rights of individuals around the personal data. It brings personal data into a complex and protective regulatory regime. AI programs have increased vulnerabilities because there are more difficult‐to‐identify places to inject and bury threat vectors. The chapter provides information on cybersecurity assurance practices and industry standards for cybersecurity compliance. AI is also a great tool for identifying cyber‐threats. This is one of the biggest emerging applications of AI techniques.",,NA; NA,,,,193.0,206.0,,9781119709176,,Artificial intelligence;Ethics;Business;Privacy;Economics;Training;Decision making,,,,,,,12 Jul 2022,Wiley,0.1283783783783783,0.0,0.5,0.1427372634824336
11,25.0,service,25.0,25.0,A Study on the Development of Digital literacy Diagnosis Tool for Lifelong Education Institutions,"2021 21st ACIS International Winter Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Winter)",,,10.1109/SNPDWinter52325.2021.00025,C. -J. Lee; S. -W. Choi,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9403504,IEEE Conferences,"It is an era in which the level of national digital literacy is the adaptability and competitiveness of the future society. In line with these times, studies on various literacy education and programs are being actively conducted in the field of lifelong education. However most of them are fragmentary event education or one-time programs. It is difficult to say that it is an education for continuous improvement of digital literacy capabilities.Lifelong education institutions need educational programs and teachers that able to not onlyutilize ICT but also communicate through digital, exchange information and creatively construct newly accepted information. For this it is necessary to measure the digital literacy competency and level of lifelong education teachers to properly recognize the digital literacy competency required for their job.They can continually develop and test their digital literacy capabilities by repeating these measurements, This study aims to present a methodology for developing competency diagnosis tools in the categories of digital ethics, digital competence, and digital application according to the education association's digital literacy framework.",Digital literacy;Diagnosis Tool;Lifelong Education Institutions;Digital Ethic;Digital Ability,"Department of Lifelong Education, Soongsil University, Seoul, Korea; Department of Lifelong Education, Soongsil University, Seoul, Korea",16 Apr 2021,,,84.0,86.0,,978-1-6654-1843-0,,Ethics;Education;Tools;Real-time systems;Reliability;Smart devices;Software engineering,computer aided instruction;computer literacy;continuing professional development;educational institutions;ethical aspects,digital literacy diagnosis tool;lifelong education institutions;national digital literacy;literacy education;fragmentary event education;one-time programs;educational programs;digital literacy competency;lifelong education teachers;competency diagnosis tools;digital ethics;digital competence;education association;continuous improvement;ICT,,,12.0,IEEE,16 Apr 2021,IEEE,0.1301775147928994,0.2857142857142857,0.1428571428571428,0.1415588372134364
