,Unnamed: 0.2,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,Author Affiliations,Date Added To Xplore,Unnamed: 13,Unnamed: 14,Start Page,End Page,ISSN,ISBNs,Funding Information,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Reference Count,License,Online Date,Publisher,Eligibility_Abstract_Score,Eligibility_Keywords_Score,Eligibility_Title_Score,Eligibility_Score
0,0.0,0.0,0.0,An Integrated Framework for Ethical and Sustainable Digitalization,2021 Eighth International Conference on eDemocracy & eGovernment (ICEDEG),,,10.1109/ICEDEG52154.2021.9530972,I. Wallimann-Helmer; L. Terán; E. Portmann; H. Schübel; J. Pincay,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530972,IEEE Conferences,"Dynamically developing digitization initiatives among public institutions and private companies necessitate a balanced approach to digital ethics. Several frameworks and legal regulations have been adopted to clarify and define the various ethical challenges in digital contexts. These initiatives often accentuate one of three components: data security, data governance, or digital strategy. However, an integrated approach is required to meet the current demand for an ethical and sustainable approach to digitalization and address the growing number of challenges occurring in handling data and related peripheral components. This paper develops the concept of an integrated framework to incorporate all relevant aspects of digital ethics by combining three categories of digital contexts: law and regulations, ethics and justice, and environmental sustainability. The core of this integrated framework, the Fribourg sustainable digital ethics framework (FSDEF), consists of two boundary conditions of sustainable development: social thresholds of justice and ecological planetary boundaries. It also incorporates numerous other frameworks and standards, including value-based engineering and IEEE standards.",Digital ethics;sustainability;corporate digital responsibility,"UniFR_ESH Institute, University of Fribourg, Fribourg, Switzerland; Human-IST Insitute, University of Fribourg, Fribourg, Switzerland; Human-IST Insitute, University of Fribourg, Fribourg, Switzerland; UniFR_ESH Institute, University of Fribourg, Fribourg, Switzerland; Human-IST Insitute, University of Fribourg, Fribourg, Switzerland",13 Sep 2021,,,156.0,162.0,2573-1998,978-1-6654-2512-4,,Ethics;Law;Data security;Green products;Companies;IEEE Standards;Regulation,data governance;environmental factors;ethical aspects;IEEE standards;law;public administration;security of data;sustainable development,sustainable digitalization;digitization initiatives;legal regulations;data security;data governance;digital strategy;peripheral components;justice;environmental sustainability;Fribourg sustainable digital ethics framework;sustainable development;ethical digitalization;data handling;law;regulations;ethics;FSDEF;value-based engineering;IEEE standards;public institutions;private companies,,2.0,20.0,IEEE,13 Sep 2021,IEEE,0.1925465838509316,1.25,0.375,0.2505032957755626
1,1.0,1.0,1.0,AI Ethics in Smart Healthcare,IEEE Consumer Electronics Magazine,12,4.0,10.1109/MCE.2022.3220001,S. Pasricha,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940606,IEEE Magazines,"This article reviews the landscape of ethical challenges of integrating artificial intelligence (AI) into smart healthcare products, including medical electronic devices. Differences between traditional ethics in the medical domain and emerging ethical challenges with AI-driven healthcare are presented, particularly as they relate to transparency, bias, privacy, safety, responsibility, justice, and autonomy. Open challenges and recommendations are outlined to enable the integration of ethical principles into the design, validation, clinical trials, deployment, monitoring, repair, and retirement of AI-based smart healthcare products.",,"Colorado State University, Fort Collins, CO, USA",6 Jun 2023,,,12.0,20.0,2162-2256,,National Science Foundation(grant numbers:CNS-2132385); ,Artificial intelligence;Ethics;Medical services;Medical diagnostic imaging;Consumer electronics;Behavioral sciences;Safety,artificial intelligence;ethical aspects;health care,AI ethics;AI-based smart healthcare products;AI-driven healthcare;artificial intelligence;ethical principles;medical domain;medical electronic devices,,,38.0,IEEE,7 Nov 2022,IEEE,0.2,0.0,0.6,0.217339312406577
2,8.0,8.0,8.0,Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations,2021 International Conference on Platform Technology and Service (PlatCon),,,10.1109/PlatCon53246.2021.9680760,J. Bang; S. Kim; J. W. Nam; D. -G. Yang,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680760,IEEE Conferences,"AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.",conversational chatbot;ethical design;framework,"Electronics and Telecommunications Research Institute, Daejun, Republic of Korea; Ewha Womans University, Seoul, Republic of Korea; University of Science and Technology, Daejun, Republic of Korea; University of Science and Technology, Daejun, Republic of Korea",20 Jan 2022,,,1.0,5.0,,978-1-6654-1766-2,Korean National Police Agency; ,Ethics;Privacy;Systematics;Chatbots;Social factors;Stakeholders;Artificial intelligence,artificial intelligence;data privacy;ethical aspects;expert systems;law administration;natural language processing;software agents;virtual reality,ethical chatbot design;biased data;unethical conversations;AI technology;public service domains;private service domains;existing computing systems;AI systems;AI-based systems;AI ethics;privacy;ethical design guidelines;AI-based conversational chatbots,,7.0,33.0,IEEE,20 Jan 2022,IEEE,0.1842105263157894,0.0,0.3076923076923077,0.1874553779461243
3,9.0,9.0,9.0,Why Do Companies Employ Prohibited Unethical Artificial Intelligence Practices?,IEEE Transactions on Engineering Management,PP,99.0,10.1109/TEM.2023.3258686,M. Méndez-Suárez; M. d. l. M. de Obesso; O. C. Márquez; C. M. Palacios,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10084347,IEEE Early Access Articles,"In this article, we investigate the previously unstudied reasons why companies use prohibited artificial intelligence (AI) applications and are punished with large fines under the European General Data Protection Regulation (GDPR). Investigating and understanding why companies engage in such severe AI ethical malpractices is essential to correct them as they seriously jeopardize the future development of AI. Based on a sample of 34 companies, out of which 23 were sanctioned under GDPR due to severe violations of AI ethical principles and using fuzzy-set qualitative comparative analysis, this study demonstrates that to be an AI ethical company and comply with the GDPR regulation, it is necessary to have an AI ethical statement, have a very strong concern for information cybersecurity, and have to be based in a country considered ethical or monitor with care the behavior of the firm in countries with lower ethical standards. As a theoretical contribution, although some authors argue that AI ethical principles are useless, the present research introduces a new theoretical perspective by demonstrating cause–effect relationships between business configurations and AI ethical failures. In addition, the results have an important managerial relevance because they show that lack of an AI ethical statement is the most relevant condition that led to ethical misbehaviors.",Artificial intelligence (AI) ethics;General Data Protection Regulation (GDPR) compliance;fuzzy-set qualitative comparative analysis (fsQCA);prohibited ai practices,"ESIC University, ESIC Business and Marketing School, Madrid, Spain; ESIC University, ESIC Business and Marketing School, Madrid, Spain; ESIC University, ESIC Business and Marketing School, Madrid, Spain; ESIC University, ESIC Business and Marketing School, Madrid, Spain",,,,1.0,10.0,1558-0040,,ESIC University(grant numbers:1-M-2017); ,Ethics;Companies;Artificial intelligence;Regulation;Behavioral sciences;Security;General Data Protection Regulation,,,,3.0,,IEEE,28 Mar 2023,IEEE,0.1941747572815534,0.2,0.0,0.1853137404945239
4,12.0,12.0,12.0,The Contestation of Tech Ethics: A Sociotechnical Approach to Technology Ethics in Practice,Journal of Social Computing,2,3.0,10.23919/JSC.2021.0018,B. Green,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684741,TUP Journals,"This article introduces the special issue “Technology Ethics in Action: Critical and Interdisciplinary Perspectives”. In response to recent controversies about the harms of digital technology, discourses and practices of “tech ethics” have proliferated across the tech industry, academia, civil society, and government. Yet despite the seeming promise of ethics, tech ethics in practice suffers from several significant limitations: tech ethics is vague and toothless, has a myopic focus on individual engineers and technology design, and is subsumed into corporate logics and incentives. These limitations suggest that tech ethics enables corporate “ethics-washing”: embracing the language of ethics to defuse criticism and resist government regulation, without committing to ethical behavior. Given these dynamics, I describe tech ethics as a terrain of contestation where the central debate is not whether ethics is desirable, but what “ethics” entails and who gets to define it. Current approaches to tech ethics are poised to enable technologists and technology companies to label themselves as “ethical” without substantively altering their practices. Thus, those striving for structural improvements in digital technologies must be mindful of the gap between ethics as a mode of normative inquiry and ethics as a practical endeavor. In order to better evaluate the opportunities and limits of tech ethics, I propose a sociotechnical approach that analyzes tech ethics in light of who defines it and what impacts it generates in practice.",technology ethics;AI ethics;ethics-washing;Science;Technology;and Society (STS);sociotechnical systems,"Society of Fellows and the Gerald R. Ford School of Public Policy, University of Michigan, Ann Arbor, MI, USA",18 Jan 2022,,,209.0,225.0,2688-5255,,,Ethics;Social computing;Special issues and sections;Law;Government;Resists;Regulation,ethical aspects;organisational aspects,technology ethics;digital technology;corporate logics;ethics-washing;government regulation,,22.0,165.0,,18 Jan 2022,TUP,0.1769911504424778,0.0,0.3076923076923077,0.1734452137496752
5,13.0,13.0,13.0,An Overview of Artificial Intelligence Ethics,IEEE Transactions on Artificial Intelligence,4,4.0,10.1109/TAI.2022.3194503,C. Huang; Z. Zhang; B. Mao; X. Yao,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844014,IEEE Journals,"Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This article will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, and methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.",Artificial intelligence (AI);AI ethics;ethical issue;ethical theory;ethical principle,"Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China; Trustworthiness Theory Research Center, Huawei Technologies Company, Ltd., Shenzhen, China; Trustworthiness Theory Research Center, Huawei Technologies Company, Ltd., Shenzhen, China; Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China",21 Jul 2023,,,799.0,819.0,2691-4581,,Research Institute of Trustworthy Autonomous Systems; Guangdong Provincial Key Laboratory(grant numbers:2020B121201001); Program for Guangdong Introducing Innovative and Enterpreneurial Teams(grant numbers:2017ZT07X386); Shenzhen Science and Technology Program(grant numbers:KQTD2016112514355531); Huawei and Southern University of Science and Technology(grant numbers:FA2019061021); ,Artificial intelligence;Ethics;Guidelines;Privacy;Government;Systematics;Security,artificial intelligence;data privacy;ethical aspects;industrial robots;Internet,AI ethics;AI systems;artificial intelligence ethics;ethical concerns;ethical guidelines;ethical issues;ethical risks,,9.0,155.0,CCBY,28 Jul 2022,IEEE,0.1756756756756756,0.0,0.3333333333333333,0.1707678248066476
6,15.0,15.0,15.0,A Case Study of Privacy Protection Challenges and Risks in AI-Enabled Healthcare App,2023 IEEE Conference on Artificial Intelligence (CAI),,,10.1109/CAI54212.2023.00132,P. Wang; H. Zare,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195065,IEEE Conferences,"Artificial intelligence (AI) is increasingly used in healthcare systems and applications (apps) with questions and debates on ethical issues and privacy risks. This research study explores and discusses the ethical challenges, privacy risks, and possible solutions related to protecting user data privacy in AI-enabled healthcare apps. The study is based on the healthcare app named Charlie in one of the fictional case studies designed by Princeton University to elucidate critical thinking and discussions on emerging ethical issues embracing AI.",AI;healthcare;ethics;privacy;security;risks,"Department of Computer Information Systems, Robert Morris University, Pittsburgh, USA; Bloomberg School of Public Health, Johns Hopkins University, Baltimore, USA",2 Aug 2023,,,296.0,297.0,,979-8-3503-3984-0,National Science Foundation; ,Privacy;Ethics;Data privacy;Medical services;Artificial intelligence;Guidelines,artificial intelligence;data privacy;ethical aspects;health care,AI-enabled healthcare app;artificial intelligence;ethical challenges;ethical issues;fictional case studies;healthcare systems;privacy protection challenges;privacy risks;research study explores;user data privacy,,,14.0,IEEE,2 Aug 2023,IEEE,0.189873417721519,0.0,0.0769230769230769,0.163721735367305
7,17.0,17.0,17.0,A Quantitative Model for the Assessment of Ethics Risks in Information Technology,"2023 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)",,,10.1109/ETHICS57328.2023.10155002,G. Rafaiani; G. Barchiesi; L. Ilari; M. Baldi; B. Giovanola,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155002,IEEE Conferences,"The management of sensitive and personal data in the healthcare sector must guarantee the widest respect of patients' fundamental rights. However, some quantitative evaluation framework for assessing the level of ethical compliance of a technology to the most important ethical principles is still missing. In this work, we first provide a model to quantitatively assess constitutive ethics, i.e., the intrinsic ethical compliance of a technology. Secondly, we propose a method for quantitatively assessing circumstantial ethics risks of a technology, when used in some specific context. Our ethics risk assessment model is based on the evaluation of the compliance of the technology to a defined set of controls about some ethical principles and about the robustness of the technological infrastructure underneath. Then, we validate our model by applying it to some recent healthrelated blockchain frameworks, and we compare a qualitative ethical assessment with the quantitative assessment made with the proposed model for constitutive ethics compliance. Through our assessment, we identify some technical choices that achieve the highest ethical scores, such as using a permissioned blockchain, off-chain storage, and encryption of data. Finally, we observe that the principles of privacy and data governance turn out to be the most satisfied ethical principles, contrary to fairness.",Ethics;Risk Assessment;Ethics by design;Privacy;Blockchain;Information Technology,"Department of Information Engineering, Marche Polytechnic University, Ancona, Italy; Department of Information Engineering, Marche Polytechnic University, Ancona, Italy; Department of Political Sciences, Communication, and International Relations, University of Macerata, Macerata, Italy; Department of Information Engineering, Marche Polytechnic University, Ancona, Italy; Department of Political Sciences, Communication, and International Relations, University of Macerata, Macerata, Italy",23 Jun 2023,,,1.0,8.0,,978-1-6654-5713-2,,Ethics;Analytical models;Protocols;Statistical analysis;Organizations;Probability;Data models,blockchains;data privacy;ethical aspects;health care;risk management,assessment model;circumstantial ethics risks;constitutive ethics compliance;data governance;ethical principles;ethical scores;ethics risk assessment model;health-related blockchain frameworks;healthcare sector;information technology;intrinsic ethical compliance;patients;personal data;privacy;qualitative ethical assessment;quantitative assessment;quantitative evaluation framework;technological infrastructure,,,31.0,IEEE,23 Jun 2023,IEEE,0.1625615763546798,0.0,0.1666666666666666,0.1542756012936997
8,18.0,18.0,18.0,AI Ethics: Algorithmic Determinism or Self-Determination? The GPDR Approach,IEEE Access,9,,10.1109/ACCESS.2021.3072782,M. Milossi; E. Alexandropoulou-Egyptiadou; K. E. Psannis,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400809,IEEE Journals,"Artificial Intelligence (AI) refers to systems designed by humans, interpreting the already collected data and deciding the best action to take, according to the pre-defined parameters, in order to achieve the given goal. Designing, trial and error while using AI, brought ethics to the center of the dialogue between tech giants, enterprises, academic institutions as well as policymakers. Ethical challenges in AI brought ethical AI framework in place in an attempt to regulate people’s lives and interactions, used for the benefit of society, for the human rights’ protection as well as for the respect of individual’s privacy and autonomy. The paper aims to summarize and critically evaluate the basic principles for the use of AI, with emphasis to the General Data Protection Regulation’s (GDPR) approach, concerning data subject’s consent, data protection principles and data subject’s rights in a context of ‘privacy by design’ architecture.",AI;privacy;data protection;ethics;GDPR,"Department of Applied Informatics, School of Information Sciences, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, School of Information Sciences, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, School of Information Sciences, University of Macedonia, Thessaloniki, Greece",20 Apr 2021,,,58455.0,58466.0,2169-3536,,,Artificial intelligence;Ethics;Tools;Education;Prediction algorithms;Medical services,artificial intelligence;data protection;ethical aspects,ethical AI framework;human rights;General Data Protection Regulation;data protection principles;AI ethics;GPDR approach;artificial intelligence;pre-defined parameters,,5.0,60.0,CCBY,12 Apr 2021,IEEE,0.1458333333333333,0.0,0.3333333333333333,0.1538642789820923
9,19.0,19.0,19.0,AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers,IEEE Transactions on Computational Social Systems,PP,99.0,10.1109/TCSS.2023.3251729,A. A. Khan; M. A. Akbar; M. Fahmideh; P. Liang; M. Waseem; A. Ahmad; M. Niazi; P. Abrahamsson,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10066257,IEEE Early Access Articles,"Artificial intelligence (AI) solutions and technologies are being increasingly adopted in smart systems contexts; however, such technologies are concerned with ethical uncertainties. Various guidelines, principles, and regulatory frameworks are designed to ensure that AI technologies adhere to ethical well-being. However, the implications of AI ethics principles and guidelines are still being debated. To further explore the significance of AI ethics principles and relevant challenges, we conducted a survey of 99 randomly selected representative AI practitioners and lawmakers (e.g., AI engineers and lawyers) from 20 countries across five continents. To the best of our knowledge, this is the first empirical study that unveils the perceptions of two different types of population (AI practitioners and lawmakers) and the study findings confirm that transparency, accountability, and privacy are the most critical AI ethics principles. On the other hand, lack of ethical knowledge, no legal frameworks, and lacking monitoring bodies are found to be the most common AI ethics challenges. The impact analysis of the challenges across principles reveals that conflict in practice is a highly severe challenge. Moreover, the perceptions of practitioners and lawmakers are statistically correlated with significant differences for particular principles (e.g. fairness and freedom) and challenges (e.g. lacking monitoring bodies and machine distortion). Our findings stimulate further research, particularly empowering existing capability maturity models to support ethics-aware AI systems’ development and quality assessment.",Accountable artificial intelligence;Artificial intelligence (AI);AI ethics;AI ethics principles;challenges;machine ethics,"M3S. Empirical Software Engineering Research Unit, University of Oulu, Oulu, Finland; Software Engineering Department, Lappeenranta-Lahti University of Technology, Lappeenranta, Finland; School of Business, University of Southern Queensland, Toowoomba, QLD, Australia; School of Computer Science, Wuhan University, Wuhan, China; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; School of Computing and Communications, Lancaster University Leipzig, Leipzig, Germany; Department of Information and Computer Science, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland",,,,1.0,14.0,2329-924X,,,Artificial intelligence;Ethics;Guidelines;Industries;Instruments;Statistics;Sociology,,,,3.0,,CCBY,10 Mar 2023,IEEE,0.1255605381165919,0.4444444444444444,0.25,0.1517523147007451
10,20.0,20.0,20.0,Imagine a More Ethical AI: Using Stories to Develop Teens' Awareness and Understanding of Artificial Intelligence and its Societal Impacts,"2021 Conference on Research in Equitable and Sustained Participation in Engineering, Computing, and Technology (RESPECT)",,,10.1109/RESPECT51740.2021.9620549,S. Forsyth; B. Dalton; E. H. Foster; B. Walsh; J. Smilack; T. Yeh,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9620549,IEEE Conferences,"Artificial intelligence (AI) tools and technologies are increasingly prevalent in society. Many teens interact with AI devices on a daily basis but often have a limited understanding of how AI works, as well as how it impacts society more broadly. It is critical to develop youths' understanding of AI, cultivate ethical awareness, and support diverse youth in pursuing computer science to help ensure future development of more equitable AI technologies. Here, we share our experiences developing and remotely facilitating an interdisciplinary AI ethics program for secondary students designed to increase teens' awareness and understanding of AI and its societal impacts. Students discussed stories with embedded ethical dilemmas, engaged with AI media and simulations, and created digital products to express their stance on an AI ethics issue. Across four iterations in formal and informal settings, we found students to be engaged in AI stories and invested in learning about AI and its societal impacts. Short stories were effective in raising awareness, focusing discussion and supporting students in developing a more nuanced understanding of AI ethics issues, such as fairness, bias and privacy.",artificial intelligence (AI);machine learning;ethics,"CU Science Discovery, University of Colorado Boulder, Boulder, CO; School of Education, University of Colorado Boulder, Boulder, CO; School of Education, University of Colorado Boulder, Boulder, CO; School of Education, University of Colorado Boulder, Boulder, CO; School of Education, University of Colorado Boulder, Boulder, CO; Department of Computer Science, University of Colorado Boulder, Boulder, CO",30 Nov 2021,,,1.0,2.0,,978-1-6654-4905-2,National Science Foundation(grant numbers:1934151); ,Computer science;Ethics;Privacy;Education;Focusing;Learning (artificial intelligence);Tools,artificial intelligence;ethical aspects;social aspects of automation,ethical AI;artificial intelligence;societal impacts;AI devices;AI works;cultivate ethical awareness;equitable AI technologies;interdisciplinary AI ethics program;embedded ethical dilemmas;AI ethics issue;AI stories;nuanced understanding,,4.0,8.0,IEEE,30 Nov 2021,IEEE,0.149171270718232,0.0,0.2,0.148638601108143
11,22.0,22.0,22.0,"Peer Support Specialists and Service Users’ Perspectives on Privacy, Confidentiality, and Security of Digital Mental Health",IEEE Pervasive Computing,21,2.0,10.1109/MPRV.2022.3141986,M. D. Venegas; J. M. Brooks; A. L. Myers; M. Storm; K. L. Fortuna,2022.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723457,IEEE Magazines,"As the digitalization of mental health systems progresses, the ethical and social debate on the use of these mental health technologies has seldom been explored among end-users. This article explores how service users (e.g., patients and users of mental health services) and peer support specialists understand and perceive issues of privacy, confidentiality, and security of digital mental health interventions. Semi-structured qualitative interviews were conducted among service users (n = 17) and peer support specialists (n = 15) from a convenience sample at an urban community mental health center in the United States. We identified technology ownership and use, lack of technology literacy including limited understanding of privacy, confidentiality, and security as the main barriers to engagement among service users. Peers demonstrated a high level of technology engagement, literacy of digital mental health tools, and a more comprehensive awareness of digital mental health ethics. We recommend peer support specialists as a potential resource to facilitate the ethical engagement of digital mental health interventions for service users. Finally, engaging potential end-users in the development cycle of digital mental health support platforms and increased privacy regulations may lead the field to a better understanding of effective uses of technology for people with mental health conditions. This study contributes to the ongoing debate of digital mental health ethics, data justice, and digital mental health by providing a first-hand experience of digital ethics from end-users’ perspectives.",,"Department of Veterans Affairs GRECC, Bedford, VA, USA; University of Wisconsin-Madison, Madison, WI, USA; Rivier University, Nashua, NH, USA; University of Stavanger, Stavanger, Norway; Dartmouth College, Hanover, NH, USA",7 Jul 2022,,,41.0,50.0,1558-2590,,National Institute of Mental Health(grant numbers:K01MH117496); ,Mental health;Interviews;Privacy;Security;Ethics;Social networking (online);Codes,behavioural sciences computing;data privacy;ethical aspects;health care;medical computing;patient treatment,digital ethics;mental health conditions;digital mental health support platforms;potential end-users;digital mental health ethics;digital mental health tools;technology engagement;urban community mental health center;digital mental health interventions;support specialists understand;mental health services;mental health technologies;mental health systems progresses;digitalization;confidentiality;privacy;service users;peer support specialists,,1.0,31.0,USGov,1 Mar 2022,IEEE,0.1428571428571428,0.0,0.1875,0.1460220255249073
12,24.0,24.0,24.0,"Dealing with Ethics, Privacy, and Security",Reimagining Businesses with AI,,,10.1002/9781119709183.ch12,S. Sinha; K. Al Huraimel,2021.0,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9821896.pdf&bkn=9820895&pdfType=chapter,Wiley Data and Cybersecurity eBook Chapters,"This chapter broadens the horizon about ethics, data privacy, and cybersecurity in businesses. It gives practical guidance on how to build barriers against threats. In the age of artificial intelligence (AI), ethics has attained a completely different level of significance and debate. The chapter discusses some of the key issues to consider around ethics and AI, including artificial stupidity and data trustworthiness. Privacy starts with data ownership. The General Data Protection Regulation (GDPR) has stringent stipulations around the various rights of individuals around the personal data. It brings personal data into a complex and protective regulatory regime. AI programs have increased vulnerabilities because there are more difficult‐to‐identify places to inject and bury threat vectors. The chapter provides information on cybersecurity assurance practices and industry standards for cybersecurity compliance. AI is also a great tool for identifying cyber‐threats. This is one of the biggest emerging applications of AI techniques.",,NA; NA,,,,193.0,206.0,,9781119709176,,Artificial intelligence;Ethics;Business;Privacy;Economics;Training;Decision making,,,,,,,12 Jul 2022,Wiley,0.1283783783783783,0.0,0.5,0.1427372634824336
13,27.0,27.0,27.0,AI Digital Tool Product Lifecycle Governance Framework through Ethics and Compliance by Design†,2023 IEEE Conference on Artificial Intelligence (CAI),,,10.1109/CAI54212.2023.00155,E. Ortega; M. Tran; G. Bandeen,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195137,IEEE Conferences,"The acceleration of Artificial Intelligence (AI) has brought forward new digital tools that have had a wide impact across society. However, AI digital tools (such as ChatGPT, midjourney, DALL-E 2) have brought forward legal and ethical concerns. — Internationally, public, and private leaders are introducing regulatory frameworks to address data governance for such these AI digital tools (i.e., Global Data Protection Regulation, the European AI Act, Blueprint for an AI Bill of Rights, NIST Risk Management Framework, etc.). We recognize that these AI digital tools are a vital aspect of future technological development, but they require input from various sectors in addressing ethics and compliance design. We survey the current landscape of published AI-specific regulatory frameworks and known engineering design process methods. Using a product lifecycle approach, we also introduce a trans-disciplinary framework to address AI ethics and compliance via design. This product lifecycle approach considers several principles: a Human-Centered Design for Risk Assessment, Functional Safety and Risk Management Standardization, and Continuous Governance throughout Product Lifecycle. Establishing risk management throughout AI product lifecycles can ensure accountability for AI product use cases. In addition, by utilizing previous Functional Safety considerations we can create safety mechanisms throughout the product lifecycle of AI digital tools. Finally, establishing in-field testing for continuous governance will enable the flexibility for new compliance standards and transparency. We establish this governance framework to aid in new compliance strategies for these emerging issues with AI digital tools.",Ethics;Compliance;AI;Risk Management;Human-Centered-Design;Engineering Design Thinking,"Pratt School of Engineering, Duke University, Durham, NC, USA; The Graduate School, Duke University, Durham, NC, USA; School of Law, Duke University, Durham, NC, USA",2 Aug 2023,,,353.0,356.0,,979-8-3503-3984-0,,Surveys;Ethics;Law;NIST;Regulation;Safety;Risk management,artificial intelligence;data protection;ethical aspects;risk management,AI digital tool Product Lifecycle Governance Framework;AI digital tools;AI ethics;AI product lifecycles;AI product use cases;European AI Act;forward new digital tools;product lifecycle approach;published AI-specific,,,20.0,IEEE,2 Aug 2023,IEEE,0.134453781512605,0.0,0.3846153846153846,0.140872680557676
