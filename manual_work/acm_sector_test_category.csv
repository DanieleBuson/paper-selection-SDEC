,Unnamed: 0.2,Category,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,ISBN,ISSN,Date,Date Added,Date Modified,Pages,Series,Publisher,Key,Eligibility_Abstract_Score,Eligibility_Keywords_Score,Eligibility_Title_Score,Eligibility_Score
0,5.0,sector,6.0,6.0,AI Ethics - Critical Reflections on Embedding Ethical Frameworks in AI Technology,"Culture and Computing. Design Thinking and Cultural Computing: 9th International Conference, C&amp;C 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part II",,,10.1007/978-3-030-77431-8_20,"Salo-Pöntinen, Henrikki",2021.0,https://doi.org/10.1007/978-3-030-77431-8_20,conferencePaper,"Embedding ethical frameworks in artificial intelligence (AI) technologies has been a popular topic for academic research for the past decade [1–7]. The approaches of the studies differ in how AI technology, ethics, role of technical artefacts and socio-technical aspects of AI are perceived. In addition, most studies define insufficiently what the connection between the process of embedding ethical frameworks to AI technology and the larger framework of AI ethics is. These deficiencies have caused that the concept of AI ethics and the construct of embedding ethical parameters into AI are used in an ambiguous, rather than in a complementary manner.One reason for the ambiguity within this field of research is due to a lack of a comprehensive conceptual framework for AI ethics in general. I intend to fill this void by grounding AI ethics as a subfield of philosophy of technology and applied ethics and presenting its main issues of study by examining recognized spheres of activities through the method of levels of abstraction [8]. I put forward an initial hierarchical conceptual framework for AI ethics as an outcome. After this, I discuss the connection between the process of embedding ethical frameworks in AI and the larger AI ethics framework, leading to presenting basic requirements for the sphere of activity hereafter known as embedded ethics.",AI ethics; Applied ethics; Embedded ethics; Human-technology interaction,978-3-030-77430-1,,2021,2023-11-06 01:29:48,2023-11-06 01:29:48,311–329,,Springer-Verlag,T2JKNGZ8,0.1953488372093023,0.875,0.5833333333333334,0.2483228832916864
1,8.0,sector,10.0,10.0,"Operationalising AI Ethics: Barriers, Enablers and next Steps",AI Soc.,38.0,1,10.1007/s00146-021-01308-8,"Morley, Jessica; Kinsey, Libby; Elhalal, Anat; Garcia, Francesca; Ziosi, Marta; Floridi, Luciano",2021.0,https://doi.org/10.1007/s00146-021-01308-8,journalArticle,"By mid-2019 there were more than 80 AI ethics guides available in the public domain. Despite this, 2020 saw numerous news stories break related to ethically questionable uses of AI. In part, this is because AI ethics theory remains highly abstract, and of limited practical applicability to those actually responsible for designing algorithms and AI systems. Our previous research sought to start closing this gap between the ‘what’ and the ‘how’ of AI ethics through the creation of a searchable typology of tools and methods designed to translate between the five most common AI ethics principles and implementable design practices. Whilst a useful starting point, that research rested on the assumption that all AI practitioners are aware of the ethical implications of AI, understand their importance, and are actively seeking to respond to them. In reality, it is unclear whether this is the case. It is this limitation that we seek to overcome here by conducting a mixed-methods qualitative analysis to answer the following four questions: what do AI practitioners understand about the need to translate ethical principles into practice? What motivates AI practitioners to embed ethical principles into design practices? What barriers do AI practitioners face when attempting to translate ethical principles into practice? And finally, what assistance do AI practitioners want and need when translating ethical principles into practice?",AI ethics; Applied ethics; Business ethics; Ethical practices; Ethical principles,,0951-5666,2021-11,2023-11-06 01:29:48,2023-11-06 01:29:48,411–423,,,XQQGTU4X,0.1583710407239819,1.3,0.375,0.2250921974267562
2,14.0,sector,16.0,16.0,The State of Ethical AI in Practice: A Multiple Case Study of Estonian Public Service Organizations,Int. J. Technoethics,14.0,1,10.4018/IJT.322017,"Hinton, Charlene",2023.0,https://doi.org/10.4018/IJT.322017,journalArticle,"Despite the prolific introduction of ethical frameworks, empirical research on AI ethics in the public sector is limited. This empirical research investigates how the ethics of AI is translated into practice and the challenges of its implementation by public service organizations. Using the Value Sensitive Design as a framework of inquiry, semi-structured interviews are conducted with eight public service organizations across the Estonian government that have piloted or developed an AI solution for delivering a public service. Results show that the practical application of AI ethical principles is indirectly considered and demonstrated in different ways in the design and development of the AI. However, translation of these principles varies according to the maturity of the AI and the public servant's level of awareness, knowledge, and competences in AI. Data-related challenges persist as public service organizations work on fine-tuning their AI applications.",Ethics; Artificial Intelligence; AI Ethical Principles; Estonia; Ethical AI Design and Development; Practical Application of AI Ethics; Public Sector; Value Sensitive Design,,1947-3451,2023-04,2023-11-06 01:29:59,2023-11-06 01:29:59,1–15,,,3Z9FZKRF,0.1276595744680851,0.5909090909090909,0.25,0.2018186327252825
3,16.0,sector,18.0,18.0,Ethics of AI: A Systematic Literature Review of Principles and Challenges,Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering,,,10.1145/3530019.3531329,"Khan, Arif Ali; Badshah, Sher; Liang, Peng; Waseem, Muhammad; Khan, Bilal; Ahmad, Aakash; Fahmideh, Mahdi; Niazi, Mahmood; Akbar, Muhammad Azeem",2022.0,https://doi.org/10.1145/3530019.3531329,conferencePaper,"Ethics in AI becomes a global topic of interest for both policymakers and academic researchers. In the last few years, various research organizations, lawyers, think tankers, and regulatory bodies get involved in developing AI ethics guidelines and principles. However, there is still debate about the implications of these principles. We conducted a systematic literature review (SLR) study to investigate the agreement on the significance of AI principles and identify the challenging factors that could negatively impact the adoption of AI ethics principles. The results reveal that the global convergence set consists of 22 ethical principles and 15 challenges. Transparency, privacy, accountability and fairness are identified as the most common AI ethics principles. Similarly, lack of ethical knowledge and vague principles are reported as the significant challenges for considering ethics in AI. The findings of this study are the preliminary inputs for proposing a maturity model that assesses the ethical capabilities of AI systems and provides best practices for further improvements.",AI Ethics; Principles; Challenges; Machine Ethics; Systematic Literature Review,978-1-4503-9613-4,,2022,2023-11-06 01:29:55,2023-11-06 01:29:55,383–392,EASE '22,Association for Computing Machinery,JD9H6H5T,0.16875,0.5555555555555556,0.2727272727272727,0.1993418041683879
4,20.0,sector,22.0,22.0,A Literature Review on Digital Ethics from a Humanistic and Sustainable Perspective,Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance,,,10.1145/3494193.3494295,"Teran, Luis; Pincay, Jhonny; Wallimann-Helmer, Ivo; Portmann, Edy",2022.0,https://doi.org/10.1145/3494193.3494295,conferencePaper,"The rapid technological transition requires the adoptive approach to the digital conduct of public and private institutions. Countries and companies strive to integrate a balanced understanding of digital ethics and sustainability concepts from various standpoints, which results in a dispersed and uncategorized knowledge base. This work presents a literature review on digital ethics published from 2010 to 2020 in three technical libraries and one library maintained by the community of philosophers. The investigation process integrates a thorough review of digital ethics concepts in the leading academic libraries using keywords representing various concept applications. This study's outcome is a quantitative and sectorial categorization of works on digital ethics, followed by a holistic review of concepts, maturity level, and conclusions on each category. This work aims to understand the trends from a technological and philosophical perspective towards designing a sustainable digital ethical framework applied in digital services that fulfill sufficiency thresholds of justice and do not foster overshooting of planetary boundaries. The first version of a holistic framework based on the literature review is presented at the end of this work. It will be extended in future work.",digital ethics; ethical challenge; humanistic; literature review; sustainability,978-1-4503-9011-8,,2022,2023-11-06 01:29:48,2023-11-06 01:29:48,57–64,ICEGOV '21,Association for Computing Machinery,WG3RQG8Q,0.1397849462365591,0.875,0.3333333333333333,0.1912146992792153
5,22.0,sector,24.0,24.0,Ethical Framework for Artificial Intelligence and Digital Technologies,Int. J. Inf. Manag.,62.0,C,10.1016/j.ijinfomgt.2021.102433,"Ashok, Mona; Madan, Rohit; Joha, Anton; Sivarajah, Uthayasankar",2022.0,https://doi.org/10.1016/j.ijinfomgt.2021.102433,journalArticle,"The use of Artificial Intelligence (AI) in Digital technologies (DT) is proliferating a profound socio-technical transformation. Governments and AI scholarship have endorsed key AI principles but lack direction at the implementation level. Through a systematic literature review of 59 papers, this paper contributes to the critical debate on the ethical use of AI in DTs beyond high-level AI principles. To our knowledge, this is the first paper that identifies 14 digital ethics implications for the use of AI in seven DT archetypes using a novel ontological framework (physical, cognitive, information, and governance). The paper presents key findings of the review and a conceptual model with twelve propositions highlighting the impact of digital ethics implications on societal impact, as moderated by DT archetypes and mediated by organisational impact. The implications of intelligibility, accountability, fairness, and autonomy (under the cognitive domain), and privacy (under the information domain) are the most widely discussed in our sample. Furthermore, ethical implications related to the governance domain are shown to be generally applicable for most DT archetypes. Implications under the physical domain are less prominent when it comes to AI diffusion with one exception (safety). The key findings and resulting conceptual model have academic and professional implications.",Artificial Intelligence (AI) ethics; Digital ethics; Digital technologies and archetypes; Ontological framework; PRISMA; Systematic literature review,,0268-4012,2022-02,2023-11-06 01:29:50,2023-11-06 01:29:50,,,,RGCVHYXK,0.1243781094527363,0.5625,0.625,0.1866909628874262
6,24.0,sector,26.0,26.0,Trustworthy AI for the People?,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462470,"Figueras, Clàudia; Verhagen, Harko; Cerratto Pargman, Teresa",2021.0,https://doi.org/10.1145/3461702.3462470,conferencePaper,"While AI systems become more pervasive, their social impact is increasingly hard to measure. To help mitigate possible risks and guide practitioners into a more responsible design, diverse organizations have released AI ethics frameworks. However, it remains unclear how ethical issues are dealt with in the everyday practices of AI developers. To this end, we have carried an exploratory empirical study interviewing AI developers working for Swedish public organizations to understand how ethics are enacted in practice. Our analysis found that several AI ethics issues are not consistently tackled, and AI systems are not fully recognized as part of a broader sociotechnical system.",AI ethics in practice; AI in public organizations; citizen empowerment; responsible AI; responsible AI principles in practice; trustworthy AI,978-1-4503-8473-5,,2021,2023-11-06 01:29:49,2023-11-06 01:29:49,269–270,AIES '21,Association for Computing Machinery,4VB2H2EN,0.145631067961165,0.3684210526315789,0.2,0.1842344041757601
7,32.0,sector,35.0,35.0,A Study on the Modeling of Major Factors for the Principles of AI Ethics,DG.O2021: The 22nd Annual International Conference on Digital Government Research,,,10.1145/3463677.3463733,"Lim, Ji Hun; Kwon, Hun Yeong",2021.0,https://doi.org/10.1145/3463677.3463733,conferencePaper,"The fourth industrial revolution, centered on artificial intelligence (AI), signals a significant transformation in human society. For this social transformation to ultimately be for humankind's prosperity and happiness, serious consideration of AI ethics is needed. As a result, many countries have begun to establish AI ethics principles, and the international community is pushing for standardization on AI ethics principles. This study aims to derive general factors of ethical principles that should be considered to establish and standardize AI ethics principles. To this end, we present a ""general AI ethics principles model,"" including 12 major factors, based on the recently published AI ethics principles in 15 countries. Furthermore, the major factors for AI ethics principles that we derived through this study ultimately confirmed that AI should be useful to all humans and is oriented toward the value of building a ""Trustworthy"" AI society. Based on these fundamental ideologies, we confirmed that each factor interconnects with each other. It is hoped that the AI ethics principles model that reflects this will be referred to national and international communities that have yet to develop Principles of AI Ethics. However, Factors for AI ethics principles should be constructed following the principles' intent and goal orientation, ensuring its feasibility, rather than merely duplicating the principles model.",,978-1-4503-8492-6,,2021,2023-11-06 01:29:49,2023-11-06 01:29:49,208–218,DG.O'21,Association for Computing Machinery,CP5RISCE,0.1706161137440758,0.0,0.2142857142857142,0.1727108580738546
8,33.0,sector,36.0,36.0,The European Commission Report on Ethics of Connected and Automated Vehicles and the Future of Ethics of Transportation,Ethics and Inf. Technol.,23.0,4,10.1007/s10676-021-09609-8,"Santoni de Sio, Filippo",2021.0,https://doi.org/10.1007/s10676-021-09609-8,journalArticle,"The paper has two goals. The first is presenting the main results of the recent report Ethics of Connected and Automated Vehicles: recommendations on road safety, privacy, fairness, explainability and responsibility written by the Horizon 2020 European Commission Expert Group to advise on specific ethical issues raised by driverless mobility, of which the author of this paper has been member and rapporteur. The second is presenting some broader ethical and philosophical implications of these recommendations, and using these to contribute to the establishment of Ethics of Transportation as an independent&nbsp;branch of applied ethics. The recent debate on the ethics of Connected and Automated Vehicles (CAVs) presents a paradox and an opportunity. The paradox is the presence of a flourishing debate on the ethics of one very specific transportation technology without ethics of transportation being in itself a well-established academic discipline. The opportunity is that now that a spotlight has been switched on the ethical dimensions of CAVs it may be easier to establish a broader debate on ethics of transportation. While the 20 recommendations of the EU report are grouped in three macro-areas: road safety, data ethics, and responsibility, in this paper they will be grouped according to eight philosophical themes: Responsible Innovation, road justice, road safety, freedom, human control, privacy, data fairness, responsibility. These are proposed as the first topics for a new ethics of transportation.",Ethics of self-driving cars; Ethics of transportation; European Commission Report on ethics of CAVs; Responsible innovation in self-driving cars,,1388-1957,2021-12,2023-11-06 01:30:04,2023-11-06 01:30:04,713–726,,,BSYCZR64,0.1541850220264317,0.3157894736842105,0.2222222222222222,0.1717578331536133
9,42.0,sector,45.0,45.0,Walking the Walk of AI Ethics: Organizational Challenges and the Individualization of Risk among Ethics Entrepreneurs,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",,,10.1145/3593013.3593990,"Ali, Sanna J.; Christin, Angèle; Smart, Andrew; Katila, Riitta",2023.0,https://doi.org/10.1145/3593013.3593990,conferencePaper,"Amidst decline in public trust in technology, computing ethics have taken center stage, and critics have raised questions about corporate “ethics washing.” Yet few studies examine the actual implementation of AI ethics values in technology companies. Based on a qualitative analysis of technology workers tasked with integrating AI ethics into product development, we find that workers experience an environment where policies, practices, and outcomes are decoupled. We analyze AI ethics workers as ethics entrepreneurs who work to institutionalize new ethics-related practices within organizations. We show that ethics entrepreneurs face three major barriers to their work. First, they struggle to have ethics prioritized in an environment centered around software product launches. Second, ethics are difficult to quantify in a context where company goals are incentivized by metrics. Third, the frequent reorganization of teams makes it difficult to access knowledge and maintain relationships central to their work. Consequently, individuals take on great personal risk when raising ethics issues, especially when they come from marginalized backgrounds. These findings shed light on complex dynamics of institutional change at technology companies.",AI ethics; decoupling; institutional change; neo-institutionalism; organizations; responsible AI; Science and Technology Studies,9798400701924,,2023,2023-11-06 01:29:48,2023-11-06 01:29:48,217–226,FAccT '23,Association for Computing Machinery,54WS3WZI,0.1363636363636363,0.3076923076923077,0.3125,0.1647601814073776
10,50.0,sector,53.0,53.0,Organisational Responses to the Ethical Issues of Artificial Intelligence,AI Soc.,37.0,1,10.1007/s00146-021-01148-6,"Stahl, Bernd Carsten; Antoniou, Josephina; Ryan, Mark; Macnish, Kevin; Jiya, Tilimbe",2022.0,https://doi.org/10.1007/s00146-021-01148-6,journalArticle,"The ethics of artificial intelligence (AI) is a widely discussed topic. There are numerous initiatives that aim to develop the principles and guidance to ensure that the development, deployment and use of AI are ethically acceptable. What is generally unclear is how organisations that make use of AI understand and address these ethical issues in practice. While there is an abundance of conceptual work on AI ethics, empirical insights are rare and often anecdotal. This paper fills the gap in our current understanding of how organisations deal with AI ethics by presenting empirical findings collected using a set of ten case studies and providing an account of the cross-case analysis. The paper reviews the discussion of ethical issues of AI as well as mitigation strategies that have been proposed in the literature. Using this background, the cross-case analysis categorises the organisational responses that were observed in practice. The discussion shows that organisations are highly aware of the AI ethics debate and keen to engage with ethical issues proactively. However, they make use of only a relatively small subsection of the mitigation strategies proposed in the literature. These insights are of importance to organisations deploying or using AI, to the academic AI ethics debate, but maybe most valuable to policymakers involved in the current debate about suitable policy developments to address the ethical issues raised by AI.",Ethics; Artificial intelligence; AI policy; Case study; Organisational response,,0951-5666,2022-03,2023-11-06 01:30:00,2023-11-06 01:30:00,23–37,,,A8WHBU5L,0.1415929203539823,0.3333333333333333,0.3333333333333333,0.1597741697444135
11,51.0,sector,54.0,54.0,Artificial Intelligence ELSI Score for Science and Technology: A Comparison between Japan and the US,AI Soc.,38.0,4,10.1007/s00146-021-01323-9,"Hartwig, Tilman; Ikkatai, Yuko; Takanashi, Naohiro; Yokoyama, Hiromi M.",2022.0,https://doi.org/10.1007/s00146-021-01323-9,journalArticle,"Artificial intelligence (AI) has become indispensable in our lives. The development of a quantitative scale for AI ethics is necessary for a better understanding of public attitudes toward AI research ethics and to advance the discussion on using AI within society. For this study, we developed an AI ethics scale based on AI-specific scenarios. We investigated public attitudes toward AI ethics in Japan and the US using online questionnaires. We designed a test set using four dilemma scenarios and questionnaire items based on a theoretical framework for ethics, legal, and social issues (ELSI). We found that country and age are the most informative sociodemographic categories for predicting attitudes for AI ethics. Our proposed scale, which consists of 13 questions, can be reduced to only three, covering ethics, tradition, and policies. This new AI ethics scale will help to quantify how AI research is accepted in society and which area of ELSI people are most concerned with.",Ethics; Artificial Intelligence; Dilemma; ELSI,,0951-5666,2022-01,2023-11-06 01:29:59,2023-11-06 01:29:59,1609–1626,,,D4YXJKJ7,0.1602564102564102,0.4,0.0,0.1558417142339404
