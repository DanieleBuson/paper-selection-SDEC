,Unnamed: 0.2,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,ISBN,ISSN,Date,Date Added,Date Modified,Pages,Series,Publisher,Key,Eligibility_Abstract_Score,Eligibility_Keywords_Score,Eligibility_Title_Score,Eligibility_Score
0,0.0,0.0,0.0,Implementing Artificial Intelligence Ethics In&nbsp;Trustworthy System Development - Making AI Ethics A&nbsp;Business Case,"Product-Focused Software Process Improvement: 23rd International Conference, PROFES 2022, Jyväskylä, Finland, November 21–23, 2022, Proceedings",,,10.1007/978-3-031-21388-5_52,"Agbese, Mamia",2022.0,https://doi.org/10.1007/978-3-031-21388-5_52,conferencePaper,"Software businesses struggle to implement AI ethics or ethical requirements in their development and engineering of AI. Current tools mainly focus on the technical level, with scarce resources identified for the different groups across software business organizations. This study focuses on developing a proposed solution, the ethical requirement stack, as a toolkit software businesses can leverage to implement ethical requirements. The tool aims to improve the understanding and visibility of AI ethics by serving as a go-to in interpreting AI ethics guidelines, thereby reducing the gap in transitioning AI ethics from principles to practice.",AI Ethics; AI ethics principles; Artificial Intelligence; Ethical requirement stack; Ethical requirements; Software businesses,978-3-031-21387-8,,2022,2023-11-06 01:29:48,2023-11-06 01:29:48,656–661,,Springer-Verlag,RCRK9GYA,0.2340425531914893,0.8571428571428571,0.3846153846153846,0.3424100294013188
1,1.0,1.0,1.0,An AI Ethics Course Highlighting Explicit Ethical Agents,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462552,"Green, Nancy",2021.0,https://doi.org/10.1145/3461702.3462552,conferencePaper,"This is an experience report describing a pilot AI Ethics course for undergraduate computer science majors. In addition to teaching students about different ethical approaches and using them to analyze ethical issues, the course covered how ethics has been incorporated into the implementation of explicit ethical agents, and required students to implement an explicit ethical agent for a simple application. This report describes the course objectives and design, the topics covered, and a qualitative evaluation with suggestions for future offerings of the courses.",AI ethics; ethics education; explicit ethical agents,978-1-4503-8473-5,,2021,2023-11-06 01:29:48,2023-11-06 01:29:48,519–524,AIES '21,Association for Computing Machinery,KXWK8WI4,0.2048192771084337,1.1428571428571428,0.75,0.3223127430356346
2,3.0,4.0,4.0,Ethical Requirements Stack: A Framework for Implementing Ethical Requirements of AI in Software Engineering Practices,Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering,,,10.1145/3593434.3593489,"Agbese, Mamia; Mohanani, Rahul; Khan, Arif Ali; Abrahamsson, Pekka",2023.0,https://doi.org/10.1145/3593434.3593489,conferencePaper,"""The ethical requirements stack uses an Agile portfolio manage- ment framework based on agile scrum practices of themes, epics, features, and stories [3, 5] for a practical and hands-on approach to implementing ethical requirements of artificial intelligence (AI) into software engineering (SE) management practices. The frame- work is conceptualized as spread across actor groups of higher-level management (strategy level activities), middle-level management (product management activities), operational or development levels, and individual or team levels. The executive or strategy layer corresponds to the themes layer in the Agile portfolio management framework. This layer creates strategic, ethical requirements for the business. Ethical require- ments are determined at this stage using appropriate ethical frame- works or tools based on AI ethics guidelines and principles to create a central or strategic ethical requirements theme. """,AI ethics; AI ethics principles; Ethical requirements; AI; Agile portfolio management; Ethical requirements stack,9798400700446,,2023,2023-11-06 01:30:00,2023-11-06 01:30:00,326–328,EASE '23,Association for Computing Machinery,N49EFHB9,0.1679389312977099,0.9285714285714286,0.4666666666666667,0.2708347757488573
4,5.0,6.0,6.0,AI Ethics - Critical Reflections on Embedding Ethical Frameworks in AI Technology,"Culture and Computing. Design Thinking and Cultural Computing: 9th International Conference, C&amp;C 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part II",,,10.1007/978-3-030-77431-8_20,"Salo-Pöntinen, Henrikki",2021.0,https://doi.org/10.1007/978-3-030-77431-8_20,conferencePaper,"Embedding ethical frameworks in artificial intelligence (AI) technologies has been a popular topic for academic research for the past decade [1–7]. The approaches of the studies differ in how AI technology, ethics, role of technical artefacts and socio-technical aspects of AI are perceived. In addition, most studies define insufficiently what the connection between the process of embedding ethical frameworks to AI technology and the larger framework of AI ethics is. These deficiencies have caused that the concept of AI ethics and the construct of embedding ethical parameters into AI are used in an ambiguous, rather than in a complementary manner.One reason for the ambiguity within this field of research is due to a lack of a comprehensive conceptual framework for AI ethics in general. I intend to fill this void by grounding AI ethics as a subfield of philosophy of technology and applied ethics and presenting its main issues of study by examining recognized spheres of activities through the method of levels of abstraction [8]. I put forward an initial hierarchical conceptual framework for AI ethics as an outcome. After this, I discuss the connection between the process of embedding ethical frameworks in AI and the larger AI ethics framework, leading to presenting basic requirements for the sphere of activity hereafter known as embedded ethics.",AI ethics; Applied ethics; Embedded ethics; Human-technology interaction,978-3-030-77430-1,,2021,2023-11-06 01:29:48,2023-11-06 01:29:48,311–329,,Springer-Verlag,T2JKNGZ8,0.1953488372093023,0.875,0.5833333333333334,0.2483228832916864
5,7.0,8.0,8.0,A Principlist Framework for Cybersecurity Ethics,Comput. Secur.,109.0,C,10.1016/j.cose.2021.102382,"Formosa, Paul; Wilson, Michael; Richards, Deborah",2021.0,https://doi.org/10.1016/j.cose.2021.102382,journalArticle,"The ethical issues raised by cybersecurity practices and technologies are of critical importance. However, there is disagreement about what is the best ethical framework for understanding those issues. In this paper we seek to address this shortcoming through the introduction of a principlist ethical framework for cybersecurity that builds on existing work in adjacent fields of applied ethics, bioethics, and AI ethics. By redeploying the AI4People framework, we develop a domain-relevant specification of five ethical principles in cybersecurity: beneficence, non-maleficence, autonomy, justice, and explicability. We then illustrate the advantages of this principlist framework by examining the ethical issues raised by four common cybersecurity contexts: penetration testing, distributed denial of service attacks (DDoS), ransomware, and system administration. These case analyses demonstrate the utility of this principlist framework as a basis for understanding cybersecurity ethics and for cultivating the ethical expertise and ethical sensitivity of cybersecurity professionals and other stakeholders.",AI ethics; Privacy; Cybersecurity ethics; DDoS attacks; Penetration testing; Principlism; Ransomware,,0167-4048,2021-10,2023-11-06 01:29:59,2023-11-06 01:29:59,,,,VXFLFHHR,0.2027027027027027,0.5454545454545454,0.3333333333333333,0.2349071940017134
6,8.0,10.0,10.0,"Operationalising AI Ethics: Barriers, Enablers and next Steps",AI Soc.,38.0,1,10.1007/s00146-021-01308-8,"Morley, Jessica; Kinsey, Libby; Elhalal, Anat; Garcia, Francesca; Ziosi, Marta; Floridi, Luciano",2021.0,https://doi.org/10.1007/s00146-021-01308-8,journalArticle,"By mid-2019 there were more than 80 AI ethics guides available in the public domain. Despite this, 2020 saw numerous news stories break related to ethically questionable uses of AI. In part, this is because AI ethics theory remains highly abstract, and of limited practical applicability to those actually responsible for designing algorithms and AI systems. Our previous research sought to start closing this gap between the ‘what’ and the ‘how’ of AI ethics through the creation of a searchable typology of tools and methods designed to translate between the five most common AI ethics principles and implementable design practices. Whilst a useful starting point, that research rested on the assumption that all AI practitioners are aware of the ethical implications of AI, understand their importance, and are actively seeking to respond to them. In reality, it is unclear whether this is the case. It is this limitation that we seek to overcome here by conducting a mixed-methods qualitative analysis to answer the following four questions: what do AI practitioners understand about the need to translate ethical principles into practice? What motivates AI practitioners to embed ethical principles into design practices? What barriers do AI practitioners face when attempting to translate ethical principles into practice? And finally, what assistance do AI practitioners want and need when translating ethical principles into practice?",AI ethics; Applied ethics; Business ethics; Ethical practices; Ethical principles,,0951-5666,2021-11,2023-11-06 01:29:48,2023-11-06 01:29:48,411–423,,,XQQGTU4X,0.1583710407239819,1.3,0.375,0.2250921974267562
7,9.0,11.0,11.0,User Perspectives on Ethical Challenges in Human-AI Co-Creativity: A Design Fiction Study,Proceedings of the 15th Conference on Creativity and Cognition,,,10.1145/3591196.3593364,"Rezwana, Jeba; Maher, Mary Lou",2023.0,https://doi.org/10.1145/3591196.3593364,conferencePaper,"In a human-AI co-creation, AI not only categorizes, evaluates and interprets data but also generates new content and interacts with humans. As co-creative AI is a form of intelligent technology that directly involves humans, it is critical to anticipate and address ethical issues during all design stages. The open-ended nature of human-AI interactions in co-creation poses many challenges for designing ethical co-creative AI systems. Researchers have been exploring ethical issues associated with autonomous AI in recent years, but ethics in human-AI co-creativity is a relatively new research area. In order to design human-centered ethical AI, it is important to understand the perspectives, expectations, and ethical concerns of potential users. In this paper, we present a study with 18 participants to explore several ethical dilemmas and challenges in human-AI co-creation from the perspective of potential users using a design fiction (DF) methodology. DF is a speculative research method that depicts a new concept or technology through stories as an intangible prototype. We present the findings from the study as potential users’ perspectives, stances, and expectations around ethical challenges in human-AI co-creativity as a basis for designing human-centered ethical AI partners for human-AI co-creation.",AI Ethics; Co-creativity; Design Fiction; Ethical AI; Ethical Issues; Human-AI Co-Creation,9798400701801,,2023,2023-11-06 01:30:01,2023-11-06 01:30:01,62–74,C&amp;C '23,Association for Computing Machinery,9N22T8PQ,0.171875,0.9090909090909092,0.25,0.2207759718600279
10,13.0,15.0,15.0,From AI for People to AI for the World and the Universe,AI Soc.,38.0,2,10.1007/s00146-022-01402-5,"Baum, Seth D.; Owe, Andrea",2022.0,https://doi.org/10.1007/s00146-022-01402-5,journalArticle,"Recent work in AI ethics often calls for AI to advance human values and interests. The concept of “AI for people” is one notable example. Though commendable in some respects, this work falls short by excluding the moral significance of nonhumans. This paper calls for a shift in AI ethics to more inclusive paradigms such as “AI for the world” and “AI for the universe”. The paper outlines the case for more inclusive paradigms and presents implications for moral philosophy and computer science work on AI ethics.",AI ethics; AI for people; Environmental ethics; Nonhumans,,0951-5666,2022-02,2023-11-06 01:29:50,2023-11-06 01:29:50,679–680,,,LQS5HU5H,0.1494252873563218,0.75,0.1666666666666666,0.2056250229517829
11,14.0,16.0,16.0,The State of Ethical AI in Practice: A Multiple Case Study of Estonian Public Service Organizations,Int. J. Technoethics,14.0,1,10.4018/IJT.322017,"Hinton, Charlene",2023.0,https://doi.org/10.4018/IJT.322017,journalArticle,"Despite the prolific introduction of ethical frameworks, empirical research on AI ethics in the public sector is limited. This empirical research investigates how the ethics of AI is translated into practice and the challenges of its implementation by public service organizations. Using the Value Sensitive Design as a framework of inquiry, semi-structured interviews are conducted with eight public service organizations across the Estonian government that have piloted or developed an AI solution for delivering a public service. Results show that the practical application of AI ethical principles is indirectly considered and demonstrated in different ways in the design and development of the AI. However, translation of these principles varies according to the maturity of the AI and the public servant's level of awareness, knowledge, and competences in AI. Data-related challenges persist as public service organizations work on fine-tuning their AI applications.",Ethics; Artificial Intelligence; AI Ethical Principles; Estonia; Ethical AI Design and Development; Practical Application of AI Ethics; Public Sector; Value Sensitive Design,,1947-3451,2023-04,2023-11-06 01:29:59,2023-11-06 01:29:59,1–15,,,3Z9FZKRF,0.1276595744680851,0.5909090909090909,0.25,0.2018186327252825
14,17.0,19.0,19.0,"Integrating AI Ethics in Wildlife Conservation AI Systems in South Africa: A Review, Challenges, and Future Research Agenda",AI Soc.,38.0,1,10.1007/s00146-021-01285-y,"Nandutu, Irene; Atemkeng, Marcellin; Okouma, Patrice",2021.0,https://doi.org/10.1007/s00146-021-01285-y,journalArticle,"With the increased use of Artificial Intelligence (AI) in wildlife conservation, issues around whether AI-based monitoring tools in wildlife conservation comply with standards regarding AI Ethics are on the rise. This review aims to summarise current debates and identify gaps as well as suggest future research by investigating (1) current AI Ethics and AI Ethics issues in wildlife conservation, (2) Initiatives Stakeholders in AI for wildlife conservation should consider integrating AI Ethics in wildlife conservation. We find that the existing literature weakly focuses on AI Ethics and AI Ethics in wildlife conservation while at the same time ignores AI Ethics integration in AI systems for wildlife conservation. This paper formulates an ethically aligned AI system framework and discusses pre-eminent on-demand AI systems in wildlife conservation. The proposed framework uses agile software life cycle methodology to implement guidelines towards the ethical upgrade of any existing AI system or the development of any new ethically aligned AI system. The guidelines enforce, among others, the minimisation of intentional harm and bias, diversity in data collection, design compliance, auditing of all activities in the framework and ease of code inspection. This framework will inform AI developers, users, conservationists, and policymakers on what to consider when integrating AI Ethics into AI-based systems for wildlife conservation.",AI Ethics; AI Ethics integration; AI in wildlife conservation; Artificial intelligence; Human–wildlife conflicts; Wildlife conservation concerns,,0951-5666,2021-09,2023-11-06 01:29:48,2023-11-06 01:29:48,245–257,,,QIMKGXJF,0.1714285714285714,0.4375,0.2222222222222222,0.1974425263391988
15,18.0,20.0,20.0,Utilizing User Stories To&nbsp;Bring AI Ethics Into&nbsp;Practice In&nbsp;Software Engineering,"Product-Focused Software Process Improvement: 23rd International Conference, PROFES 2022, Jyväskylä, Finland, November 21–23, 2022, Proceedings",,,10.1007/978-3-031-21388-5_41,"Kemell, Kai-Kristian; Vakkuri, Ville; Halme, Erika",2022.0,https://doi.org/10.1007/978-3-031-21388-5_41,conferencePaper,"AI ethics is a research area characterized by a prominent gap between research and practice. With most studies in the area being conceptual in nature or focused on technical ML (Machine Learning) solutions, the link between AI (Artificial Intelligence) ethics and SE (Software Engineering) practice remains thin. Establishing this link, we argue, is vital going forward. While conceptual discussion is required to define AI ethics, much progress has already been made in this regard. Similarly, though technical ML solutions are also required for practical implementation, ML systems are ultimately still software, and thus SE cannot be forgotten. In this paper, we propose one way of bringing AI ethics closer to conventional SE practice: utilizing user stories to implement AI ethics by means of Ethical User Stories (EUS). EUS can be used to formulate both functional and non-functional requirements, although an ethical framework is required produce them. By treating AI ethics as a part of the development process in this fashion, as opposed to a separate task, it can ideally become a part of SE for ML systems.",AI ethics; Artificial Intelligence; Ethical tool; Ethical user story; User story,978-3-031-21387-8,,2022,2023-11-06 01:29:48,2023-11-06 01:29:48,553–558,,Springer-Verlag,2VG4RNXX,0.135593220338983,0.8181818181818182,0.3333333333333333,0.192289315187082
17,21.0,23.0,23.0,How Does Value Similarity Affect Human Reliance in AI-Assisted Ethical Decision Making?,"Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3600211.3604709,"Narayanan, Saumik; Yu, Guanghui; Ho, Chien-Ju; Yin, Ming",2023.0,https://doi.org/10.1145/3600211.3604709,conferencePaper,"This paper explores the impact of value similarity between humans and AI on human reliance in the context of AI-assisted ethical decision-making. Using kidney allocation as a case study, we conducted a randomized human-subject experiment where workers were presented with ethical dilemmas in various conditions, including no AI recommendations, recommendations from a similar AI, and recommendations from a dissimilar AI. We found that recommendations provided by a dissimilar AI had a higher overall effect on human decisions than recommendations from a similar AI. However, when humans and AI disagreed, participants were more likely to change their decisions when provided with recommendations from a similar AI. The effect was not due to humans’ perceptions of the AI being similar, but rather due to the AI displaying similar ethical values through its recommendations. We also conduct a preliminary analysis on the relationship between value similarity and trust, and potential shifts in ethical preferences at the population-level.",AI ethics; ethical preference; human reliance on AI,9798400702310,,2023,2023-11-06 01:29:49,2023-11-06 01:29:49,49–57,AIES '23,Association for Computing Machinery,BYSWACNN,0.1493506493506493,0.875,0.25,0.1882661343758282
20,24.0,26.0,26.0,Trustworthy AI for the People?,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462470,"Figueras, Clàudia; Verhagen, Harko; Cerratto Pargman, Teresa",2021.0,https://doi.org/10.1145/3461702.3462470,conferencePaper,"While AI systems become more pervasive, their social impact is increasingly hard to measure. To help mitigate possible risks and guide practitioners into a more responsible design, diverse organizations have released AI ethics frameworks. However, it remains unclear how ethical issues are dealt with in the everyday practices of AI developers. To this end, we have carried an exploratory empirical study interviewing AI developers working for Swedish public organizations to understand how ethics are enacted in practice. Our analysis found that several AI ethics issues are not consistently tackled, and AI systems are not fully recognized as part of a broader sociotechnical system.",AI ethics in practice; AI in public organizations; citizen empowerment; responsible AI; responsible AI principles in practice; trustworthy AI,978-1-4503-8473-5,,2021,2023-11-06 01:29:49,2023-11-06 01:29:49,269–270,AIES '21,Association for Computing Machinery,4VB2H2EN,0.145631067961165,0.3684210526315789,0.2,0.1842344041757601
22,27.0,30.0,30.0,Designing Up with Value-Sensitive Design: Building a Field Guide for Ethical ML Development,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",,,10.1145/3531146.3534626,"Boyd, Karen",2022.0,https://doi.org/10.1145/3531146.3534626,conferencePaper,"If “studying up,” or researching powerful actors in a social system, can offer insight into the workings and effects of power in social systems, this paper argues that “designing up” will give researchers and designers a tool to intervene. This paper offers a conception of “designing up,” applies the structure of Value Sensitive Design (VSD) to accomplish it, and submits an example of a tool designed to support ethical sensitivity, especially particularization and judgment. The designed artifact is a field guide for ethical mitigation strategies that uses tool profiles and filters to aid machine learning (ML) engineers as they build understanding of an ethical issue they have recognized and as they match the particulars of their problem to a technical ethical mitigation. This guide may broaden its users’ awareness of potential ethical issues, important features of ethical issues and their mitigations, and the breadth of available mitigations. Additionally, it may encourage ethical sensitivity in future ML projects. Feedback from ML engineers and technology ethics researchers rendered several usability improvements and ideas for future development. The tool can be found at: https://ml-ethics-tool.web.app/.",AI ethics; ethics; machine learning; datasets; development practices; ethical sensitivity,978-1-4503-9352-2,,2022,2023-11-06 01:30:01,2023-11-06 01:30:01,2069–2082,FAccT '22,Association for Computing Machinery,TH8CRF2C,0.1270718232044199,0.8,0.2307692307692307,0.1764500794887535
23,28.0,31.0,31.0,Ethical Awareness of UXers in the Loop: Ethical Issues in the Uxer-AI Collaboration Process from a UX Perspective,Proceedings of the 25th International Conference on Mobile Human-Computer Interaction,,,10.1145/3565066.3608691,"Yoon, Harin; Jun, Soojin",2023.0,https://doi.org/10.1145/3565066.3608691,conferencePaper,"Artificial Intelligence (AI) has emerged as a prominent collaborative tool across diverse domains, driving innovation in various tasks. However, this human–AI process brings forth a range of ethical considerations that require careful examination. This study investigates the ethical concerns that arise during the user experience designer (UXer)–AI co-creation process and the evolving role of UXers. Employing a mixed methods approach, combining observational task performance experiments and in-depth interviews, the study captures UXers' perceptions of ethical issues in the UXer-AI co-creation process. The findings shed light on three prominent ethical challenges in the UXer–AI co-creation process: reliability, bias, and unemployment. Consequently, this study emphasizes the crucial role of UXers, such as fact-checking, empathy-based decision making, and effective communication with AI, mitigating these ethical challenges. These findings enhance our understanding of UXers' responsibilities and shed light on the potential of leveraging AI as an effective collaborative tool for task completion.",AI Ethics; Generative AI; Co-Creation; Ethical UX; Uxer-AI Co-Creation Model,978-1-4503-9924-1,,2023,2023-11-06 01:30:01,2023-11-06 01:30:01,,MobileHCI '23 Companion,Association for Computing Machinery,72KLRSH2,0.1216216216216216,0.7,0.3333333333333333,0.1740387491738843
24,29.0,32.0,32.0,Mapping Research Strands of Ethics of Artificial Intelligence in Healthcare: A Bibliometric and Content Analysis,Comput. Biol. Med.,135.0,C,10.1016/j.compbiomed.2021.104660,"Saheb, Tahereh; Saheb, Tayebeh; Carpenter, David O.",2021.0,https://doi.org/10.1016/j.compbiomed.2021.104660,journalArticle,"The growth of artificial intelligence in promoting healthcare is rapidly progressing. Notwithstanding its promising nature, however, AI in healthcare embodies certain ethical challenges as well. This research aims to delineate the most influential elements of scientific research on AI ethics in healthcare by conducting bibliometric, social network analysis, and cluster-based content analysis of scientific articles. Not only did the bibliometric analysis identify the most influential authors, countries, institutions, sources, and documents, but it also recognized four ethical concerns associated with 12 medical issues. These ethical categories are composed of normative, meta-ethics, epistemological and medical practice. The content analysis complemented this list of ethical categories and distinguished seven more ethical categories: ethics of relationships, medico-legal concerns, ethics of robots, ethics of ambient intelligence, patients' rights, physicians’ rights, and ethics of predictive analytics. This analysis likewise identified 40 general research gaps in the literature and plausible future research strands. This analysis furthers conversations on the ethics of AI and associated emerging technologies such as nanotech and biotech in healthcare, hence, advances convergence research on the ethics of AI in healthcare. Practically, this research will provide a map for policymakers and AI engineers and scientists on what dimensions of AI-based medical interventions require stricter policies and guidelines and robust ethical design and development.",Ethics; Artificial intelligence; Content analysis; Healthcare; Bibliometric analysis; Network visualization; Robotics,,0010-4825,2021-08,2023-11-06 01:30:04,2023-11-06 01:30:04,,,,2BYKVZ92,0.1761904761904762,0.1818181818181818,0.1333333333333333,0.1738921640697445
25,30.0,33.0,33.0,Mental Contents in Designing AI Ethics,"Culture and Computing: 10th International Conference, C&amp;C 2022, Held as Part of the 24th HCI International Conference, HCII 2022, Virtual Event, June 26 – July 1, 2022, Proceedings",,,10.1007/978-3-031-05434-1_32,"Saariluoma, Pertti; Myllylä, Mari; Karvonen, Antero",2022.0,https://doi.org/10.1007/978-3-031-05434-1_32,conferencePaper,"In future intelligent digital society, the way people organize their life around technologies shall change because intelligent machines can follow ethical rules in their behavior. In the human mind, ethics exist as contents of mental representations. Therefore, it is important to investigate the information contents of mental representations or mental contents. One can also call this approach content-based cognitive research. The analysis of mental contents makes it possible to mimic human ethical information processing and construct human digital twins for designing ethical machine information processes. In this paper, we analyze the relevant AI aspects of Hume’s guillotine. Hume asked critically whether facts can be used to derive values. His answer was negative. However, modern information technology can collect huge masses of facts, but can these facts be used in improving how we should live? Content-based analysis of human ethical information processing opens possibilities to bypass the logical dilemma of Hume’s guillotine.",Ethical discourse; Hume’s guillotine; Mental contents; Weak and strong ethical AI,978-3-031-05433-4,,2022,2023-11-06 01:29:48,2023-11-06 01:29:48,477–487,,Springer-Verlag,ZWPT3FNA,0.1258278145695364,0.6363636363636364,0.5,0.173611085946733
26,31.0,34.0,34.0,From the Ground Truth up: Doing AI Ethics from Practice to Principles,AI Soc.,38.0,4,10.1007/s00146-021-01336-4,"Brusseau, James",2022.0,https://doi.org/10.1007/s00146-021-01336-4,journalArticle,"Recent AI ethics has focused on applying abstract principles downward to practice. This paper moves in the other direction. Ethical insights are generated from the lived experiences of AI-designers working on tangible human problems, and then cycled upward to influence theoretical debates surrounding these questions: (1) Should AI as trustworthy be sought through explainability, or accurate performance? (2) Should AI be considered trustworthy at all, or is reliability a preferable aim? (3) Should AI ethics be oriented toward establishing protections for users, or toward catalyzing innovation? Specific answers are less significant than the larger demonstration that AI ethics is currently unbalanced toward theoretical principles, and will benefit from increased exposure to grounded practices and dilemmas.",AI case studies; AI ethics; Healthcare AI; Philosophy and AI; Trustworthy AI,,0951-5666,2022-01,2023-11-06 01:29:48,2023-11-06 01:29:48,1651–1657,,,8GLT86ME,0.1217391304347826,0.5833333333333334,0.3333333333333333,0.1735443018845113
27,32.0,35.0,35.0,A Study on the Modeling of Major Factors for the Principles of AI Ethics,DG.O2021: The 22nd Annual International Conference on Digital Government Research,,,10.1145/3463677.3463733,"Lim, Ji Hun; Kwon, Hun Yeong",2021.0,https://doi.org/10.1145/3463677.3463733,conferencePaper,"The fourth industrial revolution, centered on artificial intelligence (AI), signals a significant transformation in human society. For this social transformation to ultimately be for humankind's prosperity and happiness, serious consideration of AI ethics is needed. As a result, many countries have begun to establish AI ethics principles, and the international community is pushing for standardization on AI ethics principles. This study aims to derive general factors of ethical principles that should be considered to establish and standardize AI ethics principles. To this end, we present a ""general AI ethics principles model,"" including 12 major factors, based on the recently published AI ethics principles in 15 countries. Furthermore, the major factors for AI ethics principles that we derived through this study ultimately confirmed that AI should be useful to all humans and is oriented toward the value of building a ""Trustworthy"" AI society. Based on these fundamental ideologies, we confirmed that each factor interconnects with each other. It is hoped that the AI ethics principles model that reflects this will be referred to national and international communities that have yet to develop Principles of AI Ethics. However, Factors for AI ethics principles should be constructed following the principles' intent and goal orientation, ensuring its feasibility, rather than merely duplicating the principles model.",,978-1-4503-8492-6,,2021,2023-11-06 01:29:49,2023-11-06 01:29:49,208–218,DG.O'21,Association for Computing Machinery,CP5RISCE,0.1706161137440758,0.0,0.2142857142857142,0.1727108580738546
29,34.0,37.0,37.0,Rebuilding 'ethics' to Govern AI: How to Re-Set the Boundaries for the Legal Sector?,Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law,,,10.1145/3594536.3595156,"Unver, Mehmet B.",2023.0,https://doi.org/10.1145/3594536.3595156,conferencePaper,"Artificial intelligence (AI) has been transforming the legal sector and profession given every day enhancing AI-driven legal tech tools. Considering the far-reaching ethical implications of such tools and the disparate functionalities of 'AI ethics' and 'legal ethics', this paper puts into question the interplay between these ethical domains and their underlying rules. After fleshing out the governance of ethics under each domain, e.g. respectively professional conduct rules and self-regulatory principles, and signposting the unresolved ethical challenges of status quo, e.g. particularly concerning cross-domain issues, the paper discusses how they need to interact, based on the three policy options: 'revision of the conduct rules', 'individual (company level) collaboration' and 'higher-level collaboration'. It is concluded that 'higher-level collaboration' between the stakeholders is found to be the most sustainable and long-term option given the need to mitigate the ethical challenges concerning the legal sector from a holistic point of view.",AI ethics; fairness; accountability; transparency; Legal ethics,9798400701979,,2023,2023-11-06 01:29:59,2023-11-06 01:29:59,306–315,ICAIL '23,Association for Computing Machinery,R8UG3WLT,0.1360544217687075,0.7142857142857143,0.2142857142857142,0.1717094798118252
30,35.0,38.0,38.0,Making Art with and about Artificial Intelligence: Three Approaches to Teaching AI and AI Ethics to Middle and High School Students,Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2,,,10.1145/3478432.3499157,"Walsh, Benjamin; Ali, Safinah; Castro, Francisco; Desportes, Kayla; DiPaola, Daniella; Lee, Irene; Payne, William; Sieke, Scott; Zhang, Helen",2022.0,https://doi.org/10.1145/3478432.3499157,conferencePaper,"In this hands-on workshop participants will experience the curricula from three NSF funded projects, which engage youth in creating art with and about AI technologies while exploring related ethical concerns.danceON is a web-based creative coding environment that engages learners in creating multimedia dance performances. Besides writing reactive code that generates animations to augment dance performances, students also use the system to explore the boundaries and biases of AI.DAILy is a curriculum focused on developing AI literacy among middle school students through the integration of technical concepts and processes, ethical and societal implications, and career futures in AI. Participants will be focusing on the AI + art modules of DAILy.Imagine AI develops project-based curricula to support youth in exploring critical ethical issues related to AI. Students read short stories featuring youth at the center of AI ethical dilemmas, build and manipulate AI systems, and create digital media to express ethical stances.Participants will leave the workshop with multiple AI teaching strategies that blend technical learning with social purpose and creative expression.",ai ethics education; art; artificial intelligence education,978-1-4503-9071-2,,2022,2023-11-06 01:29:50,2023-11-06 01:29:50,1203,SIGCSE 2022,Association for Computing Machinery,EZQ5A6TG,0.1538461538461538,0.4285714285714285,0.1904761904761904,0.1691687840484339
31,36.0,39.0,39.0,AI Ethics and the Banality of Evil,Ethics and Inf. Technol.,23.0,3,10.1007/s10676-021-09587-x,"Tajalli, Payman",2021.0,https://doi.org/10.1007/s10676-021-09587-x,journalArticle,"In this paper, I draw on Hannah Arendt’s notion of ‘banality of evil’ to argue that as long as AI systems are designed to follow codes of ethics or particular normative ethical theories chosen by us and programmed in them, they are Eichmanns destined to commit evil. Since intelligence alone is not sufficient for ethical decision making, rather than strive to program AI to determine the right ethical decision based on some ethical theory or criteria, AI should be concerned with avoiding making the wrong decisions, and this requires hardwiring the thinking activity as a prerequisite for decision making.",Artificial Intelligence; Artificial Thinking; Banality of Evil,,1388-1957,2021-09,2023-11-06 01:29:48,2023-11-06 01:29:48,447–454,,,5CDJRHE9,0.1717171717171717,0.0,0.4285714285714285,0.1689992457037911
32,37.0,40.0,40.0,Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics,Proc. ACM Hum.-Comput. Interact.,7.0,CSCW1,10.1145/3579621,"Wong, Richmond Y.; Madaio, Michael A.; Merrill, Nick",2023.0,https://doi.org/10.1145/3579621,journalArticle,"Numerous toolkits have been developed to support ethical AI development. However, toolkits, like all tools, encode assumptions in their design about what work should be done and how. In this paper, we conduct a qualitative analysis of 27 AI ethics toolkits to critically examine how the work of ethics is imagined and how it is supported by these toolkits. Specifically, we examine the discourses toolkits rely on when talking about ethical issues, who they imagine should do the work of ethics, and how they envision the work practices involved in addressing ethics. Among the toolkits, we identify a mismatch between the imagined work of ethics and the support the toolkits provide for doing that work. In particular, we identify a lack of guidance around how to navigate labor, organizational, and institutional power dynamics as they relate to performing ethical work. We use these omissions to chart future work for researchers and designers of AI ethics toolkits.",ethics; fairness; labor; toolkits; work,,,2023-04,2023-11-06 01:29:49,2023-11-06 01:29:49,,,,57LMLERK,0.1538461538461538,0.4,0.25,0.1686935969058874
35,40.0,43.0,43.0,Beyond Fairness and Explanation: Foundations of Trustworthiness of Artificial Agents,"Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3514094.3539570,"Malle, Bertram F.",2022.0,https://doi.org/10.1145/3514094.3539570,conferencePaper,"The topics of fairness and explainability have dominated recent discussions of ethical AI. However, these are only two criteria that would make artificial agents anywhere close to ethical. I frame the question of ethical AI, and especially ethical social robots, as the question of what would make them worthy of human trust and actually eliciting human trust. Relying on a recent investigation of the multi-dimensionality of human trust, I lay out five criteria of trustworthiness-being competent, reliable, transparent, benevolent, and having ethical integrity. I will argue that an essential ingredient of such trustworthiness is norm competence-the ability to represent, comply with, and learn relevant social-moral norms (including fairness as one among many). I discuss the challenges to implementing norm competence and the critical role that justification, not just explanation, will play in providing evidence for such competence.",fairness; explainability; norms; ethical ai; trust; xai; robotethics; trustworthiness,978-1-4503-9247-1,,2022,2023-11-06 01:29:55,2023-11-06 01:29:55,4,AIES '22,Association for Computing Machinery,2I4CL7D7,0.145985401459854,0.5555555555555556,0.0,0.1663380091994811
36,41.0,44.0,44.0,Ethical Data Curation for AI: An Approach Based on Feminist Epistemology and Critical Theories of Race,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462598,"Leavy, Susan; Siapera, Eugenia; O'Sullivan, Barry",2021.0,https://doi.org/10.1145/3461702.3462598,conferencePaper,"The potential for bias embedded in data to lead to the perpetuation of social injustice though Artificial Intelligence (AI) necessitates an urgent reform of data curation practices for AI systems, especially those based on machine learning. Without appropriate ethical and regulatory frameworks there is a risk that decades of advances in human rights and civil liberties may be undermined. This paper proposes an approach to data curation for AI, grounded in feminist epistemology and informed by critical theories of race and feminist principles. The objective of this approach is to support critical evaluation of the social dynamics of power embedded in data for AI systems. We propose a set of fundamental guiding principles for ethical data curation that address the social construction of knowledge, call for inclusion of subjugated and new forms of knowledge, support critical evaluation of theoretical concepts within data and recognise the reflexive nature of knowledge. In developing this ethical framework for data curation, we aim to contribute to a virtue ethics for AI and ensure protection of fundamental and human rights.",critical theories of race; data curation; ethical ai; feminist theory,978-1-4503-8473-5,,2021,2023-11-06 01:29:53,2023-11-06 01:29:53,695–703,AIES '21,Association for Computing Machinery,4G3QRRXZ,0.1314285714285714,0.5,0.3125,0.1649661682854959
37,42.0,45.0,45.0,Walking the Walk of AI Ethics: Organizational Challenges and the Individualization of Risk among Ethics Entrepreneurs,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",,,10.1145/3593013.3593990,"Ali, Sanna J.; Christin, Angèle; Smart, Andrew; Katila, Riitta",2023.0,https://doi.org/10.1145/3593013.3593990,conferencePaper,"Amidst decline in public trust in technology, computing ethics have taken center stage, and critics have raised questions about corporate “ethics washing.” Yet few studies examine the actual implementation of AI ethics values in technology companies. Based on a qualitative analysis of technology workers tasked with integrating AI ethics into product development, we find that workers experience an environment where policies, practices, and outcomes are decoupled. We analyze AI ethics workers as ethics entrepreneurs who work to institutionalize new ethics-related practices within organizations. We show that ethics entrepreneurs face three major barriers to their work. First, they struggle to have ethics prioritized in an environment centered around software product launches. Second, ethics are difficult to quantify in a context where company goals are incentivized by metrics. Third, the frequent reorganization of teams makes it difficult to access knowledge and maintain relationships central to their work. Consequently, individuals take on great personal risk when raising ethics issues, especially when they come from marginalized backgrounds. These findings shed light on complex dynamics of institutional change at technology companies.",AI ethics; decoupling; institutional change; neo-institutionalism; organizations; responsible AI; Science and Technology Studies,9798400701924,,2023,2023-11-06 01:29:48,2023-11-06 01:29:48,217–226,FAccT '23,Association for Computing Machinery,54WS3WZI,0.1363636363636363,0.3076923076923077,0.3125,0.1647601814073776
38,48.0,51.0,51.0,Automated Kantian Ethics,"Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3514094.3539527,"Singh, Lavanya",2022.0,https://doi.org/10.1145/3514094.3539527,conferencePaper,"As we grant artificial intelligence increasing power and independence in contexts like healthcare, policing, and driving, AI faces moral dilemmas but lacks the tools to solve them. The dangers of unethical AI motivate automated ethics-i.e., the development of machines that can perform ethical reasoning. Though philosophically sophisticated ethical theories enable nuanced judgements, prior work in automated ethics rarely engages with philosophical literature. I contribute an implementation of automated Kantian ethics that is faithful to the Kantian philosophical tradition. My system can morally judge actions and is an early step towards philosophically mature ethical AI agents. I hope to develop an ""input parser"" that can parse natural language sentences into logical formulas that my system can evaluate.",Kant; automated ethics; Dyadic Deontic Logic; Isabelle/HOL,978-1-4503-9247-1,,2022,2023-11-06 01:29:54,2023-11-06 01:29:54,915,AIES '22,Association for Computing Machinery,UMPN42CE,0.1379310344827586,0.2857142857142857,0.6666666666666666,0.1616599225897255
39,50.0,53.0,53.0,Organisational Responses to the Ethical Issues of Artificial Intelligence,AI Soc.,37.0,1,10.1007/s00146-021-01148-6,"Stahl, Bernd Carsten; Antoniou, Josephina; Ryan, Mark; Macnish, Kevin; Jiya, Tilimbe",2022.0,https://doi.org/10.1007/s00146-021-01148-6,journalArticle,"The ethics of artificial intelligence (AI) is a widely discussed topic. There are numerous initiatives that aim to develop the principles and guidance to ensure that the development, deployment and use of AI are ethically acceptable. What is generally unclear is how organisations that make use of AI understand and address these ethical issues in practice. While there is an abundance of conceptual work on AI ethics, empirical insights are rare and often anecdotal. This paper fills the gap in our current understanding of how organisations deal with AI ethics by presenting empirical findings collected using a set of ten case studies and providing an account of the cross-case analysis. The paper reviews the discussion of ethical issues of AI as well as mitigation strategies that have been proposed in the literature. Using this background, the cross-case analysis categorises the organisational responses that were observed in practice. The discussion shows that organisations are highly aware of the AI ethics debate and keen to engage with ethical issues proactively. However, they make use of only a relatively small subsection of the mitigation strategies proposed in the literature. These insights are of importance to organisations deploying or using AI, to the academic AI ethics debate, but maybe most valuable to policymakers involved in the current debate about suitable policy developments to address the ethical issues raised by AI.",Ethics; Artificial intelligence; AI policy; Case study; Organisational response,,0951-5666,2022-03,2023-11-06 01:30:00,2023-11-06 01:30:00,23–37,,,A8WHBU5L,0.1415929203539823,0.3333333333333333,0.3333333333333333,0.1597741697444135
40,51.0,54.0,54.0,Artificial Intelligence ELSI Score for Science and Technology: A Comparison between Japan and the US,AI Soc.,38.0,4,10.1007/s00146-021-01323-9,"Hartwig, Tilman; Ikkatai, Yuko; Takanashi, Naohiro; Yokoyama, Hiromi M.",2022.0,https://doi.org/10.1007/s00146-021-01323-9,journalArticle,"Artificial intelligence (AI) has become indispensable in our lives. The development of a quantitative scale for AI ethics is necessary for a better understanding of public attitudes toward AI research ethics and to advance the discussion on using AI within society. For this study, we developed an AI ethics scale based on AI-specific scenarios. We investigated public attitudes toward AI ethics in Japan and the US using online questionnaires. We designed a test set using four dilemma scenarios and questionnaire items based on a theoretical framework for ethics, legal, and social issues (ELSI). We found that country and age are the most informative sociodemographic categories for predicting attitudes for AI ethics. Our proposed scale, which consists of 13 questions, can be reduced to only three, covering ethics, tradition, and policies. This new AI ethics scale will help to quantify how AI research is accepted in society and which area of ELSI people are most concerned with.",Ethics; Artificial Intelligence; Dilemma; ELSI,,0951-5666,2022-01,2023-11-06 01:29:59,2023-11-06 01:29:59,1609–1626,,,D4YXJKJ7,0.1602564102564102,0.4,0.0,0.1558417142339404
41,53.0,56.0,56.0,Epistemic Reasoning for Machine Ethics with Situation Calculus,"Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,,10.1145/3461702.3462586,"Pagnucco, Maurice; Rajaratnam, David; Limarga, Raynaldio; Nayak, Abhaya; Song, Yang",2021.0,https://doi.org/10.1145/3461702.3462586,conferencePaper,"With the rapid development of autonomous machines such as selfdriving vehicles and social robots, there is increasing realisation that machine ethics is important for widespread acceptance of autonomous machines. Our objective is to encode ethical reasoning into autonomous machines following well-defined ethical principles and behavioural norms. We provide an approach to reasoning about actions that incorporates ethical considerations. It builds on Scherl and Levesque's [29, 30] approach to knowledge in the situation calculus. We show how reasoning about knowledge in a dynamic setting can be used to guide ethical and moral choices, aligned with consequentialist and deontological approaches to ethics. We apply our approach to autonomous driving and social robot scenarios, and provide an implementation framework.",machine ethics; epistemic logic; knowledge representation; situation calculus,978-1-4503-8473-5,,2021,2023-11-06 01:29:57,2023-11-06 01:29:57,814–821,AIES '21,Association for Computing Machinery,AAT628QT,0.1379310344827586,0.25,0.25,0.1541408016075209
42,54.0,57.0,57.0,Broadening AI Ethics Narratives: An Indic Art View,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",,,10.1145/3593013.3593971,"Divakaran, Ajay; Sridhar, Aparna; Srinivasan, Ramya",2023.0,https://doi.org/10.1145/3593013.3593971,conferencePaper,"Incorporating interdisciplinary perspectives is seen as an essential step towards enhancing artificial intelligence (AI) ethics. In this regard, the field of arts is perceived to play a key role in elucidating diverse historical and cultural narratives, serving as a bridge across research communities. Most of the works that examine the interplay between the field of arts and AI ethics concern digital artworks, largely exploring the potential of computational tools in being able to surface biases in AI systems. In this paper, we investigate a complementary direction–that of uncovering the unique socio-cultural perspectives embedded in human-made art, which in turn, can be valuable in expanding the horizon of AI ethics. Through semi-structured interviews across sixteen artists, art scholars, and researchers of diverse Indian art forms like music, sculpture, painting, floor drawings, dance, etc., we explore how non-Western ethical abstractions, methods of learning, and participatory practices observed in Indian arts, one of the most ancient yet perpetual and influential art traditions, can shed light on aspects related to ethical AI systems. Through a case study concerning the Indian dance system (i.e. the ‘Natyashastra’), we analyze potential pathways towards enhancing ethics in AI systems. Insights from our study outline the need for (1) incorporating empathy in ethical AI algorithms, (2) integrating multimodal data formats for ethical AI system design and development, (3) viewing AI ethics as a dynamic, diverse, cumulative, and shared process rather than as a static, self-contained framework to facilitate adaptability without annihilation of values (4) consistent life-long learning to enhance AI accountability",AI ethics; Indian arts,9798400701924,,2023,2023-11-06 01:29:48,2023-11-06 01:29:48,2–11,FAccT '23,Association for Computing Machinery,4SQQGBXJ,0.1388888888888889,0.75,0.375,0.1528314620528867
43,55.0,58.0,58.0,Centring Dignity in Algorithm Development: Testing a Dignity Lens,Proceedings of the 34th Australian Conference on Human-Computer Interaction,,,10.1145/3572921.3572938,"Ruster, Lorenn P.; Oliva-Altamirano, Paola; Daniell, Katherine A.",2023.0,https://doi.org/10.1145/3572921.3572938,conferencePaper,"Against a backdrop of algorithms that disempower, dehumanise, disenfranchise and discriminate, there are increasing calls to centre the human in AI development processes and to humanise AI development in practice; centring dignity in AI development could provide a way forward. Despite the inclusion of dignity in many Artificial Intelligence (AI) ethics frameworks, like many other AI ethics principles, there is little operational understanding of what dignity can look like in practice when it comes to the development of algorithms. Drawing on cybernetics and a model of dignity developed in the field of international conflict resolution, this paper presents our work-in-progress tool - the Dignity Lens - for considering dignity throughout the AI development lifecycle, and practitioner reflections from using the tool. This work is an initial step towards articulating what dignity-centred AI development could look like in practice, assisting practitioners designing and developing algorithms to actively consider dignity.",AI Ethics; Cybernetics; Dignity; Interaction Design,9798400700248,,2023,2023-11-06 01:29:55,2023-11-06 01:29:55,1–8,OzCHI '22,Association for Computing Machinery,6GZV636E,0.1216216216216216,0.6666666666666666,0.2222222222222222,0.1515835206934683
