,Unnamed: 0.2,Category,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,Date,Date Added,Date Modified,Pages,Extra,Key,Eligibility_Abstract_Score,Eligibility_Title_Score,Eligibility_Score
0,4.0,sector,4.0,4.0,Ethical Issues in Democratizing Digital Phenotypes and Machine Learning in the Next Generation of Digital Health Technologies,Philosophy and Technology,34.0,4.0,10.1007/s13347-021-00445-8,"Mulvenna, Maurice D.; Bond, Raymond; Delaney, Jack; Dawoodbhoy, Fatema Mustansir; Boger, Jennifer; Potts, Courtney; Turkington, Robin",2021.0,https://link.springer.com/10.1007/s13347-021-00445-8,journalArticle,"Digital phenotyping is the term given to the capturing and use of user log data from health and wellbeing technologies used in apps and cloud-based services. This paper explores ethical issues in making use of digital phenotype data in the arena of digital health interventions. Products and services based on digital wellbeing technologies typically include mobile device apps as well as browser-based apps to a lesser extent, and can include telephony-based services, text-based chatbots, and voice-activated chatbots. Many of these digital products and services are simultaneously available across many channels in order to maximize availability for users. Digital wellbeing technologies offer useful methods for real-time data capture of the interactions of users with the products and services. It is possible to design what data are recorded, how and where it may be stored, and, crucially, how it can be analyzed to reveal individual or collective usage patterns. The paper also examines digital phenotyping workflows, before enumerating the ethical concerns pertaining to different types of digital phenotype data, highlighting ethical considerations for collection, storage, and use of the data. A case study of a digital health app is used to illustrate the ethical issues. The case study explores the issues from a perspective of data prospecting and subsequent machine learning. The ethical use of machine learning and artificial intelligence on digital phenotype data and the broader issues in democratizing machine learning and artificial intelligence for digital phenotype data are then explored in detail.",,2021.0,2023-11-06 14:05:11,2023-11-06 14:05:11,1945–1960,Publisher: Springer Verlag,4UZY4DMG,0.1900826446280991,0.4117647058823529,0.2059533534807806
1,7.0,sector,7.0,7.0,"Ethical Issues in Research: Perceptions of Researchers, Research Ethics Board Members and Research Ethics Experts",Journal of Academic Ethics,21.0,2.0,10.1007/s10805-022-09455-3,"Drolet, Marie-Josée; Rose-Derouin, Eugénie; Leblanc, Julie-Claude; Ruest, Mélanie; Williams-Jones, Bryn",2023.0,https://link.springer.com/10.1007/s10805-022-09455-3,journalArticle,"In the context of academic research, a diversity of ethical issues, conditioned by the different roles of members within these institutions, arise. Previous studies on this topic addressed mainly the perceptions of researchers. However, to our knowledge, no studies have explored the transversal ethical issues from a wider spectrum, including other members of academic institutions as the research ethics board (REB) members, and the research ethics experts. The present study used a descriptive phenomenological approach to document the ethical issues experienced by a heterogeneous group of Canadian researchers, REB members, and research ethics experts. Data collection involved socio-demographic questionnaires and individual semi-structured interviews. Following the triangulation of different perspectives (researchers, REB members and ethics experts), emerging ethical issues were synthesized in ten units of meaning: (1) research integrity, (2) conflicts of interest, (3) respect for research participants, (4) lack of supervision and power imbalances, (5) individualism and performance, (6) inadequate ethical guidance, (7) social injustices, (8) distributive injustices, (9) epistemic injustices, and (10) ethical distress. This study highlighted several problematic elements that can support the identification of future solutions to resolve transversal ethical issues in research that affect the heterogeneous members of the academic community.",,2023.0,2023-11-06 14:10:26,2023-11-06 14:10:26,269–292,Publisher: Springer Verlag,5BG8NK2Q,0.1538461538461538,0.4666666666666667,0.1763612608198595
2,12.0,sector,12.0,12.0,Data Ethics in Digital Health and Genomics,The New Bioethics,27.0,4.0,10.1080/20502877.2021.1996965,"Karabekmez, Muhammed Erkan",2021.0,https://www.tandfonline.com/doi/full/10.1080/20502877.2021.1996965,journalArticle,"The digital revolution has disruptively reshaped the way health services are provided and how research is conducted. This transformation has produced novel ethical challenges. The digitalization of health records, bioinformatics, molecular medicine, wearable biomedical technologies, biotechnology, and synthetic biology has created new biological data niches. How these data are shared, stored, distributed, and analyzed has created ethical problems regarding privacy, trust, accountability, fairness, and justice. This study investigates issues related to data-sharing permissions, fairness in secondary data distribution, and commercial and political conflicts of interest among individuals, companies, and states. In conclusion, establishing an agency to act as deputy trustee on behalf of individuals is recommended to intermediate the complex nature of informed consent. Focusing on decentralized digital technologies is recommended in order to catalyze the utilization of data and prevent discrimination without circulating data unnecessarily.",,2021.0,2023-11-06 14:05:09,2023-11-06 14:05:09,320–333,,VEQ6XXYR,0.1397058823529411,0.7142857142857143,0.1618051066580478
3,13.0,sector,13.0,13.0,Data Ethics in Catholic Health Systems,The National Catholic Bioethics Quarterly,22.0,2.0,10.5840/ncbq202222225,"Barina, Rachelle; Gremmels, Becket; Miller, Michael; Kockler, Nicholas; Repenshek, Mark; Ostertag, Christopher",2022.0,http://www.pdcnet.org/oom/service?url_ver=Z39.88-2004&rft_val_fmt=&rft.imuse_id=ncbq_2022_0022_0002_0289_0317&svc_id=info:www.pdcnet.org/collection,journalArticle,"The Catholic moral tradition has a rich foundation that applies broadly to encompass all areas of human experience. Yet, there is comparatively little in Catholic thought on the ethics of the collection and use of data, especially in healthcare. We provide here a brief overview of terminology, concepts, and applications of data in the context of healthcare, summarize relevant theological principles and themes (including the Vatican’s Rome Call for AI Ethics), and offer key questions for ethicists and data managers to consider as they analyze ethical implications pertinent to data governance and data management.",,2022.0,2023-11-06 14:09:47,2023-11-06 14:09:47,289–317,,PQ8GGVX6,0.1382978723404255,0.5,0.1592501297353399
4,14.0,sector,14.0,14.0,"Artificial Intelligence, Social Media and Depression. A New Concept of Health-Related Digital Autonomy",American Journal of Bioethics,21.0,7.0,10.1080/15265161.2020.1863515,"Laacke, Sebastian; Mueller, Regina; Schomerus, Georg; Salloch, Sabine",2021.0,https://www.tandfonline.com/doi/full/10.1080/15265161.2020.1863515,journalArticle,"The development of artificial intelligence (AI) in medicine raises fundamental ethical issues. As one example, AI systems in the field of mental health successfully detect signs of mental disorders, such as depression, by using data from social media. These AI depression detectors (AIDDs) identify users who are at risk of depression prior to any contact with the healthcare system. The article focuses on the ethical implications of AIDDs regarding affected users’ health-related autonomy. Firstly, it presents the (ethical) discussion of AI in medicine and, specifically, in mental health. Secondly, two models of AIDDs using social media data and different usage scenarios are introduced. Thirdly, the concept of patient autonomy, according to Beauchamp and Childress, is critically discussed. Since this concept does not encompass the specific challenges linked with the digital context of AIDDs in social media sufficiently, the current analysis suggests, finally, an extended concept of health-related digital autonomy.",,2021.0,2023-11-06 14:05:09,2023-11-06 14:05:09,4–20,Publisher: Taylor & Francis,QUBBMERR,0.1476510067114094,0.2307692307692307,0.1551670163336592
5,16.0,sector,16.0,16.0,Integrating Social Determinants of Health Into Ethical Digital Simulations,American Journal of Bioethics,23.0,9.0,10.1080/15265161.2023.2237443,"Kostick-Quenet, Kristin; Rahimzadeh, Vasiliki; Anandasabapathy, Sharmila; Hurley, Meghan; Sonig, Anika; Mcguire, Amy",2023.0,https://www.tandfonline.com/doi/full/10.1080/15265161.2023.2237443,journalArticle,"In their article, Cho and Martinez-Martin (2023) argue that developers and users of digital simulacra for modelling health and disease should involve a con- tinued focus on causality of health states, including epidemiological factors with ethical and social justice implications. The authors contend that this requires model developers to move beyond narrow perform- ance metrics so that performance evaluation standards better reflect patient, clinician, and community values and dynamics. As researchers, clinicians and legal scholars deeply involved in examining the ethical implications of digital health technologies including digital representations of patients via digital phenotyp- ing and other forms of computer perception, we agree with Cho and Martinez-Martin's solutions and wish to highlight some practical challenges, as well as offer recommendations at government, developer and user levels for acknowledging the critical role of social determinants of health (SDOH) in digital simulations.",,2023.0,2023-11-06 14:10:25,2023-11-06 14:10:25,57–60,Publisher: Taylor & Francis,YSMSNUM2,0.1214285714285714,0.5555555555555556,0.1511467923586332
6,17.0,sector,17.0,17.0,The Need to Personalise Business Ethics Education,Journal of Business Ethics Education,19.0,,10.5840/jbee2022199,"McGrane, Fódhla",2022.0,http://www.pdcnet.org/oom/service?url_ver=Z39.88-2004&rft_val_fmt=&rft.imuse_id=jbee_2022_0019_0153_0168&svc_id=info:www.pdcnet.org/collection,journalArticle,"Can business ethics textbooks and modules prepare business students to manage ethical challenges if they bypass students’ personal ethics? This paper is an academic reflection by a Higher Education, business ethics tutor in the UK and Ireland. It charts a pedagogic journey of moving away from lecturing based on the contents of the standard, “impersonal”, business ethics textbook, to moving towards facilitating interaction among students about their ethics in all parts of life, and especially “at work” in their part-time employment. The rationale for this pedagogic shift is supported by excerpts from Journal of Business Ethics Education (JBEE) articles and by current, UK, Higher Education (HE), quality frameworks. Qualitative student feedback on their experience of this more personal design of a business ethics module is included. Ten exercise suggestions and resources are offered. Business ethics textbook authors and tutors are recommended to begin their content with exercises in personal ethics.",,2022.0,2023-11-06 14:09:51,2023-11-06 14:09:51,153–168,,6BT5R3HU,0.14,0.2857142857142857,0.1467358490566037
7,26.0,sector,26.0,26.0,Correction: Ethics of Ai and Health Care: Towards a Substantive Human Rights Framework,Topoi,42.0,3.0,10.1007/s11245-023-09926-1,"Liao, S. Matthew",2023.0,https://link.springer.com/10.1007/s11245-023-09926-1,journalArticle,"There is enormous interest in using artificial intelligence (AI) in health care contexts. But before AI can be used in such settings, we need to make sure that AI researchers and organizations follow appropriate ethical frameworks and guidelines when developing these technologies. In recent years, a great number of ethical frameworks for AI have been proposed. However, these frameworks have tended to be abstract and not explain what grounds and justifies their recommendations and how one should use these recommendations in practice. In this paper, I propose an AI ethics framework that is grounded in substantive, human rights theory and one that can help us address these questions.",,2023.0,2023-11-06 14:10:24,2023-11-06 14:10:24,903–903,Publisher: Springer Verlag,NRJZNXRG,0.1203703703703703,0.2307692307692307,0.1326210826210826
8,27.0,sector,27.0,27.0,Ethically Uncharted Territory: Providing Psychological Services to Parents in Pediatric Settings,Ethics and Behavior,31.0,2.0,10.1080/10508422.2020.1772063,"Andrews, Jack H.",2021.0,https://www.tandfonline.com/doi/full/10.1080/10508422.2020.1772063,journalArticle,"Pediatric psychologists have much to contribute to growing efforts to mitigate the impact of parent mental and behavioral health problems on children’s health and development. However, providing parent-focused psychological services within the pediatric setting brings many new ethical considerations and challenges. Guided by the American Psychological Association’s Ethics Code, this paper presents an ethical case for providing these types of services, followed by a comprehensive analysis of the unique ethical challenges likely to be encountered when doing so. Recommendations are offered to support the ethical delivery of parent-focused psychological services in pediatric settings.",,2021.0,2023-11-06 14:05:13,2023-11-06 14:05:13,77–90,Publisher: Routledge,8F2VIFT9,0.1505376344086021,0.0,0.1321279364427094
