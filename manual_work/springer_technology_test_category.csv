,Unnamed: 0.2,Category,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,Eligibility_Abstract_Score,Eligibility_Title_Score,Eligibility_Score
0,29.0,technology,30.0,30.0,Ethical AI Implementation,AI for the Good,,,10.1007/978-3-030-66913-3_11,Stefan H. Vieweg,2021.0,http://link.springer.com/chapter/10.1007/978-3-030-66913-3_11,Chapter,"A framing to safeguard ethical AI is being proposed with the “House of Ethical AI.” Its key elements that focus on trust, enlightenment, and accountability are discussed and illustrated with various examples. Finally, an implementation roadmap toward ethical AI is been proposed.",,0.3095238095238095,1.3333333333333333,0.393718671679198
1,36.0,technology,39.0,39.0,"Religion, Pandemics and Ethics. A Diaconal-Ethical Perspective on the Covid-19 Pandemic",Pandemics and Ethics,,,10.1007/978-3-662-66872-6_19,Ulrich H. J. Körtner,2023.0,http://link.springer.com/chapter/10.1007/978-3-662-66872-6_19,Chapter,"The crisis caused by the Corona pandemic is a medical, political, social and economic, but also an ethical challenge and test. It is not only about questions of medical ethics, nursing ethics and ethics in healthcare in general. The Corona crisis touches on social ethical, but also individual ethical, personal ethical and environmental ethical aspects in a very comprehensive way.",,0.35,0.1818181818181818,0.3188020934289591
2,37.0,technology,40.0,40.0,Business Ethics: A European Review,Encyclopedia of Business and Professional Ethics,,,10.1007/978-3-030-22767-8_295,Alex C. Michalos,2023.0,http://link.springer.com/referenceworkentry/10.1007/978-3-030-22767-8_295,ReferenceWorkEntry,European business ethics journal; European journal on social responsibility of business; Journal on business ethics for Europeans,,0.2941176470588235,0.4,0.3162035366293756
3,38.0,technology,41.0,41.0,Ethics and Social Policy,"Global Encyclopedia of Public Administration, Public Policy, and Governance",,,10.1007/978-3-030-66252-3_2402,Anthony Bibus IIIMary S. Carlsen,2022.0,http://link.springer.com/referenceworkentry/10.1007/978-3-030-66252-3_2402,ReferenceWorkEntry,Applied Ethics; Citizenship; Codes of Ethics; Duties; Ethical Decision Making; Frameworks for Analysis; Moral Philosophy; Morality; Policy Practice; Principles; Professional Ethics; Public Administration; Public Interests; Responsibilities; Rights; Standards; Values; Virtues,,0.3,0.5,0.3160535117056856
4,40.0,technology,43.0,43.0,Artificial intelligence and medical research databases: ethical review by data access committees,BMC Medical Ethics,24.0,1.0,10.1186/s12910-023-00927-8,Francis McKayBethany J. WilliamsGraham PrestwichDaljeet BansalDarren TreanorNina Hallowell,2023.0,http://link.springer.com/article/10.1186/s12910-023-00927-8,Article,Data access committees can undertake ethical review of medical research databases provided they enhance that review function through professional and lay ethical expertise.,,0.3043478260869565,0.3333333333333333,0.3147306943543153
5,46.0,technology,50.0,50.0,Teaching Ethics Applied to AI from a Cultural Standpoint: What African “AI Ethics” for Africa?,AI Ethics in Higher Education: Insights from Africa and Beyond,,,10.1007/978-3-031-23035-6_2,Emmanuel R. Goffi,2023.0,http://link.springer.com/chapter/10.1007/978-3-031-23035-6_2,Chapter,"Ethics applied to Artificial Intelligence (AI), improperly called AI ethics, is mainly addressed through a Western perspective focusing on continental philosophy. As a result, discussions on ethics applied to AI are shaped by the West.",,0.2571428571428571,0.4,0.2979591836734693
6,48.0,technology,52.0,52.0,European Business Ethics Network,Encyclopedia of Business and Professional Ethics,,,10.1007/978-3-030-22767-8_274,Alex C. Michalos,2023.0,http://link.springer.com/referenceworkentry/10.1007/978-3-030-22767-8_274,ReferenceWorkEntry,Business ethics organization for Europe; European organization for issues on social responsibility of business; European social responsibility of business organization; Professional business ethics organization,,0.25,0.5,0.2830578512396694
7,52.0,technology,58.0,58.0,AI ethics: from principles to practice,AI & SOCIETY,,,10.1007/s00146-022-01602-z,Jianlong ZhouFang Chen,2022.0,http://link.springer.com/article/10.1007/s00146-022-01602-z,Article,"Much of the current work on AI ethics has lost its connection to the real-world impact by making AI ethics operable. There exist significant limitations of hyper-focusing on the identification of abstract ethical principles, lacking effective collaboration among stakeholders, and lacking the communication of ethical principles to real-world applications. This position paper presents challenges in making AI ethics operable and highlights key obstacles to AI ethics impact. A preliminary practice example is provided to initiate practical implementations of AI ethics. We aim to inspire discussions on making AI ethics operable and focus on its impact on real-world applications.",,0.2448979591836734,0.5,0.2583804036218103
8,54.0,technology,60.0,60.0,In defense of ethical guidelines,AI and Ethics,3.0,3.0,10.1007/s43681-022-00244-7,Björn Lundgren,2023.0,http://link.springer.com/article/10.1007/s43681-022-00244-7,Article,"Recently, Luke Munn attacked “AI ethics” generally, or guidelines, principles, codes of ethics, ethical frameworks. In particular, he argued that ethical guidelines are useless. Here I respond to this critique, arguing that Munn’s criticism is mostly unfair and misguided, and that his own proposal is already implemented in various guidelines.",,0.22,0.6,0.2523404255319149
9,56.0,technology,62.0,62.0,Corporate Digital Responsibility: Stimulating Human-Centric Innovation and Building Trust in the Digital World,Liquid Legal – Humanization and the Law,,,10.1007/978-3-031-14240-6_4,Martina Seidl,2022.0,http://link.springer.com/chapter/10.1007/978-3-031-14240-6_4,Chapter,"This article (1) highlights the development of Corporate Social Responsibility up into the digital era, (2) introduces Corporate Digital Responsibility as an emerging new field of corporate responsibility, (3) presents a framework of topics that are currently being discussed as building blocks of Corporate Digital Responsibility that aim to stimulate human-centric innovation and build trust in the digital world, and (4) provides some thoughts on how lawyers may contribute to shape corporate responsibility in the digital world.",,0.2077922077922078,0.4615384615384615,0.2512689802409428
10,57.0,technology,63.0,63.0,Business Ethics for the Digital Era,Business Ethics and Digitization,,,10.1007/978-3-662-64094-4_1,Christoph Lütge,2022.0,http://link.springer.com/chapter/10.1007/978-3-662-64094-4_1,Chapter,"We are currently experiencing a fourth industrial revolution. In this paper, the great opportunities and challenges of change through digital technologies are presented. These ethical risks and benefits are classified and highlighted in the historical and economic ethical discourse. On this basis, the authors define a business ethics for digital technology, companies and markets. The aim of this chapter is to bridge the gap between the ethics of digitalization and business ethics that has not been made before. The main message of the chapter is that digital technologies need good ethical rules to experience social acceptance. People would benefit from the new technologies and experience ethical improvements. The fact that these changes will mainly be driven by companies makes business ethics a central discipline in the discussion of ethical challenges of digital change.",,0.2330827067669172,0.6666666666666666,0.2496317128699611
11,58.0,technology,64.0,64.0,Towards AI ethics’ institutionalization: knowledge bridges from business ethics to advance organizational AI ethics,AI and Ethics,3.0,1.0,10.1007/s43681-022-00150-y,Mario D. SchultzPeter Seele,2023.0,http://link.springer.com/article/10.1007/s43681-022-00150-y,Article,"This paper proposes to generate awareness for developing Artificial intelligence (AI) ethics by transferring knowledge from other fields of applied ethics, particularly from business ethics, stressing the role of organizations and processes of institutionalization. With the rapid development of AI systems in recent years, a new and thriving discourse on AI ethics has (re-)emerged, dealing primarily with ethical concepts, theories, and application contexts. We argue that business ethics insights may generate positive knowledge spillovers for AI ethics, given that debates on ethical and social responsibilities have been adopted as voluntary or mandatory regulations for organizations in both national and transnational contexts. Thus, business ethics may transfer knowledge from five core topics and concepts researched and institutionalized to AI ethics: (1) stakeholder management, (2) standardized reporting, (3) corporate governance and regulation, (4) curriculum accreditation, and as a unified topic (5) AI ethics washing derived from greenwashing. In outlining each of these five knowledge bridges, we illustrate current challenges in AI ethics and potential insights from business ethics that may advance the current debate. At the same time, we hold that business ethics can learn from AI ethics in catching up with the digital transformation, allowing for cross-fertilization between the two fields. Future debates in both disciplines of applied ethics may benefit from dialog and cross-fertilization, meant to strengthen the ethical depth and prevent ethics washing or, even worse, ethics bashing.",,0.222707423580786,0.5714285714285714,0.2459017162369429
12,59.0,technology,66.0,66.0,An Introduction to Ethics and AI,Human-Centered Artificial Intelligence,,,10.1007/978-3-031-24349-3_13,Guido BoellaMaurizio Mori,2023.0,http://link.springer.com/chapter/10.1007/978-3-031-24349-3_13,Chapter,"In this paper we discuss the relationship between Ethics and AI. First, we present a non-exhaustive panorama of ethical issues raised by AI, with a focus on the fact that not all problems can be solved by technological advancements. Second, we introduce what is Ethics and how AI may need changing it. Finally, we will consider how AI can impact current ethical theories.",,0.2222222222222222,0.5,0.2442790184725668
13,61.0,technology,68.0,68.0,Ecological and Ethical Contexts of Digital Literacy in the Light of Phenomenographic Studies,Information Literacy in a Post-Truth Era,,,10.1007/978-3-030-99885-1_14,Jela Steinerová,2022.0,http://link.springer.com/chapter/10.1007/978-3-030-99885-1_14,Chapter,"The paper is aimed at exploration of new contexts of the concept of digital literacy from the perspective of phenomenographic studies. Concepts and basic models of digital literacy are briefly summarized. Results of phenomenographic studies of information literacy are related to digital literacy concepts. Following the sociocultural background, we frame the concepts of digital literacy into ecological and ethical factors of digital information. We apply a meta-analysis of three selected phenomenographic studies in Slovakia related to information literacy, information ethics and information behavior. Common ecological and ethical factors were found, namely emotions, responsibility, truth and value of information. A new interpretation of digital information literacy is derived, based on social representations of experiencing digital information. Ethical awareness of digital resources and ecological adaptations are emphasized. We recommed including values of information, verification of information, digital creativity and experiences into digital information literacy development and courses.",,0.2275862068965517,0.3846153846153846,0.239655283212452
14,62.0,technology,69.0,69.0,Should explainability be a fifth ethical principle in AI ethics?,AI and Ethics,3.0,1.0,10.1007/s43681-022-00152-w,João Figueiredo Nobre Brito CorteseFabio Gagliardi CozmanMarcos Paulo Lucca-SilveiraAdriano Figueiredo Bechara,2023.0,http://link.springer.com/article/10.1007/s43681-022-00152-w,Article,"It has been recently claimed that explainability should be added as a fifth principle to AI ethics, supplementing the four principles that are usually accepted in Bioethics: Autonomy, Beneficence, Nonmaleficence and Justice. We propose here that with regard to AI, on the one hand explainability is indeed a new dimension of ethical concern that should be paid attention to, while on the other hand, explainability in itself should not necessarily be considered an ethical “principle”. We think of explainability rather (i) as an epistemic requirement for taking into account ethical principles, but not as an ethical principle in itself; (ii) as an ethical demand that can be derived from ethical principles. We do agree that explainability is a key demand in AI Ethics, with practical importance for stakeholders to take into account; but we argue that it should not be considered as a fifth ethical principle, to maintain a philosophical consistency in the organization of AI ethical principles.",,0.2151898734177215,0.6,0.2383799375432072
15,64.0,technology,72.0,72.0,The Ethics of AI Ethics. A Constructive Critique,Philosophy & Technology,35.0,3.0,10.1007/s13347-022-00557-9,Jan-Christoph Heilinger,2022.0,http://link.springer.com/article/10.1007/s13347-022-00557-9,Article,"The paper presents an ethical analysis and constructive critique of the current practice of AI ethics. It identifies conceptual substantive and procedural challenges and it outlines strategies to address them. The strategies include countering the hype and understanding AI as ubiquitous infrastructure including neglected issues of ethics and justice such as structural background injustices into the scope of AI ethics and making the procedures and fora of AI ethics more inclusive and better informed with regard to philosophical ethics. These measures integrate the perspective of AI justice into AI ethics, strengthening its capacity to provide comprehensive normative orientation and guidance for the development and use of AI that actually improves human lives and living together.",,0.208695652173913,0.625,0.2325982941543582
16,67.0,technology,76.0,76.0,The AI life cycle: a holistic approach to creating ethical AI for health decisions,Nature Medicine,28.0,11.0,10.1038/s41591-022-01993-y,Madelena Y. NgSupriya KapurKatherine D. BlizinskyTina Hernandez-Boussard,2022.0,http://link.springer.com/article/10.1038/s41591-022-01993-y,Article,"The ethical impact of AI algorithms in healthcare should be assessed at each phase, from data creation to model deployment, so that their use narrows rather than widens inequalities.",,0.1724137931034483,0.3571428571428571,0.2297917599641737
17,72.0,technology,82.0,82.0,AI Principles,Building Responsible AI Algorithms,,,10.1007/978-1-4842-9306-5_2,Toju Duke,2023.0,http://link.springer.com/chapter/10.1007/978-1-4842-9306-5_2,Chapter,"The first chapter set the foundation for responsible AI frameworks, kicking off with responsibility and a few examples of AI and its ethical limitations. This chapter delves into “AI principles,” which are fundamental components of building responsible AI systems.",,0.2051282051282051,0.5,0.2189669536239933
18,75.0,technology,85.0,85.0,Social Inclusion and Research,Handbook of Social Inclusion,,,10.1007/978-3-030-89594-5_29,Ana M. Sobočan,2022.0,http://link.springer.com/referenceworkentry/10.1007/978-3-030-89594-5_29,ReferenceWorkEntry,"Research is an endeavor marked by privilege and authority, prone to misconduct, and shaped by responsibilities and relationships. Ethical issues undeniably permeate all research, and it is important that questions of ethical practice in research and the ethical foundations of research be addressed along a broad spectrum of issues that includes research processes, methods, and purposes; forms of interpretation; and issues related to the values and ethical choices of those who conduct the research. Research ethics introduces complexity into research processes. While the standards and ethical principles of research may (often) seem very simple, ethical dilemmas and controversies abound in research practice. Research ethics is about conducting research responsibly and in a morally defensible manner while adhering to relevant ethical principles. Many researchers in the field of social inclusion would certainly agree that the ethical lens needs to go beyond a legalistic and codified understanding of research ethics to address the sociopolitical embeddedness of ethical principles and how research can serve as a means of providing knowledge, improving social justice, realizing human rights, and mobilizing social equality and inclusion. In this context, this chapter raises issues related to research ethics and integrity and suggests possible ethical considerations for research from its inception to possible social action, calling for researchers to develop ethical awareness. Ethical practice involves anticipating and responding to ethical dilemmas and taking ethical considerations into account (at every stage of the research process).",,0.2170212765957447,0.0,0.2132795304475422
19,76.0,technology,86.0,86.0,Protecting privacy and promoting learning: blockchain and privacy preserving technology should inform new ethical guidelines for health data,Health and Technology,11.0,5.0,10.1007/s12553-021-00589-9,Marielle GrossRobert C. Miller,2021.0,http://link.springer.com/article/10.1007/s12553-021-00589-9,Article,Our current legal protections and ethical oversight have been insufficient for guarding against ethical violations involving our health data in the modern age. Concerns regarding the governance and privacy of health data are growing in tandem with calls for updated ethical guidelines for data-driven research. In this piece we discuss how blockchain technology and privacy preserving forms of computation may be foundational for new ethical guidelines given their potential to resolve the fundamental tensions between our concurrent obligations to protect individuals’ health data rights and to promote learning from health data for the good of society.,,0.1875,0.3333333333333333,0.2132136859781696
20,77.0,technology,87.0,87.0,Trust and ethics in AI,AI & SOCIETY,38.0,2.0,10.1007/s00146-022-01473-4,Hyesun ChoungPrabu DavidArun Ross,2023.0,http://link.springer.com/article/10.1007/s00146-022-01473-4,Article,"With the growing influence of artificial intelligence (AI) in our lives, the ethical implications of AI have received attention from various communities. Building on previous work on trust in people and technology, we advance a multidimensional, multilevel conceptualization of trust in AI and examine the relationship between trust and ethics using the data from a survey of a national sample in the U.S. This paper offers two key dimensions of trust in AI—human-like trust and functionality trust—and presents a multilevel conceptualization of trust with dispositional, institutional, and experiential trust each significantly correlated with trust dimensions. Along with trust in AI, we examine perceptions of the importance of seven ethics requirements of AI offered by the European Commission’s High-Level Expert Group. Then the association between ethics requirements and trust is evaluated through regression analysis. Findings suggest that the ethical requirement of societal and environmental well-being is positively associated with human-like trust in AI. Accountability and technical robustness are two other ethical requirements, which are significantly associated with functionality trust in AI. Further, trust in AI was observed to be higher than trust in other institutions. Drawing from our findings, we offer a multidimensional framework of trust that is inspired by ethical values to ensure the acceptance of AI as a trustworthy technology.",,0.2037914691943128,0.8,0.2126480442636747
21,79.0,technology,89.0,89.0,Epistemic Just and Dynamic AI Ethics in Africa,Responsible AI in Africa,,,10.1007/978-3-031-08215-3_2,Emma Ruttkamp-Bloem,2023.0,http://link.springer.com/chapter/10.1007/978-3-031-08215-3_2,Chapter,"This chapter considers the potential for actualising the ideal for responsible AI on the African continent, focusing on the AI ethics policy environment in Africa. I consider the impact of context and culture on successful adoption of AI technologies in general and on trust in AI technology and openness to AI regulation in particular. It concludes that actionable AI ethics in Africa should be driven by dynamic and epistemic just ethical systems.",,0.1944444444444444,0.375,0.2112233445566778
22,81.0,technology,91.0,91.0,The 2020 Yearbook of the Digital Ethics Lab,Digital Ethics Lab Yearbook,,,10.1007/978-3-030-80083-3,Josh CowlsJessica Morley,2021.0,http://link.springer.com/book/10.1007/978-3-030-80083-3,Book,"
This annual edited volume presents an overview of cutting-edge research areas within digital ethics as defined by the Digital Ethics Lab of the University of Oxford. It identifies new challenges and opportunities of influence in setting the research agenda in the field.
The 2020 edition of the yearbook presents research on the following topics: governing digital health, visualising governance, the digital afterlife, the possibility of an AI winter, the limits of design theory in philosophy, cyberwarfare, ethics of online behaviour change, governance of AI, trust in AI, and Emotional Self-Awareness as a Digital Literacy. This book appeals to students, researchers and professionals in the field.
",,0.1923076923076923,0.5,0.2100195654412522
23,82.0,technology,92.0,92.0,You cannot have AI ethics without ethics,AI and Ethics,1.0,1.0,10.1007/s43681-020-00013-4,Dave Lauer,2021.0,http://link.springer.com/article/10.1007/s43681-020-00013-4,Article,"In this paper, I will examine the reasons that ethical deployment of AI has been so elusive for so many high-profile organizations, and I’ll explain why there have been such egregious examples of unethical AI built and deployed into the world. I will draw on examples and lessons from other fields, such as medical ethics and systems theory, to demonstrate that AI ethics simply cannot exist without a broader culture of ethics. I will make the case that only organizations with a firm grounding in ethics, and an appreciation for the way complex systems behave can succeed at ethical deployment of AI.",,0.1764705882352941,0.7142857142857143,0.2099793188303358
24,83.0,technology,94.0,94.0,Basic Issues in AI Policy,"Interactive Robotics: Legal, Ethical, Social and Economic Aspects",,,10.1007/978-3-031-04305-5_1,Vincent C. Müller,2022.0,http://link.springer.com/chapter/10.1007/978-3-031-04305-5_1,Chapter,"This short paper summarises some of the basic points of AI ethics and policy as they present themselves now. We explain the notion of AI, the main ethical issues in AI and the main policy aims and means.",,0.2105263157894736,0.2,0.2093721144967682
25,85.0,technology,96.0,96.0,Ethical Issues of AI,Artificial Intelligence for a Better Future,,,10.1007/978-3-030-69978-9_4,Bernd Carsten Stahl,2021.0,http://link.springer.com/chapter/10.1007/978-3-030-69978-9_4,Chapter,"This chapter discusses the ethical issues
 that are raised by the development, deployment and use of AI. It starts with a review of the (ethical) benefits of AI and then presents the findings of the SHERPA
 project, which used case studies and a Delphi study to identify what people perceived to be ethical issues
. These are discussed using the categorisation of AI technologies introduced earlier. Detailed accounts are given of ethical issues
 arising from machine learning
, from artificial general intelligence
 and from broader socio-technical systems
 that incorporate AI.",,0.1818181818181818,1.0,0.2091364395204128
26,88.0,technology,100.0,100.0,Do ethical leaders enhance employee ethical behaviors?,Asian Journal of Business Ethics,11.0,1.0,10.1007/s13520-022-00143-4,Hussam Al HalbusiThomas Li-Ping TangKent A. WilliamsT. Ramayah,2022.0,http://link.springer.com/article/10.1007/s13520-022-00143-4,Article,"Corruption devours profits, people, and the planet. Ethical leaders promote ethical behaviors. We develop a first-stage moderated mediation theoretical model, explore the intricate relationships between ethical leadership (member rated, Time 1) and employee ethical behaviors (leader rated, Time 3), and treat ethical climate and organizational justice (member rated, 
Time 2) as dual mediators and leaders’ moral attentiveness (leader rated, Time 3) as a moderator. We investigate leadership from two perspectives—leaders’ self-evaluation of moral attentiveness and members’ perceptions of ethical leadership. We theorize: These dual mediation mechanisms are more robust for high moral leaders than low moral leaders. Our three-wave data collected from multiple sources, 236 members and 98 immediate supervisors in the Republic of Iraq, support our theory. Specifically, ethical leadership robustly impacts organizational justice’s intensity and magnitude, leading to high employee ethical behaviors when leaders’ moral attentiveness is high than low. However, ethical leadership only influences the ethical climate’s intensity but has no impact on the magnitude when leaders’ moral attentiveness is high than low. Therefore, organizational justice is a more robust mediator than the ethical climate in the omnibus context of leader moral attentiveness. Our findings support Western theory and constructs, demonstrating a new theory for Muslims in Arabic’s emerging markets. Individual decision-makers (subordinates) apply their values (ethical leadership) as a lens to frame their concerns in the immediate (organizational justice and ethical climate) and omnibus (leader moral attentiveness) contexts to maximize their expected utility and ultimate serenity-happiness. Ethical leadership trickles down to employee ethical behaviors, providing practical implications for improving the ethical environment, corporate social responsibility, leader-member exchange (LMX), business ethics, and economic potentials in the global competitive markets.",,0.1902985074626865,0.8571428571428571,0.2074459335973195
27,89.0,technology,101.0,101.0,Ethical Artificial Intelligence in the Italian Defence: a Case Study,Digital Society,2.0,2.0,10.1007/s44206-023-00056-0,Rosanna FanniFernando Giancotti,2023.0,http://link.springer.com/article/10.1007/s44206-023-00056-0,Article,"The ethical or responsible use of Artificial Intelligence (AI) is central to numerous civilian AI governance frameworks and to literature. Not so in defence: only a handful of governments have engaged with ethical questions arising from the development and use of AI in and for defence. This paper fills a critical gap in the AI ethics literature by providing evidence on the perception of ethical AI within a national defence institution. Our qualitative case study analyses how the collective Italian Defence leadership thinks about deploying AI systems and the ethical implications. We interviewed 15 leaders about the impact of AI on the Italian Defence, key ethical challenges, and responsibility for future action. Our findings suggest that Italian Defence leaders are keen to address ethical issues but encounter challenges in developing a system governance approach to implement ethical AI across the organisation. Guidance on risk management and human–machine interaction, applied education, and interdisciplinary research, as well as guidance on AI defence ethics by the European Union are critical elements for Italian Defence leaders as they adapt their organisational processes to the AI-enabled digital transformation.",,0.2021857923497267,0.3,0.207302227826818
28,90.0,technology,102.0,102.0,AI Integration in the Digital Transformation Strategy,Artificial Intelligence for Business,,,10.1007/978-3-030-88241-9_5,Ana Landeta Echeberria,2022.0,http://link.springer.com/chapter/10.1007/978-3-030-88241-9_5,Chapter,"This chapter presents three frameworks (Digital Strategic Framework, AI readiness and AI integration in Digital Transformation Strategy Model) that help to address new businesses challenges and a series of strategic-operational suggestions that permit an initial and future approach associated with AI integration, as new technological elements of the Digital Transformation Strategy.",,0.1764705882352941,0.4285714285714285,0.2070457473607292
29,92.0,technology,104.0,104.0,Artificial Intelligence (AI) in Islamic Ethics: Towards Pluralist Ethical Benchmarking for AI,Philosophy & Technology,36.0,4.0,10.1007/s13347-023-00668-x,Ezieddin Elmahjub,2023.0,http://link.springer.com/article/10.1007/s13347-023-00668-x,Article,"The paper outlines Islamic parameters for ethical values and moral actions in the context of AI's ethical uncertainties. It emphasizes the significance of both textual and non-textual Islamic sources in addressing these uncertainties while placing a strong emphasis on the notion of ""good"" or ""maṣlaḥa"" as a normative guide for AI's ethical evaluation. Defining maṣlaḥa as an ethical state of affairs in harmony with divine will, the paper highlights the coexistence of two interpretations of maṣlaḥa: welfarist/utility-based and duty-based. Islamic jurisprudence allows for arguments supporting ethical choices that prioritize building the technical infrastructure for AI to maximize utility. Conversely, it also supports choices that reject consequential utility calculations as the sole measure of value in determining ethical responses to AI advancements.",,0.1652892561983471,0.5833333333333334,0.2061275956663657
30,94.0,technology,106.0,106.0,Sustained Enablement of AI Ethics in Industry,"Systems, Software and Services Process Improvement",,,10.1007/978-3-031-42307-9_1,Martina FlatscherAnja FesslerIsabel Janez,2023.0,http://link.springer.com/chapter/10.1007/978-3-031-42307-9_1,Chapter,"Artificial Intelligence (AI) has become an increasingly pervasive technology in various industries, offering numerous benefits such as increased efficiency, productivity, and innovation. However, the ethical implications of AI adoption in industry have raised concerns and AI ethics has emerged as a critical field of study, focusing on the trustworthy development, deployment, and use of AI technologies. In this paper, we explore an AI Ethics concept with a particular focus on sustained enabling factors to guide organizations in navigating the ethical challenges associated with AI adoption.",,0.188235294117647,0.4285714285714285,0.2051339285714285
31,96.0,technology,108.0,108.0,Philosophical foundations for digital ethics and AI Ethics: a dignitarian approach,AI and Ethics,1.0,4.0,10.1007/s43681-021-00040-9,Robert HannaEmre Kazim,2021.0,http://link.springer.com/article/10.1007/s43681-021-00040-9,Article,"AI Ethics is a burgeoning and relatively new field that has emerged in response to growing concerns about the impact of artificial intelligence (AI) on human individuals and their social institutions. In turn, AI ethics is a part of the broader field of digital ethics, which addresses similar concerns generated by the development and deployment of new digital technologies. Here, we tackle the important worry that digital ethics in general, and AI ethics in particular, lack adequate philosophical foundations. In direct response to that worry, we formulate and rationally justify some basic concepts and principles for digital ethics/AI ethics, all drawn from a broadly Kantian theory of human dignity. Our argument, which is designed to be relatively compact and easily accessible, is presented in ten distinct steps: (1) what “digital ethics” and “AI ethics” mean, (2) refuting the dignity-skeptic, (3) the metaphysics of human dignity, (4) human happiness or flourishing, true human needs, and human dignity, (5) our moral obligations with respect to all human real persons, (6) what a natural automaton or natural machine is, (7) why human real persons are not natural automata/natural machines: because consciousness is a form of life, (8) our moral obligations with respect to the design and use of artificial automata or artificial machines, aka computers, and digital technology more generally, (9) what privacy is, why invasions of digital privacy are morally impermissible, whereas consensual entrances into digital privacy are either morally permissible or even obligatory, and finally (10) dignitarian morality versus legality, and digital ethics/AI ethics. We conclude by asserting our strongly-held belief that a well-founded and generally-accepted dignitarian digital ethics/AI ethics is of global existential importance for humanity.",,0.1847826086956521,0.6363636363636364,0.2039193757596184
32,99.0,technology,111.0,111.0,The ethical agency of AI developers,AI and Ethics,,,10.1007/s43681-022-00256-3,Tricia A. GriffinBrian Patrick GreenJos V. M. Welie,2023.0,http://link.springer.com/article/10.1007/s43681-022-00256-3,Article,"Public and academic discourse about the ethics of artificial intelligence, machine learning, and data science has largely focused on the algorithms and the companies deploying them. Little attention has been paid to the ethical agency of the developers. This study is the first of its kind that centers developers in the ethical environment. Semi-structured interviews with 40 developers about the ethics of being a developer revealed more than 20 themes, 3 of which are the subject of this paper: ethics in the occupational ecosystem, developer ethical agency, and the characteristics of an ethical developer. These themes reveal significant gaps between how developers perceive themselves and the reality of their work experiences. Their ethical agency is likewise variable. They have some authority to intervene for ethical reasons in systems they work on, but they often do not realize just how many ethical decisions they make. Nonetheless, this study reveals a growing ethical wisdom in this community, one that needs to be surfaced and nurtured by engaging with developers.",,0.1867469879518072,0.6666666666666666,0.2018117312298521
33,104.0,technology,119.0,119.0,The latent space of data ethics,AI & SOCIETY,,,10.1007/s00146-023-01757-3,Enrico Panai,2023.0,http://link.springer.com/article/10.1007/s00146-023-01757-3,Article,"In informationally mature societies, almost all organisations record, generate, process, use, share and disseminate data. In particular, the rise of AI and autonomous systems has corresponded to an improvement in computational power and in solving complex problems. However, the resulting possibilities have been coupled with an upsurge of ethical risks. To avoid the misuse, underuse, and harmful use of data and data-based systems like AI, we should use an ethical framework appropriate to the object of its reasoning. Unfortunately, in recent years, the space for data-related ethics has not been precisely defined in organisations. As a consequence, there has been an overlapping of responsibilities and a void of clear accountabilities. Ethical issues have, therefore, been dealt with using inadequate levels of abstraction (e.g. legal, technical). Yet, if building an ethical infrastructure requires the collaboration of each body, addressing ethical issues related to data requires leaving room for the appropriate level of abstraction. This paper first aims to show how the space of data ethics is already latent in organisations. It then highlights how to redefine roles (chief data ethics officer, data ethics committee, etc.) and codes (code of data ethics) to create and maintain an environment where ethical reasoning about data, information, and AI systems may flourish.",,0.1884057971014492,0.5,0.1952322425359758
34,105.0,technology,120.0,120.0,Artificial Intelligence and Ethics,Digital Health Entrepreneurship,,,10.1007/978-3-031-33902-8_16,Doreen RosenstrauchUtpal ManglaAtul GuptaCostansia Taikwa Masau,2023.0,http://link.springer.com/chapter/10.1007/978-3-031-33902-8_16,Chapter,"In summary, the chapter “Artificial Intelligence and Ethics” part of the book Digital Health Entrepreneurship published by Springer Nature offers valuable insights into the ethical implications of AI. It emphasizes the importance of a human-centric approach to AI development and deployment, highlighting the need for safety, fairness, transparency, accountability, and inclusivity. The chapter identifies potential ethical challenges associated with AI and offers solutions to address these challenges. Ongoing interdisciplinary approaches and international collaboration are crucial in navigating the complex ethical landscape of AI and ensuring its responsible and beneficial use for the betterment of humanity.",,0.1789473684210526,0.5,0.1935406698564593
35,106.0,technology,121.0,121.0,Embedded ethics: a proposal for integrating ethics into the development of medical AI,BMC Medical Ethics,23.0,1.0,10.1186/s12910-022-00746-3,Stuart McLennanAmelia FiskeDaniel TigardRuth MüllerSami HaddadinAlena Buyx,2022.0,http://link.springer.com/article/10.1186/s12910-022-00746-3,Article,"The emergence of ethical concerns surrounding artificial intelligence (AI) has led to an explosion of high-level ethical principles being published by a wide range of public and private organizations. However, there is a need to consider how AI developers can be practically assisted to anticipate, identify and address ethical issues regarding AI technologies. This is particularly important in the development of AI intended for healthcare settings, where applications will often interact directly with patients in various states of vulnerability. In this paper, we propose that an ‘embedded ethics’ approach, in which ethicists and developers together address ethical issues via an iterative and continuous process from the outset of development, could be an effective means of integrating robust ethical considerations into the practical development of medical AI.",,0.1746031746031746,0.3846153846153846,0.1933345889274535
36,109.0,technology,124.0,124.0,Ethical Principles for Trustworthy AI,"EU Policy and Legal Framework for Artificial Intelligence, Robotics and Related Technologies - The AI Act",,,10.1007/978-3-031-27953-9_3,Nikos Th. Nikolinakos,2023.0,http://link.springer.com/chapter/10.1007/978-3-031-27953-9_3,Chapter,"This chapter covers the guiding ethical principles which should be based on the EU’s ‘human-centric’ approach to AI that is respectful of European values and principles. The chapter discusses five ethical principles (“ethical imperatives”) and their correlated values that must be respected in the development, deployment and use of AI systems. These ethical principles are: (i) respect for human autonomy; (ii) prevention of harm (non-maleficence); (iii) fairness/justice; (iv) explicability; (v) the principle of beneficence (‘do only good’), i.e., the principle of creating AI technology that is beneficial to humanity. It is explained that EU policy-makers have chosen to remain faithful to the EU’s cultural preferences and higher standard of protection against the risks posed by AI, building on the existing regulatory framework and ensuring that European values are at the heart of creating the right environment of trust for the successful development and use of AI. The overall aim of the ethics guidelines is—apart from establishing an ethical level playing field across all Member States as well as offering guidance on how to foster and secure the development of ethical AI systems—to bring a European ethical approach to the global stage, i.e. to stimulate discussion of ethical frameworks for AI “at a global level” and, therefore, to build an international consensus on AI ethics guidelines.",,0.1767441860465116,0.8,0.1927140372350705
37,111.0,technology,126.0,126.0,Ethics Auditing: Lessons from Business Ethics for Ethics Auditing of AI,The 2021 Yearbook of the Digital Ethics Lab,,,10.1007/978-3-031-09846-8_13,Noah SchöpplMariarosaria TaddeoLuciano Floridi,2022.0,http://link.springer.com/chapter/10.1007/978-3-031-09846-8_13,Chapter,"This chapter reviews the business ethics literature on ethics auditing to extract lessons for the emerging practice of ethics auditing of Artificial Intelligence (AI). It reviews the definitions, purposes and motivations of ethics audits, identifies their benefits as well as limitations, and compares various theoretical and practical approaches to ethics auditing. It distils seven lessons for the ethics auditing of AI and finds that ethics audits need to be comprehensive, involve stakeholders, entice behaviour change, be pragmatic and rigorous, be widely endorsed, fitting in context but also comparable, and lastly integrate a technical dimension with an organisational dimension. It is crucial that, while ethics auditing can also have financial benefits, their main goal must remain the improvement of the ethical performance and meaningful accountability of the audited organisation. The novel elements of AI should not blind us to the continuities of social embeddedness and organisational dynamics. Ethics auditing of AI can learn valuable lessons from failed and successful previous efforts to audit the ethics of organisations.",,0.1626506024096385,0.6363636363636364,0.1904011184250955
38,114.0,technology,129.0,129.0,An AI ethics ‘David and Goliath’: value conflicts between large tech companies and their employees,AI & SOCIETY,,,10.1007/s00146-022-01430-1,Mark RyanEleni ChristodoulouJosephina AntoniouKalypso Iordanou,2022.0,http://link.springer.com/article/10.1007/s00146-022-01430-1,Article,"Artificial intelligence ethics requires a united approach from policymakers, AI companies, and individuals, in the development, deployment, and use of these technologies. However, sometimes discussions can become fragmented because of the different levels of governance (Schmitt in AI Ethics 1–12, 2021) or because of different values, stakeholders, and actors involved (Ryan and Stahl in J Inf Commun Ethics Soc 19:61–86, 2021). Recently, these conflicts became very visible, with such examples as the dismissal of AI ethics researcher Dr. Timnit Gebru from Google and the resignation of whistle-blower Frances Haugen from Facebook. Underpinning each debacle was a conflict between the organisation’s economic and business interests and the morals of their employees. This paper will examine tensions between the ethics of AI organisations and the values of their employees, by providing an exploration of the AI ethics literature in this area, and a qualitative analysis of three workshops with AI developers and practitioners. Common ethical and social tensions (such as power asymmetries, mistrust, societal risks, harms, and lack of transparency) will be discussed, along with proposals on how to avoid or reduce these conflicts in practice (e.g., building trust, fair allocation of responsibility, protecting employees’ autonomy, and encouraging ethical training and practice). Altogether, we suggest the following steps to help reduce ethical issues within AI organisations: improved and diverse ethics education and training within businesses; internal and external ethics auditing; the establishment of AI ethics ombudsmen, AI ethics review committees and an AI ethics watchdog; as well as access to trustworthy AI ethics whistle-blower organisations.",,0.1857707509881423,0.2,0.1865212711190153
39,115.0,technology,132.0,132.0,Discussion of ethical decision mode for artificial intelligence,AI & SOCIETY,,,10.1007/s00146-022-01447-6,Guoman LiuYufeng LuoJing Sheng,2022.0,http://link.springer.com/article/10.1007/s00146-022-01447-6,Article,"At present, although artificial intelligence (AI) has made great progress in the aspects of control policy and operation, there is still no unified ethical decision mode, laws and regulations in ethical dilemma, which seriously affect application and development of artificial intelligence. Therefore, this paper studies and analyzes various ethical decision mode of AI system, then the current research status and advantages, deficiencies of these decision modes are analyzed and summarized. According to the characteristics of the current ethical decision modes and existing problems, the future implementation mode for the future ethical decision of artificial intelligence is explored and discussed. A hierarchical hybrid ethical decision mode will be proposed and designed, which has the advantages of the existing ethical decision modes. In addition, it will provide a few references for research, design and formulation of laws, regulations of AI.",,0.1739130434782608,0.375,0.1863697575990765
40,116.0,technology,133.0,133.0,Ethical Challenges of Integrating AI into Healthcare,Artificial Intelligence in Medicine,,,10.1007/978-3-030-64573-1_337,Lisa Soleymani Lehmann,2022.0,http://link.springer.com/referenceworkentry/10.1007/978-3-030-64573-1_337,ReferenceWorkEntry,"Artificial intelligence (AI) is revolutionizing healthcare, and with this transformative innovation comes the challenge of responsibly integrating AI into clinical care. AI has the potential to improve patient outcomes, increase the efficiency of healthcare diagnosis and treatment, and lower the cost of care. Leveraging these benefits, however, requires attention to the ethical risks raised by this new technology. In this chapter, I illuminate the primary ethical challenges of AI in healthcare and argue that in order to fully realize the potential of AI to improve individual and population health, we need to align AI with the ethical principles of medicine. The ethical challenges posed by AI can be categorized into the four principles commonly used in healthcare ethics: respect for autonomy, beneficence, nonmaleficence, and justice [1]. Careful consideration of the implications of these principles will allow us to maximize the benefits of AI in healthcare.",,0.1655172413793103,0.5714285714285714,0.1861702640432649
41,117.0,technology,134.0,134.0,Ethical Challenges of Integrating AI into Healthcare,Artificial Intelligence in Medicine,,,10.1007/978-3-030-58080-3_337-2,Lisa Soleymani Lehmann,2022.0,http://link.springer.com/referenceworkentry/10.1007/978-3-030-58080-3_337-2,ReferenceWorkEntry,"Artificial intelligence (AI) is revolutionizing healthcare, and with this transformative innovation comes the challenge of responsibly integrating AI into clinical care. AI has the potential to improve patient outcomes, increase the efficiency of healthcare diagnosis and treatment, and lower the cost of care. Leveraging these benefits, however, requires attention to the ethical risks raised by this new technology. In this chapter, I illuminate the primary ethical challenges of AI in healthcare and argue that in order to fully realize the potential of AI to improve individual and population health, we need to align AI with the ethical principles of medicine. The ethical challenges posed by AI can be categorized into the four principles commonly used in healthcare ethics: respect for autonomy, beneficence, nonmaleficence, and justice [1]. Careful consideration of the implications of these principles will allow us to maximize the benefits of AI in healthcare.",,0.1655172413793103,0.5714285714285714,0.1861702640432649
42,120.0,technology,137.0,137.0,Biomedical Ethical Aspects Towards the Implementation of Artificial Intelligence in Medical Education,Medical Science Educator,33.0,4.0,10.1007/s40670-023-01815-x,Felix BuschLisa C. AdamsKeno K. Bressem,2023.0,http://link.springer.com/article/10.1007/s40670-023-01815-x,Article,"The increasing use of artificial intelligence (AI) in medicine is associated with new ethical challenges and responsibilities. However, special considerations and concerns should be addressed when integrating AI applications into medical education, where healthcare, AI, and education ethics collide. This commentary explores the biomedical ethical responsibilities of medical institutions in incorporating AI applications into medical education by identifying potential concerns and limitations, with the goal of implementing applicable recommendations. The recommendations presented are intended to assist in developing institutional guidelines for the ethical use of AI for medical educators and students.",,0.1758241758241758,0.25,0.1850846928102799
43,121.0,technology,138.0,138.0,AI and Ethics—Operationalizing Responsible AI,Humanity Driven AI,,,10.1007/978-3-030-72188-6_2,Liming ZhuXiwei XuQinghua LuGuido GovernatoriJon Whittle,2022.0,http://link.springer.com/chapter/10.1007/978-3-030-72188-6_2,Chapter,"In the last few years, AI continues demonstrating its positive impact on society while sometimes with ethically questionable consequences. Building and maintaining public trust in AI has been identified as the key to successful and sustainable innovation. This chapter discusses the challenges related to operationalizing ethical AI principles and presents an integrated view that covers high-level ethical AI principles, general notion of trust/trustworthiness, and product/process support in the context of responsible AI, which helps improve both trust and trustworthiness of AI for a wider set of stakeholders.",,0.160919540229885,0.5,0.1840737446147942
44,122.0,technology,139.0,139.0,How AI Can Be a Force for Good – An Ethical Framework to Harness the Potential of AI While Keeping Humans in Control,"Ethics, Governance, and Policies in Artificial Intelligence",,,10.1007/978-3-030-81907-1_7,Mariarosaria TaddeoLuciano Floridi,2021.0,http://link.springer.com/chapter/10.1007/978-3-030-81907-1_7,Chapter,"The article has the goal of indicating how to harness the potential for good of artificial intelligence (AI) – defined as a distinct form of autonomous and self- learning agency and thus raises unique ethical challenges – while mitigating its ethical challenges. The analyses focuses first on uses of AI that may lead to undue discrimination, lack of explainability, the responsibility gap, and the nudging potential of AI and its negative impact on human self-determination. It then turns on the role that ethical analyses in harnessing the potential for good of AI and argues that existing guidelines for the ethics design, development and use of AI will be effective insofar as they are translated into viable guidelines to shape AI-based innovation and that this is the task of digital ethics as a translational ethics.",,0.1791044776119403,0.217391304347826,0.1838342666442755
45,123.0,technology,140.0,140.0,Ethical Issues in Social Science Research Employing Big Data,Science and Engineering Ethics,28.0,3.0,10.1007/s11948-022-00380-7,Mohammad HosseiniMichał WieczorekBert Gordijn,2022.0,http://link.springer.com/article/10.1007/s11948-022-00380-7,Article,"This paper analyzes the ethics of social science research (SSR) employing big data. We begin by highlighting the research gap found on the intersection between big data ethics, SSR and research ethics. We then discuss three aspects of big data SSR which make it warrant special attention from a research ethics angle: (1) the interpretative character of both SSR and big data, (2) complexities of anticipating and managing risks in publication and reuse of big data SSR, and (3) the paucity of regulatory oversight and ethical recommendations on protecting individual subjects as well as societies when conducting big data SSR. Against this backdrop, we propose using David Resnik’s research ethics framework to analyze some of the most pressing ethical issues of big data SSR. Focusing on the principles of honesty, carefulness, openness, efficiency, respect for subjects, and social responsibility, we discuss three clusters of ethical issues: those related to methodological biases and personal prejudices, those connected to risks arising from data availability and reuse, and those leading to individual and social harms. Finally, we advance considerations to observe in developing future ethical guidelines about big data SSR.",,0.1711229946524064,0.4444444444444444,0.1838159412371759
46,126.0,technology,144.0,144.0,Ethics of Quantum Computing: an Outline,Philosophy & Technology,36.0,3.0,10.1007/s13347-023-00651-6,Luca M. Possati,2023.0,http://link.springer.com/article/10.1007/s13347-023-00651-6,Article,"This paper intends to contribute to the emerging literature on the ethical problems posed by quantum computing and quantum technologies in general. The key ethical questions are as follows: Does quantum computing pose new ethical problems, or are those raised by quantum computing just a different version of the same ethical problems raised by other technologies, such as nanotechnologies, nuclear plants, or cloud computing? In other words, what is new in quantum computing from an ethical point of view? The paper aims to answer these two questions by (a) developing an analysis of the existing literature on the ethical and social aspects of quantum computing and (b) identifying and analyzing the main ethical problems posed by quantum computing. The conclusion is that quantum computing poses completely new ethical issues that require new conceptual tools and methods.",,0.1764705882352941,0.3333333333333333,0.1831638563521689
47,128.0,technology,146.0,146.0,Introduction – The Importance of an Ethics-First Approach to the Development of AI,"Ethics, Governance, and Policies in Artificial Intelligence",,,10.1007/978-3-030-81907-1_1,Luciano Floridi,2021.0,http://link.springer.com/chapter/10.1007/978-3-030-81907-1_1,Chapter,"This is the introduction to the volume. It highlights the various “seasons” through which the development of AI has gone, and how the failures and successes of AI raise ethical questions, and require an ethical approach.",,0.2222222222222222,0.0769230769230769,0.1827701364125205
48,129.0,technology,147.0,147.0,"Artificial Intelligence: Benefits, Application, Ethical Issues, and Organizational Responses",Intelligent Sustainable Systems,,,10.1007/978-981-19-7660-5_62,Khalda AliMaram AlzaidiDimah Al-FraihatAmir M. Elamir,2023.0,http://link.springer.com/chapter/10.1007/978-981-19-7660-5_62,Chapter,"Artificial intelligence (AI) ethics is a hotly debated subject. Increasingly, both service providers and users face ethical dilemmas. To ensure that the development, deployment, and usage of AI are all morally permissible, various initiatives have been launched. For the most part, it's not clear how AI-enabled businesses deal with these ethical challenges. Our paper identified four main ethical issues of AI (i.e. “Ubiquitous surveillance, social engineering, transhumanism, machine learning issues, and metaphysical issues”). It also identified two main mitigation strategies (i.e. “Policy-level mitigation, corporate governance of AI ethics”). Many people, including those working in AI-related organisations and academia can benefit from these findings, but policymakers grappling with how to best handle ethical concerns generated by AI may find them most useful.",,0.1666666666666666,0.3333333333333333,0.1826056826056825
49,134.0,technology,152.0,152.0,Implementing AI Ethics in a Software Engineering Project-Based Learning Environment - The Case of WIMMA Lab,Software Business,,,10.1007/978-3-031-20706-8_19,Mamia Ori-otse AgbeseMarko RintamakiRahul MohananiPekka Abrahamsson,2022.0,http://link.springer.com/chapter/10.1007/978-3-031-20706-8_19,Chapter,"Increasing ethical concerns necessitate AI ethics forms part of practical software engineering (SE) foundational educational learning. Using an ethnographic approach and focus group discussions in a SE project-based learning environment, WIMMA lab, we gain insight into how AI ethics can be implemented to enable students to acquire these necessary skills. We propose a framework as an outcome to aid the implementation of AI ethics skills within SE project-based learning environments.",,0.1714285714285714,0.2307692307692307,0.1821359079369197
50,135.0,technology,153.0,153.0,Leveraging Artificial Intelligence in Marketing for Social Good—An Ethical Perspective,Journal of Business Ethics,179.0,1.0,10.1007/s10551-021-04843-y,Erik Hermann,2022.0,http://link.springer.com/article/10.1007/s10551-021-04843-y,Article,"Artificial intelligence (AI) is (re)shaping strategy, activities, interactions, and relationships in business and specifically in marketing. The drawback of the substantial opportunities AI systems and applications (will) provide in marketing are ethical controversies. Building on the literature on AI ethics, the authors systematically scrutinize the ethical challenges of deploying AI in marketing from a multi-stakeholder perspective. By revealing interdependencies and tensions between ethical principles, the authors shed light on the applicability of a purely principled, deontological approach to AI ethics in marketing. To reconcile some of these tensions and account for the AI-for-social-good perspective, the authors make suggestions of how AI in marketing can be leveraged to promote societal and environmental well-being.",,0.1696428571428571,0.3,0.1818151853575306
51,144.0,technology,165.0,165.0,"Converged AI, IoT, and blockchain technologies: a conceptual ethics framework",AI and Ethics,2.0,1.0,10.1007/s43681-021-00079-8,Esther NehmeRayane El SibaiJacques Bou AbdoA. Ross TaylorJacques Demerjian,2022.0,http://link.springer.com/article/10.1007/s43681-021-00079-8,Article,"The convergence of AI, IoT, and blockchain as the next disruptive technology is inevitable. Studying the ethics of these converged technologies is crucial for the steady development and adoption of the applications. Even though this topic is crucial, it is still not yet touched in the literature. This work is the first attempt to tackle this issue by developing a conceptual ethics framework for converged AI, IoT, and blockchain. The framework is based on a systematic literature review and categorizes the ethical issues into three layers namely micro (ethical issue involving the technology itself), meso (ethical issue involving the applications), and macro (ethical issue involving the society and institutions).",,0.1651376146788991,0.3,0.1781833479323221
52,151.0,technology,172.0,172.0,A Virtue-Based Framework to Support Putting AI Ethics into Practice,Philosophy & Technology,35.0,3.0,10.1007/s13347-022-00553-z,Thilo Hagendorff,2022.0,http://link.springer.com/article/10.1007/s13347-022-00553-z,Article,"Many ethics initiatives have stipulated sets of principles and standards for good technology development in the AI sector. However, several AI ethics researchers have pointed out a lack of practical realization of these principles. Following that, AI ethics underwent a practical turn, but without deviating from the principled approach. This paper proposes a complementary to the principled approach that is based on virtue ethics. It defines four “basic AI virtues”, namely justice, honesty, responsibility and care, all of which represent specific motivational settings that constitute the very precondition for ethical decision making in the AI field. Moreover, it defines two “second-order AI virtues”, prudence and fortitude, that bolster achieving the basic virtues by helping with overcoming bounded ethicality or hidden psychological forces that can impair ethical decision making and that are hitherto disregarded in AI ethics. Lastly, the paper describes measures for successfully cultivating the mentioned virtues in organizations dealing with AI research and development.",,0.1677419354838709,0.3,0.1754407107424119
53,158.0,technology,179.0,179.0,From AI ethics principles to data science practice: a reflection and a gap analysis based on recent frameworks and practical experience,AI and Ethics,2.0,4.0,10.1007/s43681-021-00127-3,Ilina GeorgievaClaudio LazoTjerk TimanAnne Fleur van Veenstra,2022.0,http://link.springer.com/article/10.1007/s43681-021-00127-3,Article,"In the field of AI ethics, after the introduction of ethical frameworks and the evaluation thereof, we seem to have arrived at a third wave in which the operationalisation of ethics is central. Operationalisation is required, since ethics frameworks are often not suited to be used by data scientists in the development of AI-based services or products. Therefore, in this paper, we aim to contribute to this third wave by mapping AI ethical principles onto the lifecycle of an AI-based digital service or product and combining it with an explicit governance model to clarify responsibilities in operationalisation. We then discuss practical, conceptual, and political implications of this analysis to end with key challenges around operationalising AI ethics.",,0.1709401709401709,0.1904761904761904,0.1738869448366655
54,162.0,technology,183.0,183.0,The need for health AI ethics in medical school education,Advances in Health Sciences Education,26.0,4.0,10.1007/s10459-021-10040-3,Gali KatznelsonSara Gerke,2021.0,http://link.springer.com/article/10.1007/s10459-021-10040-3,Article,"Health Artificial Intelligence (AI) has the potential to improve health care, but at the same time, raises many ethical challenges. Within the field of health AI ethics, the solutions to the questions posed by ethical issues such as informed consent, bias, safety, transparency, patient privacy, and allocation are complex and difficult to navigate. The increasing amount of data, market forces, and changing landscape of health care suggest that medical students may be faced with a workplace in which understanding how to safely and effectively interact with health AIs will be essential. Here we argue that there is a need to teach health AI ethics in medical schools. Real events in health AI already pose ethical challenges to the medical community. We discuss key ethical issues requiring medical school education and suggest that case studies based on recent real-life examples are useful tools to teach the ethical issues raised by health AIs.",,0.1655629139072847,0.3,0.1731650110375276
55,163.0,technology,184.0,184.0,Ethics and Participatory Health Research,Handbook of Social Inclusion,,,10.1007/978-3-030-89594-5_30,Barbara C. GrootTineke A. Abma,2022.0,http://link.springer.com/referenceworkentry/10.1007/978-3-030-89594-5_30,ReferenceWorkEntry,"Participatory Health Research (PHR) and related participatory action research approaches share the normative ideals of transformation, social justice, and inclusion. PHR researchers seek, together with people who are involved in an issue, to make a difference and improve local situations. Ethics is at the core of this type of inclusive research. This means not simply “doing ethics” by submitting a proposal to an Ethics Commission Board, but is an integral part of what participatory researchers do. It means practicing research in an inclusive and democratic way and fostering mutual learning and collective action (process), with the aim to bring about social justice and social inclusion (outcome). PHR involves people who are not usually involved in research, which creates daily situations in which ethical issues may arise, such as who decides, who participates, who is excluded, what does it mean to share power equally, or whose knowledge counts. Ethics is, therefore, more than following procedures about informed consent and privacy and relates to everyday ethical issues, and relational and moral complexity. This chapter introduces the context of ethics in PHR, ethical guidelines for PHR, and the concept of ethics work in PHR. Ethics work entails seeing ethically salient issues and reflecting on everyday ethical issues. Ethical issues often relate to power differentials, partnership, and collaboration in inclusive research. Reflection on ethics in PHR, in collaboration with those who are subject of the ethical issue, is a pathway towards ethical PHR.",,0.1673640167364016,0.4,0.1731330429797643
56,164.0,technology,185.0,185.0,Ethics and Participatory Health Research,Handbook of Social Inclusion,,,10.1007/978-3-030-48277-0_30-1,Barbara C. GrootTineke A. Abma,2021.0,http://link.springer.com/referenceworkentry/10.1007/978-3-030-48277-0_30-1,ReferenceWorkEntry,"Participatory Health Research (PHR) and related participatory action research approaches share the normative ideals of transformation, social justice, and inclusion. PHR researchers seek, together with people who are involved in an issue, to make a difference and improve local situations. Ethics is at the core of this type of inclusive research. This means not simply “doing ethics” by submitting a proposal to an Ethics Commission Board, but is an integral part of what participatory researchers do. It means practicing research in an inclusive and democratic way and fostering mutual learning and collective action (process), with the aim to bring about social justice and social inclusion (outcome). PHR involves people who are not usually involved in research, which creates daily situations in which ethical issues may arise, such as who decides, who participates, who is excluded, what does it mean to share power equally, or whose knowledge counts. Ethics is, therefore, more than following procedures about informed consent and privacy and relates to everyday ethical issues, and relational and moral complexity. This chapter introduces the context of ethics in PHR, ethical guidelines for PHR, and the concept of ethics work in PHR. Ethics work entails seeing ethically salient issues and reflecting on everyday ethical issues. Ethical issues often relate to power differentials, partnership, and collaboration in inclusive research. Reflection on ethics in PHR, in collaboration with those who are subject of the ethical issue, is a pathway towards ethical PHR.",,0.1673640167364016,0.4,0.1731330429797643
57,167.0,technology,188.0,188.0,Islamic virtue-based ethics for artificial intelligence,Discover Artificial Intelligence,2.0,1.0,10.1007/s44163-022-00028-2,Amana RaquibBilal ChannaTalat ZubairJunaid Qadir,2022.0,http://link.springer.com/article/10.1007/s44163-022-00028-2,Article,"The twenty-first century technological advances driven by exponential rise of artificial intelligence (AI) technology have ushered in a new era that offers many of us hitherto unimagined luxuries and facilities. However, under the guise of this progressive discourse, particularly in the backdrop of current neo-liberal late-capitalist postmodern world, AI development also has prompted an increasingly uncertain ethical tomorrow. This paper aims to probe the question of ethics by exploring the true ramifications of AI and interrogating its various ethical dimensions. It questions the essential goodness that is attributed to unstinted AI development before elucidating the ethical repercussions of AI advancements and the aptness of the current market logics and business models that govern the tech-industry. The paper next positions a holistic Islamic virtue-based AI ethics framework grounded in the context of Islamic objectives (maqāṣid) as an alternative ethical system for AI governance. We argue that this distinctive Islamic virtue-based ethical approach, which can be used to explore AI-related ethical problems more holistically due to its ontological base and rich tradition while keeping in check undue influence from the current socio-politico-economic climate, can be a valuable addition to the global discourse on AI ethics.",,0.1658031088082901,0.3333333333333333,0.1723893578067729
58,169.0,technology,191.0,191.0,To Each Technology Its Own Ethics: The Problem of Ethical Proliferation,Philosophy & Technology,35.0,4.0,10.1007/s13347-022-00591-7,Henrik Skaug SætraJohn Danaher,2022.0,http://link.springer.com/article/10.1007/s13347-022-00591-7,Article,"Ethics plays a key role in the normative analysis of the impacts of technology. We know that computers in general and the processing of data, the use of artificial intelligence, and the combination of computers and/or artificial intelligence with robotics are all associated with ethically relevant implications for individuals, groups, and society. In this article, we argue that while all technologies are ethically relevant, there is no need to create a separate ‘ethics of X’ or ‘X ethics’ for each and every subtype of technology or technological property—e.g. computer ethics, AI ethics, data ethics, information ethics, robot ethics, and machine ethics. Specific technologies might have specific impacts, but we argue that they are often sufficiently covered and understood through already established higher-level domains of ethics. Furthermore, the proliferation of tech ethics is problematic because (a) the conceptual boundaries between the subfields are not well-defined, (b) it leads to a duplication of effort and constant reinventing the wheel, and (c) there is danger that participants overlook or ignore more fundamental ethical insights and truths. The key to avoiding such outcomes lies in a taking the discipline of ethics seriously, and we consequently begin with a brief description of what ethics is, before presenting the main forms of technology related ethics. Through this process, we develop a hierarchy of technology ethics, which can be used by developers and engineers, researchers, or regulators who seek an understanding of the ethical implications of technology. We close by deducing two principles for positioning ethical analysis which will, in combination with the hierarchy, promote the leveraging of existing knowledge and help us to avoid an exaggerated proliferation of tech ethics.",,0.1605839416058394,0.4545454545454545,0.1716036181732695
59,172.0,technology,195.0,195.0,Identifying the scope of ethical challenges caused by the Ebola epidemic 2014-2016 in West Africa: a qualitative study,"Philosophy, Ethics, and Humanities in Medicine",17.0,1.0,10.1186/s13010-022-00128-y,Saskia WilhelmyRegina MüllerDominik Gross,2022.0,http://link.springer.com/article/10.1186/s13010-022-00128-y,Article,An ethical discussion of the Ebola epidemic requires an examination of as many of the ethical dimensions involved as possible. The presented investigation of the two types of media with regard to the Ebola epidemic offers this possibility of a more comprehensive insight into this diversity as a basis for ethical discussions.,,0.173076923076923,0.1666666666666666,0.1713732963732963
60,177.0,technology,200.0,200.0,Artificial intelligence for good health: a scoping review of the ethics literature,BMC Medical Ethics,22.0,1.0,10.1186/s12910-021-00577-8,Kathleen MurphyErica Di RuggieroRoss UpshurDonald J. WillisonNeha MalhotraJia Ce CaiNakul MalhotraVincci LuiJennifer Gibson,2021.0,http://link.springer.com/article/10.1186/s12910-021-00577-8,Article,"The ethical issues surrounding AI in the field of health are both vast and complex. While AI holds the potential to improve health and health systems, our analysis suggests that its introduction should be approached with cautious optimism. The dearth of literature on the ethics of AI within LMICs, as well as in public health, also points to a critical need for further research into the ethical implications of AI within both global and public health, to ensure that its development and implementation is ethical for everyone, everywhere.",,0.1704545454545454,0.1666666666666666,0.1699551787976225
61,178.0,technology,201.0,201.0,Ethical issues deriving from the delayed adoption of artificial intelligence in medical imaging,AI and Ethics,2.0,4.0,10.1007/s43681-022-00139-7,Giuseppe Placidi,2022.0,http://link.springer.com/article/10.1007/s43681-022-00139-7,Article,"Medical imaging (MI) has assumed a central role in medicine. Artificial intelligence (AI) has revolutionized computer vision and it is also approaching to impact deeply MI. Fundamental ethical matters have raised and teams of experts around the world are involved in defining ethical borders for AI in MI. However, reading the extremely detailed proposals, it is clear that the treated ethical arguments have been completely redefined and specifically structured for AI in MI. Instead, many of them should be inherited from other technologies already in use in MI. The complete re-definition of ethical principles could produce contradictions and delays for AI adoption in MI, thus arising important ethical concerns. In this paper, potential ethical issues related to AI delay are presented: the objective is to contribute to reuse some concepts from other technologies to streamline the arguments and avoid these concerns.",,0.1631205673758865,0.2307692307692307,0.1694273613134407
62,184.0,technology,207.0,207.0,The social dilemma in artificial intelligence development and why we have to solve it,AI and Ethics,2.0,4.0,10.1007/s43681-021-00120-w,Inga StrümkeMarija SlavkovikVince Istvan Madai,2022.0,http://link.springer.com/article/10.1007/s43681-021-00120-w,Article,"While the demand for ethical artificial intelligence (AI) systems increases, the number of unethical uses of AI accelerates, even though there is no shortage of ethical guidelines. We argue that a possible underlying cause for this is that AI developers face a social dilemma in AI development ethics, preventing the widespread adaptation of ethical best practices. We define the social dilemma for AI development and describe why the current crisis in AI development ethics cannot be solved without relieving AI developers of their social dilemma. We argue that AI development must be professionalised to overcome the social dilemma, and discuss how medicine can be used as a template in this process.",,0.1891891891891892,0.0,0.1687557951852742
63,200.0,technology,223.0,223.0,A Discussion on Ethical Cybersecurity Issues in Digital Service Chains,Cybersecurity of Digital Service Chains,,,10.1007/978-3-031-04036-8_10,Frédéric TronnierSebastian PapeSascha LöbnerKai Rannenberg,2022.0,http://link.springer.com/chapter/10.1007/978-3-031-04036-8_10,Chapter,"Enabling cybersecurity and protecting personal data are crucial challenges in the development and provision of digital service chains. Data and information are the key ingredients in the creation process of new digital services and products. While legal and technical problems are frequently discussed in academia, ethical issues of digital service chains and the commercialization of data are seldom investigated. Thus, based on outcomes of the Horizon2020 PANELFIT project, this work discusses current ethical issues related to cybersecurity. Utilizing expert workshops and encounters as well as a scientific literature review, ethical issues are mapped on individual steps of digital service chains. Not surprisingly, the results demonstrate that ethical challenges cannot be resolved in a general way, but need to be discussed individually and with respect to the ethical principles that are violated in the specific step of the service chain. Nevertheless, our results support practitioners by providing and discussing a list of ethical challenges to enable legally compliant as well as ethically acceptable solutions in the future.",,0.1746987951807229,0.0,0.164567133488386
64,224.0,technology,248.0,248.0,The Implications of Diverse Human Moral Foundations for Assessing the Ethicality of Artificial Intelligence,Journal of Business Ethics,178.0,4.0,10.1007/s10551-022-05057-6,Jake B. TelkampMarc H. Anderson,2022.0,http://link.springer.com/article/10.1007/s10551-022-05057-6,Article,"Organizations are making massive investments in artificial intelligence (AI), and recent demonstrations and achievements highlight the immense potential for AI to improve organizational and human welfare. Yet realizing the potential of AI necessitates a better understanding of the various ethical issues involved with deciding to use AI, training and maintaining it, and allowing it to make decisions that have moral consequences. People want organizations using AI and the AI systems themselves to behave ethically, but ethical behavior means different things to different people, and many ethical dilemmas require trade-offs such that no course of action is universally considered ethical. How should organizations using AI—and the AI itself—process ethical dilemmas where humans disagree on the morally right course of action? Though a variety of ethical AI frameworks have been suggested, these approaches do not adequately address how people make ethical evaluations of AI systems or how to incorporate the fundamental disagreements people have regarding what is and is not ethical behavior. Drawing on moral foundations theory, we theorize that a person will perceive an organization’s use of AI, its data procedures, and the resulting AI decisions as ethical to the extent that those decisions resonate with the person’s moral foundations. Since people hold diverse moral foundations, this highlights the crucial need to consider individual moral differences at multiple levels of AI. We discuss several unresolved issues and suggest potential approaches (such as moral reframing) for thinking about conflicts in moral judgments concerning AI.",,0.1694214876033057,0.0,0.1591097133293844
