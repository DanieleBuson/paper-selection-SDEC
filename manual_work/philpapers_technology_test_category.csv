,Unnamed: 0.2,Category,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,Date,Date Added,Date Modified,Pages,Extra,Key,Eligibility_Abstract_Score,Eligibility_Title_Score,Eligibility_Score
0,2.0,technology,2.0,2.0,Artificial Intelligent Systems and Ethical Agency,Journal of Human Values,29.0,1.0,10.1177/09716858221119546,"Cheruvalath, Reena",2023.0,http://journals.sagepub.com/doi/10.1177/09716858221119546,journalArticle,"The article examines the challenges involved in the process of developing artificial ethical agents. The process involves the creators or designing professionals, the procedures to develop an ethical agent and the artificial systems. There are two possibilities available to create artificial ethical agents: (a) programming ethical guidance in the artificial Intelligence (AI)-equipped machines and/or (b) allowing AI-equipped machines to learn ethical decision-making by observing humans. However, it is difficult to fulfil these possibilities due to the subjective nature of ethical decision-making. The challenge related to the developers is that they themselves lack training in ethical skills. The creators who develop an artificial ethical agent should be able to foresee the ethical issues and have knowledge about ethical decision-making to improve the ethical use of AI-equipped machines. The suggestion is that the focus should be on training professionals involved in the process of developing these artificial systems in ethics rather than developing artificial ethical agents and thereby attributing ethical agency to it.",,2023.0,2023-11-06 14:10:27,2023-11-06 14:10:27,33–47,Publisher: SAGE Publications,VYCPMM9S,0.2546583850931677,0.5,0.2648118809803592
1,4.0,technology,4.0,4.0,Ethical Issues in Democratizing Digital Phenotypes and Machine Learning in the Next Generation of Digital Health Technologies,Philosophy and Technology,34.0,4.0,10.1007/s13347-021-00445-8,"Mulvenna, Maurice D.; Bond, Raymond; Delaney, Jack; Dawoodbhoy, Fatema Mustansir; Boger, Jennifer; Potts, Courtney; Turkington, Robin",2021.0,https://link.springer.com/10.1007/s13347-021-00445-8,journalArticle,"Digital phenotyping is the term given to the capturing and use of user log data from health and wellbeing technologies used in apps and cloud-based services. This paper explores ethical issues in making use of digital phenotype data in the arena of digital health interventions. Products and services based on digital wellbeing technologies typically include mobile device apps as well as browser-based apps to a lesser extent, and can include telephony-based services, text-based chatbots, and voice-activated chatbots. Many of these digital products and services are simultaneously available across many channels in order to maximize availability for users. Digital wellbeing technologies offer useful methods for real-time data capture of the interactions of users with the products and services. It is possible to design what data are recorded, how and where it may be stored, and, crucially, how it can be analyzed to reveal individual or collective usage patterns. The paper also examines digital phenotyping workflows, before enumerating the ethical concerns pertaining to different types of digital phenotype data, highlighting ethical considerations for collection, storage, and use of the data. A case study of a digital health app is used to illustrate the ethical issues. The case study explores the issues from a perspective of data prospecting and subsequent machine learning. The ethical use of machine learning and artificial intelligence on digital phenotype data and the broader issues in democratizing machine learning and artificial intelligence for digital phenotype data are then explored in detail.",,2021.0,2023-11-06 14:05:11,2023-11-06 14:05:11,1945–1960,Publisher: Springer Verlag,4UZY4DMG,0.1900826446280991,0.4117647058823529,0.2059533534807806
2,5.0,technology,5.0,5.0,Advertising Benefits From Ethical Artificial Intelligence Algorithmic Purchase Decision Pathways,Journal of Business Ethics,178.0,4.0,10.1007/s10551-022-05048-7,"Rodgers, Waymond; Nguyen, Tam",2022.0,https://link.springer.com/10.1007/s10551-022-05048-7,journalArticle,"Artificial intelligence (AI) has dramatically changed the way organizations communicate, understand, and interact with their potential consumers. In the context of this trend, the ethical considerations of advertising when applying AI should be the core question for marketers. This paper discusses six dominant algorithmic purchase decision pathways that align with ethical philosophies for online customers when buying a product/goods. The six ethical positions include: ethical egoism, deontology (i.e., rule-based), relativist, utilitarianism, virtue ethics, and ethics of care (i.e., stakeholders’ perspective). Furthermore, this paper launches an “intelligent advertising” AI theme by examining its present and future as well as identifying the key phases of intelligent advertising. Several research questions are offered to guide future research on intelligent advertising to benefit ethical AI decision-making. Finally, several areas that can be widely applied to ethical intelligent advertising are suggested for future research.",,2022.0,2023-11-06 14:09:49,2023-11-06 14:09:49,1043–1061,Publisher: Springer Verlag,6ANUK3R3,0.1870503597122302,0.3,0.1966038094634424
3,6.0,technology,6.0,6.0,From Machine Ethics to Computational Ethics,AI and Society,36.0,1.0,10.1007/s00146-020-01010-1,"Segun, Samuel T.",2021.0,https://link.springer.com/10.1007/s00146-020-01010-1,journalArticle,"Research into the ethics of artificial intelligence is often categorized into two subareas—robot ethics and machine ethics. Many of the definitions and classifications of the subject matter of these subfields, as found in the literature, are conflated, which I seek to rectify. In this essay, I infer that using the term ‘machine ethics’ is too broad and glosses over issues that the term computational ethics best describes. I show that the subject of inquiry of computational ethics is of great value and indeed is an important frontier in developing ethical artificial intelligence systems (AIS). I also show that computational is a distinct, often neglected field in the ethics of AI. In contrast to much of the literature, I argue that the appellation ‘machine ethics’ does not sufficiently capture the entire project of embedding ethics into AI/S, and hence the need for computational ethics. This essay is unique for two reasons; first, it offers a philosophical analysis of the subject of computational ethics that is not found in the literature. Second, it offers a finely grained analysis that shows the thematic distinction among robot ethics, machine ethics and computational ethics.",,2021.0,2023-11-06 14:05:11,2023-11-06 14:05:11,263–276,,R5ZH9II3,0.1693121693121693,0.6666666666666666,0.1865870024189894
4,7.0,technology,7.0,7.0,"Ethical Issues in Research: Perceptions of Researchers, Research Ethics Board Members and Research Ethics Experts",Journal of Academic Ethics,21.0,2.0,10.1007/s10805-022-09455-3,"Drolet, Marie-Josée; Rose-Derouin, Eugénie; Leblanc, Julie-Claude; Ruest, Mélanie; Williams-Jones, Bryn",2023.0,https://link.springer.com/10.1007/s10805-022-09455-3,journalArticle,"In the context of academic research, a diversity of ethical issues, conditioned by the different roles of members within these institutions, arise. Previous studies on this topic addressed mainly the perceptions of researchers. However, to our knowledge, no studies have explored the transversal ethical issues from a wider spectrum, including other members of academic institutions as the research ethics board (REB) members, and the research ethics experts. The present study used a descriptive phenomenological approach to document the ethical issues experienced by a heterogeneous group of Canadian researchers, REB members, and research ethics experts. Data collection involved socio-demographic questionnaires and individual semi-structured interviews. Following the triangulation of different perspectives (researchers, REB members and ethics experts), emerging ethical issues were synthesized in ten units of meaning: (1) research integrity, (2) conflicts of interest, (3) respect for research participants, (4) lack of supervision and power imbalances, (5) individualism and performance, (6) inadequate ethical guidance, (7) social injustices, (8) distributive injustices, (9) epistemic injustices, and (10) ethical distress. This study highlighted several problematic elements that can support the identification of future solutions to resolve transversal ethical issues in research that affect the heterogeneous members of the academic community.",,2023.0,2023-11-06 14:10:26,2023-11-06 14:10:26,269–292,Publisher: Springer Verlag,5BG8NK2Q,0.1538461538461538,0.4666666666666667,0.1763612608198595
5,8.0,technology,8.0,8.0,Ethics in Science and Technology Policy-Making: A Proposed Normative Framework,"Bulletin of Science, Technology and Society",42.0,4.0,10.1177/02704676221137307,"Khedmatgozar, Hamid Reza; Sharifzadeh, Rahman; Namdarian, Leila",2022.0,http://journals.sagepub.com/doi/10.1177/02704676221137307,journalArticle,"In the twenty-first century, the focus of science and technology (S&T) on the human interests and the accessible interests of society, and so the rise of some questions concerning the impact of S&T on social norms, has led to embedding ethical debates in S&T policy-making. The ethics of S&T policy-making, as a representation of the relationship between ethics and S&T policy-making, is a relatively new area of applied and professional ethics that addresses the dilemmas and ethical challenges of the S&T policy-making process. Understanding and recognizing the ethical components of S&T policy-making, one can develop a normative framework to assist policymakers in designing and analyzing ethical policies in the S&T field. The design and development of such a framework is the main purpose of the present study. In this study, the components of the proposed framework for ethical policy-making in S&T, their ethical and policy approaches, as well as their fundamental ethical and policy principles have been identified through studying sources and texts related to meta-ethics, normative ethics, and S&T ethics. Then, these components have been categorized in the form of steps for ethical policy-making using the thematic analysis method. Based on the results of this study, the ethical policy-making steps in S&T include problem identification, information gathering and feeding of the policy process, policy advice and policy formulation, policy implementation, and policy evaluation, which follow 9 ethical principles and 13 policy principles.",,2022.0,2023-11-06 14:09:50,2023-11-06 14:09:50,117–132,Publisher: SAGE Publications,6WVQPFEH,0.1716738197424892,0.2,0.1730293056689223
6,11.0,technology,11.0,11.0,Ai Ethics and Data Governance in the Geospatial Domain of Digital Earth,Big Data and Society,9.0,2.0,10.1177/20539517221138767,"Micheli, Marina; Gevaert, Caroline M.; Carman, Mary; Craglia, Max; Daemen, Emily; Ibrahim, Rania E.; Kotsev, Alexander; Mohamed-Ghouse, Zaffar; Schade, Sven; Schneider, Ingrid; Shanley, Lea A.; Tartaro, Alessio; Vespe, Michele",2022.0,http://journals.sagepub.com/doi/10.1177/20539517221138767,journalArticle,"Digital Earth applications provide a common ground for visualizing, simulating, and modeling real-world situations. The potential of Digital Earth applications has increased significantly with the evolution of artificial intelligence systems and the capacity to collect and process complex amounts of geospatial data. Yet, the widespread techno-optimism at the root of Digital Earth must now confront concerns over high-risk artificial intelligence systems and power asymmetries of a datafied society. In this commentary, we claim that not only can current debates about data governance and ethical artificial intelligence inform development in the field of Digital Earth, but that the specificities of geospatial data, together with the expectations surrounding Digital Earth applications, offer a fruitful lens through which to examine current debates on data governance and artificial intelligence ethics. In particular, we argue that for the implementation of ethical artificial intelligence and inclusive approaches to data governance, Digital Earth initiatives need to involve stakeholders and communities at the local level and be sensitive to social, legal, cultural, and institutional contexts, including conflicts that might arise within those contexts.",,2022.0,2023-11-06 14:09:47,2023-11-06 14:09:47,,Publisher: SAGE Publications,5XLLZ7BN,0.1428571428571428,0.5,0.1618654958235168
7,13.0,technology,13.0,13.0,Data Ethics in Catholic Health Systems,The National Catholic Bioethics Quarterly,22.0,2.0,10.5840/ncbq202222225,"Barina, Rachelle; Gremmels, Becket; Miller, Michael; Kockler, Nicholas; Repenshek, Mark; Ostertag, Christopher",2022.0,http://www.pdcnet.org/oom/service?url_ver=Z39.88-2004&rft_val_fmt=&rft.imuse_id=ncbq_2022_0022_0002_0289_0317&svc_id=info:www.pdcnet.org/collection,journalArticle,"The Catholic moral tradition has a rich foundation that applies broadly to encompass all areas of human experience. Yet, there is comparatively little in Catholic thought on the ethics of the collection and use of data, especially in healthcare. We provide here a brief overview of terminology, concepts, and applications of data in the context of healthcare, summarize relevant theological principles and themes (including the Vatican’s Rome Call for AI Ethics), and offer key questions for ethicists and data managers to consider as they analyze ethical implications pertinent to data governance and data management.",,2022.0,2023-11-06 14:09:47,2023-11-06 14:09:47,289–317,,PQ8GGVX6,0.1382978723404255,0.5,0.1592501297353399
8,14.0,technology,14.0,14.0,"Artificial Intelligence, Social Media and Depression. A New Concept of Health-Related Digital Autonomy",American Journal of Bioethics,21.0,7.0,10.1080/15265161.2020.1863515,"Laacke, Sebastian; Mueller, Regina; Schomerus, Georg; Salloch, Sabine",2021.0,https://www.tandfonline.com/doi/full/10.1080/15265161.2020.1863515,journalArticle,"The development of artificial intelligence (AI) in medicine raises fundamental ethical issues. As one example, AI systems in the field of mental health successfully detect signs of mental disorders, such as depression, by using data from social media. These AI depression detectors (AIDDs) identify users who are at risk of depression prior to any contact with the healthcare system. The article focuses on the ethical implications of AIDDs regarding affected users’ health-related autonomy. Firstly, it presents the (ethical) discussion of AI in medicine and, specifically, in mental health. Secondly, two models of AIDDs using social media data and different usage scenarios are introduced. Thirdly, the concept of patient autonomy, according to Beauchamp and Childress, is critically discussed. Since this concept does not encompass the specific challenges linked with the digital context of AIDDs in social media sufficiently, the current analysis suggests, finally, an extended concept of health-related digital autonomy.",,2021.0,2023-11-06 14:05:09,2023-11-06 14:05:09,4–20,Publisher: Taylor & Francis,QUBBMERR,0.1476510067114094,0.2307692307692307,0.1551670163336592
9,16.0,technology,16.0,16.0,Integrating Social Determinants of Health Into Ethical Digital Simulations,American Journal of Bioethics,23.0,9.0,10.1080/15265161.2023.2237443,"Kostick-Quenet, Kristin; Rahimzadeh, Vasiliki; Anandasabapathy, Sharmila; Hurley, Meghan; Sonig, Anika; Mcguire, Amy",2023.0,https://www.tandfonline.com/doi/full/10.1080/15265161.2023.2237443,journalArticle,"In their article, Cho and Martinez-Martin (2023) argue that developers and users of digital simulacra for modelling health and disease should involve a con- tinued focus on causality of health states, including epidemiological factors with ethical and social justice implications. The authors contend that this requires model developers to move beyond narrow perform- ance metrics so that performance evaluation standards better reflect patient, clinician, and community values and dynamics. As researchers, clinicians and legal scholars deeply involved in examining the ethical implications of digital health technologies including digital representations of patients via digital phenotyp- ing and other forms of computer perception, we agree with Cho and Martinez-Martin's solutions and wish to highlight some practical challenges, as well as offer recommendations at government, developer and user levels for acknowledging the critical role of social determinants of health (SDOH) in digital simulations.",,2023.0,2023-11-06 14:10:25,2023-11-06 14:10:25,57–60,Publisher: Taylor & Francis,YSMSNUM2,0.1214285714285714,0.5555555555555556,0.1511467923586332
10,22.0,technology,22.0,22.0,The Ethical Implications of Artificial Intelligence (Ai) for Meaningful Work,Journal of Business Ethics,,4.0,10.1007/s10551-023-05339-7,"Bankins, Sarah; Formosa, Paul",2023.0,https://link.springer.com/10.1007/s10551-023-05339-7,journalArticle,"The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the perception that one’s work has worth, significance, or a higher purpose. The development and organisational deployment of AI is accelerating, but the ways in which this will support or diminish opportunities for meaningful work and the ethical implications of these changes remain under-explored. This conceptual paper is positioned at the intersection of the meaningful work and ethical AI literatures and offers a detailed assessment of the ways in which the deployment of AI can enhance or diminish employees’ experiences of meaningful work. We first outline the nature of meaningful work and draw on philosophical and business ethics accounts to establish its ethical importance. We then explore the impacts of three paths of AI deployment (replacing some tasks, ‘tending the machine’, and amplifying human skills) across five dimensions constituting a holistic account of meaningful work, and finally assess the ethical implications. In doing so we help to contextualise the meaningful work literature for the era of AI, extend the ethical AI literature into the workplace, and conclude with a range of practical implications and future research directions.",,2023.0,2023-11-06 14:10:26,2023-11-06 14:10:26,1–16,,S8BX8J2H,0.1206030150753768,0.4,0.1357163039396269
11,26.0,technology,26.0,26.0,Correction: Ethics of Ai and Health Care: Towards a Substantive Human Rights Framework,Topoi,42.0,3.0,10.1007/s11245-023-09926-1,"Liao, S. Matthew",2023.0,https://link.springer.com/10.1007/s11245-023-09926-1,journalArticle,"There is enormous interest in using artificial intelligence (AI) in health care contexts. But before AI can be used in such settings, we need to make sure that AI researchers and organizations follow appropriate ethical frameworks and guidelines when developing these technologies. In recent years, a great number of ethical frameworks for AI have been proposed. However, these frameworks have tended to be abstract and not explain what grounds and justifies their recommendations and how one should use these recommendations in practice. In this paper, I propose an AI ethics framework that is grounded in substantive, human rights theory and one that can help us address these questions.",,2023.0,2023-11-06 14:10:24,2023-11-06 14:10:24,903–903,Publisher: Springer Verlag,NRJZNXRG,0.1203703703703703,0.2307692307692307,0.1326210826210826
12,28.0,technology,28.0,28.0,The Ai Carbon Footprint and Responsibilities of Ai Scientists,Philosophies,7.0,4.0,10.3390/philosophies7010004,"Tamburrini, Guglielmo",2022.0,https://www.mdpi.com/2409-9287/7/1/4,journalArticle,"This article examines ethical implications of the growing AI carbon footprint, focusing on the fair distribution of prospective responsibilities among groups of involved actors. First, major groups of involved actors are identified, including AI scientists, AI industry, and AI infrastructure providers, from datacenters to electrical energy suppliers. Second, responsibilities of AI scientists concerning climate warming mitigation actions are disentangled from responsibilities of other involved actors. Third, to implement these responsibilities nudging interventions are suggested, leveraging on AI competitive games which would prize research combining better system accuracy with greater computational and energy efficiency. Finally, in addition to the AI carbon footprint, it is argued that another ethical issue with a genuinely global dimension is now emerging in the AI ethics agenda. This issue concerns the threats that AI-powered cyberweapons pose to the digital command, control, and communication infrastructure of nuclear weapons systems.",,2022.0,2023-11-06 14:09:49,2023-11-06 14:09:49,4,Publisher: Mdpi,AM9KVNUI,0.1267605633802817,0.2222222222222222,0.1319831294693923
13,35.0,technology,35.0,35.0,Towards a Governance Framework for Brain Data,Neuroethics,15.0,2.0,10.1007/s12152-022-09498-8,"Ienca, Marcello; Fins, Joseph J.; Jox, Ralf J.; Jotterand, Fabrice; Voeneky, Silja; Andorno, Roberto; Ball, Tonio; Castelluccia, Claude; Chavarriaga, Ricardo; Chneiweiss, Hervé; Ferretti, Agata; Friedrich, Orsolya; Hurst, Samia; Merkel, Grischa; Molnár-Gábor, Fruzsina; Rickli, Jean-Marc; Scheibner, James; Vayena, Effy; Yuste, Rafael; Kellmeyer, Philipp",2022.0,https://link.springer.com/10.1007/s12152-022-09498-8,journalArticle,"The increasing availability of brain data within and outside the biomedical field, combined with the application of artificial intelligence (AI) to brain data analysis, poses a challenge for ethics and governance. We identify distinctive ethical implications of brain data acquisition and processing, and outline a multi-level governance framework. This framework is aimed at maximizing the benefits of facilitated brain data collection and further processing for science and medicine whilst minimizing risks and preventing harmful use. The framework consists of four primary areas of regulatory intervention: binding regulation, ethics and soft law, responsible innovation, and human rights.",,2022.0,2023-11-06 14:09:49,2023-11-06 14:09:49,1–14,Publisher: Springer Verlag,WF3XQICW,0.125,0.1428571428571428,0.1260903275828649
14,36.0,technology,36.0,36.0,Findings From a Mixed-Methods Pragmatic Cluster Trial Evaluating the Impact of Ethics Education Interventions on Residential Care-Givers,Nursing Inquiry,28.0,2.0,10.1111/nin.12383,"Gallagher, Ann; Peacock, Matthew; Williams, Emily; Zasada, Magdalena; Cox, Anna",2021.0,https://onlinelibrary.wiley.com/doi/10.1111/nin.12383,journalArticle,"There has been little previous research regarding the effectiveness of ethics education interventions for residential care‐givers. The Researching Interventions to Promote Ethics in social care project responded to the question: Which is the most effective ethics education intervention for care‐givers in residential social care? A pragmatic cluster trial explored the impact of three ethics education interventions for: (a) interactive face‐to‐face ethics teaching; (b) reflective ethics discussion groups; and (c) an immersive simulation experience. There was also a control arm (d). 144 trial participants were recruited from 39 residential care homes for older people in southern England. Change scores compared across intervention arms showed a significant reduction in work‐related moral stress in the teaching arm compared with control group (               p                = .03); there were no significant differences between control and intervention arms in change scores for moral sensitivity, interpersonal reactivity (empathy) or ethical leadership. Qualitative data themes were as follows: ethical care; care challenges; and ethical care inhibitors. Overall findings stimulate reflection on the value of three different ethics education interventions and the most appropriate means to evaluate their impact. Findings suggest the complexity and diverse nature of ethical competence in care. We suggest a way forward for research evaluating ethics education.",,2021.0,2023-11-06 14:05:09,2023-11-06 14:05:09,e12383,,JL9XHX2U,0.1266375545851528,0.1176470588235294,0.1258771643963588
15,42.0,technology,43.0,43.0,Moral Awareness of College Students Regarding Artificial Intelligence,Asian Bioethics Review,13.0,4.0,10.1007/s41649-021-00182-2,"Ho, Manh Tung; Ghotbi, Nader",2021.0,https://link.springer.com/10.1007/s41649-021-00182-2,journalArticle,"To evaluate the moral awareness of college students regarding artificial intelligence (AI) systems, we have examined 467 surveys collected from 152 Japanese and 315 non-Japanese students in an international university in Japan. The students were asked to choose a most significant moral problem of AI applications in the future from a list of ten ethical issues and to write an essay about it. The results show that most of the students (n = 269, 58%) considered unemployment to be the major ethical issue related to AI. The second largest group of students (n = 54, 12%) was concerned with ethical issues related to emotional AI, including the impact of AI on human behavior and emotion and robots’ rights and emotions. A relatively small number of students referred to the risk of social control by AI (6%), AI discrimination (6%), increasing inequality (5%), loss of privacy (4%), AI mistakes (3%), malicious AI (3%), and AI security breaches (3%). Calculation of the z score for two population proportions shows that Japanese students were much less concerned about AI control of society (− 3.1276, p < 0.01) than non-Japanese students, but more concerned about discrimination (2.2757, p < 0.05). Female students were less concerned about unemployment (− 2.6108, p < 0.01) than males, but more concerned about discrimination (2.4333, p < 0.05). The study concludes that the moral awareness of college students regarding AI technologies is quite limited and recommends including the ethics of AI in the curriculum.",,2021.0,2023-11-06 14:05:11,2023-11-06 14:05:11,421–433,Publisher: Springer Singapore,GGPKPH9B,0.1255411255411255,0.0,0.1200793741777348
